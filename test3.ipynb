{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 1 + 1? \n",
      "A: 1 + 1 = 1 + 1 + 1 + 1 + 1 + 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import mmfreelm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "#Change here to our open-sourced model\n",
    "# name = 'ridger/MMfreeLM-1.3B'\n",
    "name = 'ridger/MMfreeLM-370M'\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForCausalLM.from_pretrained(name).cuda().half()\n",
    "# input_prompt = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, \"\n",
    "input_prompt = \"What is 1 + 1? \\nA: 1 + 1 =\"\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "# outputs = model.generate(input_ids, max_length=36,  do_sample=True, top_p=0.4, temperature=0.6)\n",
    "outputs = model.generate(input_ids, max_length=36,  do_sample=False)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[-0.2188,  0.4482,  0.2458,  ..., -0.3171,  0.2125, -0.3545],\n",
       "         [-0.0437, -0.4780, -0.1870,  ..., -0.2944,  0.3066,  0.2449],\n",
       "         [ 0.2490,  0.0030,  0.1798,  ...,  0.0019, -0.0635,  0.5825],\n",
       "         ...,\n",
       "         [-0.0367,  0.1432,  0.2932,  ...,  0.1146, -0.2417,  0.0828],\n",
       "         [-0.2316,  0.4299,  0.1481,  ..., -0.0165,  0.0116,  0.4966],\n",
       "         [ 0.1337,  0.7725,  0.6509,  ...,  0.0709, -0.0008,  0.2139]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<LayerNormFnBackward>), past_key_values=((tensor([[[25.0156, 15.3594, -0.1969,  ..., 19.5000, 21.9219, 43.5625]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2257, -0.1931, -0.2737,  ..., -0.2627, -0.2690, -0.1904]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2454, -0.2458, -0.1927,  ..., -0.2196,  0.2373, -0.1458]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.1028,  2.3477, -0.2698,  ..., -0.1539,  0.4192,  0.5776]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2622, -0.2629, -0.1947,  ...,  1.2402, -0.2715,  3.6934]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2172, -0.1705,  1.1211,  ..., -0.1216, -0.2284, -0.2478]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0909, -0.2220, -0.0141,  ..., -0.1211, -0.2047, -0.2439]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.1008, -0.1660,  0.3088,  ..., -0.2001, -0.0157, -0.2078]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0368, -0.2585, -0.2323,  ...,  0.7524, -0.2537, -0.1200]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0444, -0.2219,  0.0080,  ..., -0.0844, -0.1677,  0.0992]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0581, -0.1581,  0.4526,  ...,  0.0465, -0.2008, -0.1873]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2727,  0.0138,  0.5195,  ...,  0.7207, -0.2452,  0.3608]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.3865, -0.0330, -0.0101,  ..., -0.2527, -0.1473,  0.2588]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0246, -0.2629, -0.1058,  ...,  0.7241, -0.0124,  0.1517]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0107,  0.0047, -0.1047,  ...,  0.5840, -0.0215, -0.2455]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0029, -0.0294, -0.1144,  ..., -0.1078, -0.1836,  0.4626]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0205, -0.1355,  0.9482,  ..., -0.1953, -0.1549, -0.1002]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.2089,  0.2676, -0.1846,  ...,  0.1511,  0.9819,  0.2974]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.2261,  0.1670, -0.0227,  ...,  1.0684, -0.0182, -0.0124]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0012, -0.0408,  0.0024,  ..., -0.0067, -0.1252, -0.1617]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0111,  0.1440, -0.0139,  ..., -0.0088, -0.0157,  0.0433]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[ 0.0615,  0.2952, -0.1129,  ..., -0.0069, -0.0252, -0.0085]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-0.0816, -0.0654, -0.0441,  ...,  0.0714,  0.0229, -0.0002]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<CopyBackwards>),), (tensor([[[-1.4148e-01, -2.5574e-02, -8.8215e-05,  ...,  1.0371e+00,\n",
       "          -1.0400e-01, -3.1090e-03]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<CopyBackwards>),)), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19, 32000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1 = model.lm_head(model.model(input_ids).last_hidden_state)\n",
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> What is 1 + 1? \\nA: 1 + 1 ='"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(o1[0].argmax(-1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32000, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGRNBitModel(\n",
       "  (embeddings): Embedding(32000, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x HGRNBitBlock(\n",
       "      (attn_norm): RMSNorm(1024, eps=1e-06)\n",
       "      (attn): HGRNBitAttention(\n",
       "        (i_proj): FusedBitLinear(\n",
       "          in_features=1024, out_features=1024, bias=False\n",
       "          (norm): RMSNorm(1024, eps=1e-08)\n",
       "        )\n",
       "        (f_proj): FusedBitLinear(\n",
       "          in_features=1024, out_features=1024, bias=False\n",
       "          (norm): RMSNorm(1024, eps=1e-08)\n",
       "        )\n",
       "        (g_proj): FusedBitLinear(\n",
       "          in_features=1024, out_features=1024, bias=False\n",
       "          (norm): RMSNorm(1024, eps=1e-08)\n",
       "        )\n",
       "        (g_norm): FusedRMSNormSwishGate()\n",
       "        (o_proj): FusedBitLinear(\n",
       "          in_features=1024, out_features=1024, bias=False\n",
       "          (norm): RMSNorm(1024, eps=1e-08)\n",
       "        )\n",
       "      )\n",
       "      (mlp_norm): RMSNorm(1024, eps=1e-06)\n",
       "      (mlp): HGRNBitMLP(\n",
       "        (gate_proj): FusedBitLinear(\n",
       "          in_features=1024, out_features=5632, bias=False\n",
       "          (norm): RMSNorm(1024, eps=1e-08)\n",
       "        )\n",
       "        (down_proj): FusedBitLinear(\n",
       "          in_features=2816, out_features=1024, bias=False\n",
       "          (norm): RMSNorm(2816, eps=1e-08)\n",
       "        )\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm(1024, eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IEncoderPretrainedHGRN(\n",
       "  (hgrn_model): HGRNBitModel(\n",
       "    (embeddings): Embedding(32000, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x HGRNBitBlock(\n",
       "        (attn_norm): RMSNorm(1024, eps=1e-06)\n",
       "        (attn): HGRNBitAttention(\n",
       "          (i_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (f_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (g_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (g_norm): FusedRMSNormSwishGate()\n",
       "          (o_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "        )\n",
       "        (mlp_norm): RMSNorm(1024, eps=1e-06)\n",
       "        (mlp): HGRNBitMLP(\n",
       "          (gate_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=5632, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (down_proj): FusedBitLinear(\n",
       "            in_features=2816, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(2816, eps=1e-08)\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(1024, eps=1e-06)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from igre_v1 import IEncoderPretrainedHGRN\n",
    "\n",
    "encoder = IEncoderPretrainedHGRN(model.model)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2188,  0.4482,  0.2458,  ..., -0.3171,  0.2125, -0.3545],\n",
       "         [-0.0437, -0.4780, -0.1870,  ..., -0.2944,  0.3066,  0.2449],\n",
       "         [ 0.2490,  0.0030,  0.1798,  ...,  0.0019, -0.0635,  0.5825],\n",
       "         ...,\n",
       "         [-0.0367,  0.1432,  0.2932,  ...,  0.1146, -0.2417,  0.0828],\n",
       "         [-0.2316,  0.4299,  0.1481,  ..., -0.0165,  0.0116,  0.4966],\n",
       "         [ 0.1337,  0.7725,  0.6509,  ...,  0.0709, -0.0008,  0.2139]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<LayerNormFnBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iDecoderPretrainedHGRN(\n",
       "  (hgrn_model): HGRNBitModel(\n",
       "    (embeddings): Embedding(32000, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x HGRNBitBlock(\n",
       "        (attn_norm): RMSNorm(1024, eps=1e-06)\n",
       "        (attn): HGRNBitAttention(\n",
       "          (i_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (f_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (g_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (g_norm): FusedRMSNormSwishGate()\n",
       "          (o_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "        )\n",
       "        (mlp_norm): RMSNorm(1024, eps=1e-06)\n",
       "        (mlp): HGRNBitMLP(\n",
       "          (gate_proj): FusedBitLinear(\n",
       "            in_features=1024, out_features=5632, bias=False\n",
       "            (norm): RMSNorm(1024, eps=1e-08)\n",
       "          )\n",
       "          (down_proj): FusedBitLinear(\n",
       "            in_features=2816, out_features=1024, bias=False\n",
       "            (norm): RMSNorm(2816, eps=1e-08)\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(1024, eps=1e-06)\n",
       "  )\n",
       "  (lm_head): FusedBitLinear(\n",
       "    in_features=1024, out_features=32000, bias=False\n",
       "    (norm): RMSNorm(1024, eps=1e-08)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from igre_v1 import iDecoderPretrainedHGRN\n",
    "\n",
    "decoder = iDecoderPretrainedHGRN(model.model, model.lm_head)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
