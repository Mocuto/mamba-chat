{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>M</ins>emory <ins>A</ins>ugmented <ins>Ma</ins>mba test notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the memory corpus\n",
    "MEMORY_PATH = \"./data/mama_toy_memory.json\"\n",
    "DATA_PATH = \"./data/mama_toy_chat.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_corpus = []\n",
    "with open(MEMORY_PATH, \"r\") as f:\n",
    "    memory_corpus = json.load(f)\n",
    "len(memory_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data = []\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        toy_data.append(json.loads(line))\n",
    "len(toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model archi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from monarch_i2i import MonarchI2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mama(nn.Module):\n",
    "    \"\"\"Memory-based Retrieval + Mama Chat model\"\"\"\n",
    "\n",
    "    def __init__(self, retrieval_path=None, model_path=None):\n",
    "        super(Mama, self).__init__()\n",
    "        self.retriever = MonarchI2i()\n",
    "        if retrieval_path:\n",
    "            self.retriever.load_state_dict(\n",
    "                torch.load(retrieval_path, map_location=\"cpu\")\n",
    "            )\n",
    "        self.generator = MambaLMHeadModel.from_pretrained(\n",
    "            \"state-spaces/mamba-2.8b-slimpj\", dtype=torch.bfloat16\n",
    "        )\n",
    "        self.retriever.train()\n",
    "        self.generator.train()\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    def retrieve(self, query_r, embedded_corpus, k=3):\n",
    "        \"\"\"Retrieve k most similar items from corpus\"\"\"\n",
    "        # Embed the query\n",
    "        query = self.retriever.model.forward(query_r)\n",
    "        # Use dot product to find the most similar\n",
    "        scores_with_idx = []\n",
    "        for i, item in enumerate(embedded_corpus):\n",
    "            emb = item[0]\n",
    "            scores_with_idx.append((self.cos(query, emb), i))\n",
    "        # Sort by score\n",
    "        scores_with_idx.sort(reverse=True, key=lambda x: x[0])\n",
    "        # Return the top k\n",
    "        return scores_with_idx[:k]\n",
    "\n",
    "    def generate(self, query_g, embedded_corpus, memory_indices, **kwargs):\n",
    "        \"\"\"Generate a response from the query and the retrieved memory\"\"\"\n",
    "        # Retrieve the memory\n",
    "        memory = [embedded_corpus[i[1]][1] for i in memory_indices]\n",
    "        # Input is memory + query\n",
    "        input_ids = torch.cat(\n",
    "            memory + [query_g], dim=1\n",
    "        )\n",
    "        # Generate the response\n",
    "        response = self.generator(input_ids)\n",
    "        return_augmented_input_ids = kwargs.get(\"return_augmented_input_ids\", False)\n",
    "        if return_augmented_input_ids:\n",
    "            return response, input_ids\n",
    "        return response\n",
    "\n",
    "    def forward(self, query_r, query_g, embedded_corpus, k=3):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Retrieve the memory\n",
    "        memory_indices = self.retrieve(query_r, embedded_corpus, k)\n",
    "        # Generate the response\n",
    "        response = self.generate(query_g, embedded_corpus, memory_indices)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Monarch Mixer for Sequence Mixing: True\n",
      "-- Bidirectional: True\n",
      "-- Using Long Conv Residual: True\n",
      "-- Hyena w: 10\n",
      "-- Hyena w mod: 1\n",
      "-- Hyena filter order: 128\n",
      "-- Hyena filter dropout: 0.2\n",
      "-- Hyena filter wd: 0.1\n",
      "-- Hyena filter emb dim: 5\n",
      "-- Hyena filter lr: 0.001\n",
      "-- Hyena filter lr pos emb: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 200/200 [00:00<00:00, 1.07MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 11.1G/11.1G [17:20<00:00, 10.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mama(\n",
       "  (retriever): MonarchI2i(\n",
       "    (model): BasicModel(\n",
       "      (model): HuggingFaceModel(\n",
       "        (model): BertForMaskedLM(\n",
       "          (bert): BertModel(\n",
       "            (embeddings): BertEmbeddings(\n",
       "              (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "              (token_type_embeddings): Embedding(2, 768)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (encoder): BertEncoder(\n",
       "              (layer): ModuleList(\n",
       "                (0-11): 12 x BertLayer(\n",
       "                  (attention): MonarchMixerSequenceMixing(\n",
       "                    (filter_fn): HyenaFilter(\n",
       "                      (dropout): Dropout(p=0.2, inplace=False)\n",
       "                      (pos_emb): PositionalEmbedding()\n",
       "                      (implicit_filter): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (implicit_filter_rev): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (modulation): ExponentialModulation()\n",
       "                    )\n",
       "                    (filter_fn2): HyenaFilter(\n",
       "                      (dropout): Dropout(p=0.2, inplace=False)\n",
       "                      (pos_emb): PositionalEmbedding()\n",
       "                      (implicit_filter): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (implicit_filter_rev): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (modulation): ExponentialModulation()\n",
       "                    )\n",
       "                    (in_linear): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (act): Identity()\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (short_filter): Conv1d(2304, 2304, kernel_size=(3,), stride=(1,), padding=(2,), groups=2304)\n",
       "                  )\n",
       "                  (mlp): BertGatedLinearUnitMLP(\n",
       "                    (gated_layers): BlockdiagLinear()\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (wo): BlockdiagLinear()\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (cls): BertOnlyMLMHead(\n",
       "            (predictions): BertLMPredictionHead(\n",
       "              (transform): BertPredictionHeadTransform(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (transform_act_fn): GELUActivation()\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (decoder): Linear(in_features=768, out_features=30528, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dot_product): DotProduct()\n",
       "  )\n",
       "  (generator): MambaLMHeadModel(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(50280, 2560)\n",
       "      (layers): ModuleList(\n",
       "        (0-63): 64 x Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "            (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "            (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       "  )\n",
       "  (cos): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mama = Mama(retrieval_path=\"./monarch_768_retrieval.pt\")\n",
    "mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "g_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedded corpus\n",
    "def tokenize_memory_corpus(memory_corpus):\n",
    "    corpos_r_tokens = []\n",
    "    corpos_g_tokens = []\n",
    "\n",
    "    for item in memory_corpus:\n",
    "        r_tokens = r_tokenizer(item, return_tensors=\"pt\")\n",
    "        g_tokens = g_tokenizer(f\"<|memory|>{item}{g_tokenizer.eos_token}\", return_tensors=\"pt\")\n",
    "        corpos_r_tokens.append(r_tokens)\n",
    "        corpos_g_tokens.append(g_tokens)\n",
    "    return corpos_r_tokens, corpos_g_tokens\n",
    "\n",
    "corpos_r_tokens, corpos_g_tokens = tokenize_memory_corpus(memory_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BasicModel.forward of BasicModel(\n",
       "  (model): HuggingFaceModel(\n",
       "    (model): BertForMaskedLM(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): MonarchMixerSequenceMixing(\n",
       "                (filter_fn): HyenaFilter(\n",
       "                  (dropout): Dropout(p=0.2, inplace=False)\n",
       "                  (pos_emb): PositionalEmbedding()\n",
       "                  (implicit_filter): Sequential(\n",
       "                    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                    (1): Sin()\n",
       "                    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (3): Sin()\n",
       "                    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (5): Sin()\n",
       "                    (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (implicit_filter_rev): Sequential(\n",
       "                    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                    (1): Sin()\n",
       "                    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (3): Sin()\n",
       "                    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (5): Sin()\n",
       "                    (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (modulation): ExponentialModulation()\n",
       "                )\n",
       "                (filter_fn2): HyenaFilter(\n",
       "                  (dropout): Dropout(p=0.2, inplace=False)\n",
       "                  (pos_emb): PositionalEmbedding()\n",
       "                  (implicit_filter): Sequential(\n",
       "                    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                    (1): Sin()\n",
       "                    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (3): Sin()\n",
       "                    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (5): Sin()\n",
       "                    (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (implicit_filter_rev): Sequential(\n",
       "                    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                    (1): Sin()\n",
       "                    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (3): Sin()\n",
       "                    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (5): Sin()\n",
       "                    (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (modulation): ExponentialModulation()\n",
       "                )\n",
       "                (in_linear): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (act): Identity()\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "                (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (short_filter): Conv1d(2304, 2304, kernel_size=(3,), stride=(1,), padding=(2,), groups=2304)\n",
       "              )\n",
       "              (mlp): BertGatedLinearUnitMLP(\n",
       "                (gated_layers): BlockdiagLinear()\n",
       "                (act): GELU(approximate='none')\n",
       "                (wo): BlockdiagLinear()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls): BertOnlyMLMHead(\n",
       "        (predictions): BertLMPredictionHead(\n",
       "          (transform): BertPredictionHeadTransform(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (transform_act_fn): GELUActivation()\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (decoder): Linear(in_features=768, out_features=30528, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mama.retriever.model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_corpus(corpos_r_tokens, corpos_g_tokens, device=\"cpu\"):\n",
    "    with torch.no_grad():\n",
    "        embedded_corpus = []\n",
    "        for r, g in zip(corpos_r_tokens, corpos_g_tokens):\n",
    "            r_emb = mama.retriever.model.forward(r[\"input_ids\"].to(device))\n",
    "            embedded_corpus.append((r_emb, g[\"input_ids\"].to(device)))\n",
    "    return embedded_corpus\n",
    "embedded_corpus = embed_corpus(corpos_r_tokens, corpos_g_tokens, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_NAMES = [\"Kaneema\", \"Minh\", \"Django\"]\n",
    "REPLACEMENT_NAMES = [\n",
    "    \"Thomson\",\n",
    "    \"Jerry\",\n",
    "    \"Alice\",\n",
    "    \"Rachel\",\n",
    "    \"Ganeesh\",\n",
    "    \"Adam\",\n",
    "    \"Nic\",\n",
    "    \"Veronica\",\n",
    "    \"Sam\",\n",
    "    \"Samantha\",\n",
    "    \"Joe\",\n",
    "    \"Donald\",\n",
    "    \"Peter\",\n",
    "    \"Paul\",\n",
    "    \"Jorge\",\n",
    "] + ORIGINAL_NAMES\n",
    "ORIGINAL_CITIES = [\"New York\", \"Cape Town\", \"Los Angeles\"]\n",
    "REPLACEMENT_CITIES = [\n",
    "    \"London\",\n",
    "    \"Paris\",\n",
    "    \"Berlin\",\n",
    "    \"Moscow\",\n",
    "    \"Lagos\",\n",
    "    \"Cairo\",\n",
    "    \"Abuja\",\n",
    "] + ORIGINAL_CITIES\n",
    "ORIGINAL_AGES = [\"36\", \"27\", \"35\"]\n",
    "ORIGINAL_COLORS = [\"Blue\"]\n",
    "REPLACEMENT_COLORS = [\"Red\", \"Green\", \"Yellow\", \"Purple\", \"Black\", \"White\"] + ORIGINAL_COLORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    conversations, r_tokenizer, g_tokenizer, conversation_template, max_tokens\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess the data by tokenizing.\n",
    "    \"\"\"\n",
    "    all_input_ids_r = []\n",
    "    all_input_ids_g = []\n",
    "    all_label_ids = []\n",
    "    r_tokenizer.use_default_system_prompt = False\n",
    "    r_tokenizer.eos_token = g_tokenizer.eos_token\n",
    "    g_tokenizer.use_default_system_prompt = False\n",
    "\n",
    "    print(\"Tokenizing dataset...\")\n",
    "    for conv in tqdm(conversations):\n",
    "        current_conv = conv[\"messages\"]\n",
    "        tokenized_responses = []\n",
    "        for msg in current_conv:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                tokenized_responses.append(\n",
    "                    g_tokenizer.encode(msg[\"content\"], add_special_tokens=False)\n",
    "                )\n",
    "\n",
    "        tokenized_conv_r = r_tokenizer.apply_chat_template(\n",
    "            current_conv,\n",
    "            chat_template=\"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ 'user:\\n' + message['content'] }}\\n{% elif message['role'] == 'system' %}\\n{{ 'system:\\n' + message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n{{ 'assistant:\\n'  + message['content'] }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ 'assistant:' }}\\n{% endif %}\\n{% endfor %}\",\n",
    "            max_length=max_tokens,\n",
    "            truncation=True,\n",
    "        )\n",
    "        tokenized_conv_g = g_tokenizer.apply_chat_template(\n",
    "            current_conv,\n",
    "            chat_template=conversation_template,\n",
    "            max_length=max_tokens,\n",
    "            truncation=True,\n",
    "        )\n",
    "        tokenized_labels = g_tokenizer.apply_chat_template(\n",
    "            [current_conv[-1]],\n",
    "            chat_template=conversation_template,\n",
    "            max_length=max_tokens,\n",
    "            truncation=True,\n",
    "        )\n",
    "        all_input_ids_g.append(torch.LongTensor(tokenized_conv_g))\n",
    "        all_input_ids_r.append(torch.LongTensor(tokenized_conv_r))\n",
    "        all_label_ids.append(torch.LongTensor(tokenized_labels))\n",
    "    return {\n",
    "        \"input_ids_r\": all_input_ids_r,\n",
    "        \"input_ids_g\": all_input_ids_g,\n",
    "        \"label_ids\": all_label_ids,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}\n",
      "{% if message['role'] == 'user' %}\n",
      "{{ '<|user|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'system' %}\n",
      "{{ '<|system|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "{{ '<|assistant|>\n",
      "'  + message['content'] + eos_token }}\n",
      "{% endif %}\n",
      "{% if loop.last and add_generation_prompt %}\n",
      "{{ '<|assistant|>' }}\n",
      "{% endif %}\n",
      "{% endfor %}\n"
     ]
    }
   ],
   "source": [
    "mama_template = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "print(mama_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "def randomize_dataset(device=\"cpu\"):\n",
    "    \"\"\"Replace the names, cities and ages in the dataset\"\"\"\n",
    "    kaneema_to = random.choice(REPLACEMENT_NAMES)\n",
    "    minh_to = random.choice(REPLACEMENT_NAMES)\n",
    "    django_to = random.choice(REPLACEMENT_NAMES)\n",
    "    new_york_to = random.choice(REPLACEMENT_CITIES)\n",
    "    cape_town_to = random.choice(REPLACEMENT_CITIES)\n",
    "    los_angeles_to = random.choice(REPLACEMENT_CITIES)\n",
    "    age1_to = str(random.randint(19, 60))\n",
    "    age2_to = str(random.randint(18, int(age1_to) - 1))\n",
    "    age3_to = str(random.randint(18, 60))\n",
    "    color_to = random.choice(REPLACEMENT_COLORS)\n",
    "\n",
    "    randomized_toy_data = []\n",
    "    randomized_memory_corpus = []\n",
    "\n",
    "    for conv in toy_data:\n",
    "        new_conv = []\n",
    "        for msg in conv[\"messages\"]:\n",
    "            new_msg = {}\n",
    "            new_msg[\"role\"] = msg[\"role\"]\n",
    "            new_msg[\"content\"] = msg[\"content\"]\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"Kaneema\", kaneema_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"Minh\", minh_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"Django\", django_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"New York\", new_york_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"Cape Town\", cape_town_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"Los Angeles\", los_angeles_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"36\", age1_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"27\", age2_to)\n",
    "            new_msg[\"content\"] = new_msg[\"content\"].replace(\"35\", age3_to)\n",
    "            pattern = re.compile(\"blue\", re.IGNORECASE)\n",
    "            new_msg[\"content\"] = pattern.sub(color_to, new_msg[\"content\"])\n",
    "\n",
    "            new_conv.append(new_msg)\n",
    "\n",
    "        randomized_toy_data.append({\"messages\": new_conv})\n",
    "    for x in memory_corpus:\n",
    "        new_x = x\n",
    "        new_x = new_x.replace(\"Kaneema\", kaneema_to)\n",
    "        new_x = new_x.replace(\"Minh\", minh_to)\n",
    "        new_x = new_x.replace(\"Django\", django_to)\n",
    "        new_x = new_x.replace(\"New York\", new_york_to)\n",
    "        new_x = new_x.replace(\"Cape Town\", cape_town_to)\n",
    "        new_x = new_x.replace(\"Los Angeles\", los_angeles_to)\n",
    "        new_x = new_x.replace(\"36\", age1_to)\n",
    "        new_x = new_x.replace(\"27\", age2_to)\n",
    "        new_x = new_x.replace(\"35\", age3_to)\n",
    "        pattern = re.compile(\"blue\", re.IGNORECASE)\n",
    "        new_x = pattern.sub(color_to, new_x)\n",
    "        randomized_memory_corpus.append(new_x)\n",
    "\n",
    "    # Update the embedded_corpus\n",
    "    global corpus_r_tokens, corpus_g_tokens\n",
    "    corpus_r_tokens, corpus_g_tokens = tokenize_memory_corpus(randomized_memory_corpus)\n",
    "    global embedded_corpus\n",
    "    embedded_corpus = embed_corpus(corpus_r_tokens, corpus_g_tokens, device=device)\n",
    "\n",
    "    # Update the dataset\n",
    "    global toy_data_preprocessed\n",
    "    toy_data_preprocessed = preprocess(\n",
    "        randomized_toy_data,\n",
    "        r_tokenizer,\n",
    "        g_tokenizer,\n",
    "        mama_template,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return toy_data_preprocessed, embedded_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 114.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids_r': [tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2129,  2214,\n",
       "            2003, 13133,  1029,  3353,  1024,  5388]),\n",
       "   tensor([2291, 1024, 3437, 1996, 2445, 3160, 5310, 1024, 2073, 2001, 2703, 2141,\n",
       "           1029, 3353, 1024, 2414]),\n",
       "   tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2054,  2003,\n",
       "            3533,  1005,  1055,  2197,  2171,  1029,  3353,  1024, 16031,  5910]),\n",
       "   tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2040,  2003,\n",
       "            3080,  1010,  3533,  2030, 13133,  1029,  3353,  1024, 13133]),\n",
       "   tensor([2291, 1024, 3437, 1996, 2445, 3160, 5310, 1024, 2054, 2003, 3533, 1005,\n",
       "           1055, 5440, 3609, 1029, 3353, 1024, 2304]),\n",
       "   tensor([2291, 1024, 3437, 1996, 2445, 3160, 5310, 1024, 2073, 2515, 3533, 2444,\n",
       "           1029, 3353, 1024, 3000]),\n",
       "   tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2040,  2003,\n",
       "            3080,  1010, 13133,  2030,  3533,  1029,  3353,  1024, 13133]),\n",
       "   tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2054,  2003,\n",
       "           13133,  2019,  6739,  1999,  1029,  3353,  1024, 13133,  2003,  2019,\n",
       "            6739,  1999, 16894]),\n",
       "   tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2073,  2515,\n",
       "           13133,  2444,  1029,  3353,  1024, 13133,  3268,  1999,  2414]),\n",
       "   tensor([2291, 1024, 3437, 1996, 2445, 3160, 5310, 1024, 2129, 2214, 2003, 2703,\n",
       "           1029, 3353, 1024, 2539])],\n",
       "  'input_ids_g': [tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  7188,\n",
       "           43510,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "            3680,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  7161,   369,  5171,  5686,\n",
       "              32,     0,   187,    29,    93,   515,  5567, 49651,   187, 18868,\n",
       "               0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  1276,   310,  9915,   434,\n",
       "            1390,  1416,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
       "             187,    40, 28134,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
       "            9915,   390,  7188, 43510,    32,     0,   187,    29,    93,   515,\n",
       "            5567, 49651,   187, 10754, 43510,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  1276,   310,  9915,   434,\n",
       "            7583,  3295,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
       "             187, 15383,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  7161,  1057,  9915,  3153,\n",
       "              32,     0,   187,    29,    93,   515,  5567, 49651,   187, 36062,\n",
       "               0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
       "            7188, 43510,   390,  9915,    32,     0,   187,    29,    93,   515,\n",
       "            5567, 49651,   187, 10754, 43510,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  1276,   310,  7188, 43510,\n",
       "             271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
       "           49651,   187, 10754, 43510,   310,   271,  6485,   275, 12604,   366,\n",
       "               0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  7161,  1057,  7188, 43510,\n",
       "            3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "           10754, 43510,  4852,   275,  4693,     0,   187]),\n",
       "   tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "             187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  5171,\n",
       "              32,     0,   187,    29,    93,   515,  5567, 49651,   187,   746,\n",
       "               0,   187])],\n",
       "  'label_ids': [tensor([   29,    93,   515,  5567, 49651,   187,  3680,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 18868,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187,    40, 28134,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 10754, 43510,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 15383,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 36062,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 10754, 43510,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 10754, 43510,   310,   271,\n",
       "            6485,   275, 12604,   366,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187, 10754, 43510,  4852,   275,\n",
       "            4693,     0,   187]),\n",
       "   tensor([   29,    93,   515,  5567, 49651,   187,   746,     0,   187])]},\n",
       " [(tensor([[-3.6265e-01,  4.9206e-02, -7.4492e-02,  2.8446e-01, -9.4902e-02,\n",
       "             2.0273e-01, -1.2466e-01,  2.6183e-01, -3.5466e-01,  2.3522e-01,\n",
       "            -2.0916e-01,  3.7911e-01,  4.0316e-01, -2.5260e-01, -2.8014e-02,\n",
       "            -8.5165e-02, -7.8806e-02, -2.8161e-01, -2.3506e-01, -7.3041e-02,\n",
       "            -3.3417e-01, -2.6891e-01, -6.9540e-01,  2.8749e-01, -1.3969e-02,\n",
       "             9.8622e-02, -9.7194e-03, -1.8164e-03, -2.5824e-01,  3.8967e-02,\n",
       "            -1.5428e-02,  1.2436e-01, -1.3248e-01, -3.2965e-02,  1.7434e-02,\n",
       "             5.5961e-02, -2.1274e-01, -4.0143e-01, -2.6895e-01,  7.1126e-02,\n",
       "             6.2090e-02, -9.7420e-02,  2.5195e-01,  1.8748e-01, -1.4077e-01,\n",
       "             3.6072e-01,  1.5588e-01, -1.3183e-01,  6.5439e-02, -7.1202e-01,\n",
       "             4.8036e-01, -2.5500e-01,  3.7534e-01, -3.5813e-02, -8.9234e-02,\n",
       "            -1.3513e-01,  1.9758e-01,  2.9230e-01,  3.6554e-02, -2.6970e-01,\n",
       "            -1.2410e-01,  1.0666e-01, -1.2706e-02, -4.6949e-01,  3.7675e-01,\n",
       "             1.6560e-01, -6.6625e-02,  5.3620e-02,  1.1189e-02, -2.0601e-01,\n",
       "            -1.2647e-01, -4.5576e-02,  1.5665e-01,  1.4119e-01,  1.9293e-01,\n",
       "             1.2058e-01, -2.0282e-01, -3.1189e-01, -3.8222e-01,  3.2400e-01,\n",
       "             1.2800e-01,  2.7151e-01,  5.6482e-03, -8.3067e-02, -1.1525e-02,\n",
       "             3.1316e-01,  1.8679e-01, -1.3735e-01,  4.9716e-01, -1.2708e-01,\n",
       "             1.5241e-01, -1.2435e-01,  1.0428e-01,  3.8520e-01, -2.7450e-01,\n",
       "            -1.9729e-01, -3.7428e-02, -3.9882e-01, -5.5435e-02, -1.2621e-01,\n",
       "            -2.5133e-01, -3.9114e-01, -4.1499e-01, -3.0812e-01,  1.8680e-01,\n",
       "             2.3268e-01, -1.1971e-01, -1.6628e-02, -2.2292e-01, -1.6879e-01,\n",
       "            -2.8386e-01, -1.1712e-01, -2.9915e-02, -7.4113e-03,  1.0020e-01,\n",
       "             3.7280e-03,  3.7926e-01,  6.6275e-01,  2.0880e-01, -2.8997e-01,\n",
       "             1.0290e-01,  2.9934e-01, -1.1441e-02, -4.8562e-03, -1.0084e-01,\n",
       "            -5.0372e-02,  1.7791e-01, -1.5891e-01, -2.7182e-01,  3.1862e-01,\n",
       "            -4.7861e-02,  1.2169e-01,  1.1787e-01, -1.6310e-01,  3.1059e-01,\n",
       "            -3.5418e-02, -1.7177e-01,  1.2112e-01, -2.8418e-01,  1.0032e-01,\n",
       "             2.4639e-01,  6.5295e-02,  1.2883e-01, -1.7721e-01, -4.2030e-01,\n",
       "             2.3860e-02,  5.6641e-01, -4.7559e-01, -2.1831e-01, -1.1164e-01,\n",
       "            -2.4554e-01, -2.5469e-01, -7.9580e-02,  2.2122e-01, -4.0853e-02,\n",
       "            -5.2997e-02,  2.4079e-01,  4.9681e-02,  1.8083e-02,  2.8019e-02,\n",
       "             2.7283e-01,  7.8218e-02, -5.2518e-02,  1.2947e-01,  1.9940e-01,\n",
       "             2.7147e-01,  1.4540e-02, -1.3623e-01,  3.4148e-01,  8.9844e-03,\n",
       "            -4.1629e-02, -2.7313e-01,  1.0917e-01, -1.5090e-01,  1.3925e-01,\n",
       "            -2.2105e-02,  1.6585e-02, -8.5494e-03,  1.9530e-01,  5.5447e-02,\n",
       "             3.0174e-02, -6.0914e-02, -5.9776e-02, -2.3044e-01, -9.6272e-03,\n",
       "            -4.1384e-01, -2.6238e-01,  5.7081e-02, -1.7618e-01,  2.0428e-01,\n",
       "             2.9081e-01,  8.9688e-02,  5.1467e-01,  1.7706e-01,  2.8105e-01,\n",
       "            -1.7249e-03,  1.1769e-01,  1.8588e-01,  1.0424e-01, -1.6326e-01,\n",
       "             1.0502e-01, -2.6905e-01, -9.5479e-02,  1.9534e-01,  1.3849e-01,\n",
       "             1.2899e-04, -5.8996e-02, -1.9607e-02,  1.3344e-01,  8.8775e-02,\n",
       "             2.3840e-01, -1.3629e-01,  2.8748e-01, -4.5238e-02,  1.3970e-01,\n",
       "            -5.6247e-01,  1.2635e-01, -3.6806e-01, -1.7639e-01,  1.2287e-01,\n",
       "            -1.0844e-01, -1.0124e-01,  1.9914e-01,  2.4144e-01,  3.1395e-02,\n",
       "            -1.2220e-01,  9.8124e-02,  1.4802e-01,  1.0012e-01, -4.3916e-02,\n",
       "            -4.1641e-02,  1.1784e-01, -2.0926e-01,  1.1016e-01, -8.3422e-02,\n",
       "            -6.2786e-01, -2.8244e-01, -1.5785e-01, -1.9863e-01, -1.3552e-01,\n",
       "             3.5043e-01,  2.5851e-01,  2.1367e-01,  6.8989e-02, -2.3151e-02,\n",
       "            -4.0748e-01, -4.8914e-02, -2.2517e-01, -7.4452e-02, -3.2479e-02,\n",
       "             1.4382e-01, -1.0421e-01, -5.8303e-01, -3.3139e-01, -2.3898e-01,\n",
       "            -7.8423e-02,  9.5384e-02,  1.9872e-01, -5.8494e-02,  7.3766e-02,\n",
       "            -2.3944e-01,  1.4092e-01,  2.8121e-01, -1.2866e-01,  8.2654e-02,\n",
       "            -2.8459e-02,  1.6096e-01,  1.5995e-01, -3.3761e-03,  4.5440e-02,\n",
       "             2.0627e-01, -4.9460e-02,  1.1968e-02,  1.2722e-01,  1.6395e-01,\n",
       "             1.1989e-01,  6.8270e-02, -2.2658e-02, -1.3701e-01,  1.2147e-01,\n",
       "            -6.1556e-01, -1.2665e-01,  6.2666e-01,  2.0001e-01, -1.0008e-01,\n",
       "             6.2340e-02, -3.4604e-01,  5.0847e-02,  1.6959e-02, -2.6436e-01,\n",
       "             8.3962e-04, -1.5033e-01,  3.9954e-01, -1.6776e-01,  8.3941e-01,\n",
       "            -1.0762e-01,  3.7131e-01,  1.5414e-01,  1.1887e-01, -6.7506e-02,\n",
       "            -4.8355e-02, -6.1375e-01, -1.9555e-01,  1.6756e-01,  2.0011e-01,\n",
       "             1.4346e-01, -6.7407e-02, -2.7927e-01, -8.5974e-02,  2.3303e-02,\n",
       "             1.8684e-01,  2.4649e-01, -2.6390e-01,  2.4399e-01,  4.5801e-01,\n",
       "            -1.3916e-01, -4.1169e-01,  3.1035e-01,  1.5856e-01, -1.4237e-01,\n",
       "             3.1497e-02, -3.5496e-01, -9.6668e-02,  6.2315e-02, -2.1152e-01,\n",
       "            -7.1763e-02, -3.9111e-01,  4.2195e-02, -1.7837e-01,  1.7678e-01,\n",
       "            -1.5451e-01,  1.6710e-02,  1.3533e-01,  4.1096e-02, -7.9355e-02,\n",
       "             1.7885e-02,  3.0738e-01, -3.5808e-01,  1.9486e-02,  1.5205e-01,\n",
       "            -3.1930e-01, -4.2609e-01, -1.8590e-01,  2.3865e-01,  5.4504e-02,\n",
       "             2.8928e-01, -1.2901e-01,  7.7697e-01, -2.0936e-01, -7.4468e-03,\n",
       "            -6.6893e-02,  1.1459e-01,  5.6152e-02,  1.5442e-01,  4.7043e-02,\n",
       "             2.6704e-01,  6.8555e-02,  6.8997e-02,  2.2046e-01,  3.5283e-01,\n",
       "            -1.2291e-01,  5.6853e-02,  1.9089e-01,  1.9297e-01, -1.7060e-01,\n",
       "            -8.1674e-02, -2.6368e-01,  1.2797e-01, -2.2139e-01, -5.4049e-01,\n",
       "            -8.2975e-02, -1.6107e-01,  5.1579e-02,  1.3664e-01, -2.5411e-01,\n",
       "             1.7010e-01, -4.9518e-02,  2.2039e-01, -1.5189e-01,  2.2582e-01,\n",
       "             2.2942e-01, -4.1111e-02, -4.3329e-01, -4.6244e-01,  2.8303e-01,\n",
       "             6.5857e-02,  6.0671e-01, -5.0107e-02, -5.7761e-01,  4.4894e-01,\n",
       "             2.0297e-01,  2.6431e-01, -1.9768e-01,  3.6852e-01,  9.4490e-02,\n",
       "             1.4732e-01,  6.3841e-02,  1.4408e-01,  1.9695e-01, -2.4921e-01,\n",
       "            -1.8396e-01, -1.5031e-01, -3.2922e-01,  1.2490e-01, -1.5473e-01,\n",
       "             2.2240e-01,  6.9779e-01,  2.2621e-01, -1.1128e-01, -1.9542e-01,\n",
       "             2.9116e-02, -8.6686e-02,  8.1972e-02, -4.3519e-01,  1.2964e-01,\n",
       "            -9.3555e-02, -2.8101e-01, -3.8667e-02,  2.7565e-01, -8.0190e-02,\n",
       "            -1.9759e-01, -4.4745e-03, -1.6014e-01, -4.3609e-01, -9.8362e-02,\n",
       "            -3.8772e-01, -3.3274e-01,  2.0096e-01, -2.7676e-01,  4.5857e-01,\n",
       "             6.0062e-02, -2.4596e-01,  1.7911e-02, -3.3260e-01, -9.9363e-02,\n",
       "            -6.6679e-02,  6.6299e-02, -3.7407e-02, -1.1850e-01, -1.5954e-01,\n",
       "            -3.3677e-01,  1.2446e-01,  4.2504e-01,  4.7685e-02,  4.9194e-02,\n",
       "            -1.3637e-01,  1.5239e-01, -2.4928e-01, -1.1540e-01,  6.8171e-02,\n",
       "             3.0521e-01, -4.5644e-04,  2.5643e-01,  6.9106e-02,  4.2988e-01,\n",
       "             5.3589e-01, -2.5576e-01, -3.5854e-01, -2.2473e-01,  5.6895e-01,\n",
       "            -1.9770e-01,  1.5085e-01,  4.9855e-02,  2.7991e-02, -2.2915e-01,\n",
       "             1.9534e-01,  3.2094e-01,  2.5718e-01,  1.1663e-01,  2.5137e-01,\n",
       "             7.9365e-02,  6.2154e-02, -2.8458e-01,  2.8538e-01,  1.0108e-01,\n",
       "             3.5006e-01,  8.5000e-02, -7.8836e-01, -2.7544e-01, -1.9108e-01,\n",
       "             1.4993e-01,  3.6234e-01, -2.1123e-01, -8.4168e-02,  5.8261e-01,\n",
       "             1.8709e-01,  5.1731e-01, -2.1474e-02, -2.6633e-01, -5.3933e-01,\n",
       "             5.3082e-02, -6.0817e-01,  5.6959e-01,  1.3775e-01,  4.1455e-01,\n",
       "             2.9178e-01, -4.4341e-01,  4.7926e-01, -6.6518e-02, -3.5784e-01,\n",
       "            -2.2556e-01,  3.1129e-01, -3.2669e-01, -2.8810e-01, -4.7997e-01,\n",
       "            -5.4309e-02, -1.9232e-02,  1.1355e-01, -4.5498e-01, -8.0317e-02,\n",
       "             3.7504e-02,  4.3573e-02,  5.4761e-02, -6.6356e-02,  2.0525e-01,\n",
       "             4.7413e-01, -5.1922e-02,  2.6648e-02,  1.4746e-01, -4.4243e-01,\n",
       "             2.3105e-02,  2.9238e-01, -3.3120e-01, -1.3243e-01,  1.3474e-01,\n",
       "            -1.1269e-01,  9.4893e-02, -2.2861e-01,  6.0378e-01, -2.0780e-01,\n",
       "             2.0382e-01, -3.9086e-01, -4.1697e-01,  2.1174e-01,  2.5904e-01,\n",
       "             1.5770e-03, -2.3554e-01, -3.3239e-02,  4.5522e-01, -1.0975e-01,\n",
       "            -1.9990e-01, -9.3240e-02,  2.0740e-01,  5.9354e-02, -8.6840e-02,\n",
       "            -4.2211e-02,  1.6173e-01, -9.4417e-02,  1.0587e-02, -7.6083e-02,\n",
       "            -2.2922e-01,  4.0942e-02, -9.7710e-01, -1.1114e-01, -6.2514e-02,\n",
       "            -9.5522e-03, -1.2007e-01, -2.3935e-01, -4.2623e-01, -3.9434e-01,\n",
       "            -3.4826e-02,  1.1540e-01, -2.7367e-01,  2.5685e-01, -5.4526e-01,\n",
       "            -3.2177e-01, -7.6055e-02,  9.2203e-02,  1.5286e-02,  4.3951e-01,\n",
       "            -2.2425e-01, -6.5635e-02, -1.5464e-01,  1.2980e-01, -1.5604e-01,\n",
       "            -2.8130e-01, -1.8242e-01,  2.2019e-01, -1.6714e-02, -1.8093e-01,\n",
       "             7.3154e-02,  3.1560e-01,  3.5625e-02,  3.4869e-01, -3.4608e-02,\n",
       "             5.4266e-03,  1.7296e-01, -1.5248e-01,  1.1350e-01, -5.1065e-01,\n",
       "             5.2762e-04,  3.2375e-01, -2.0122e-01,  8.8666e-02, -1.7469e-01,\n",
       "            -5.3491e-02, -2.6695e-01,  3.6263e-02,  2.1199e-01, -2.2217e-01,\n",
       "             3.2737e-01,  1.3852e-01,  6.4622e-02, -3.0676e-02,  1.5262e-01,\n",
       "            -9.8963e-02, -9.7681e-02,  3.0450e-01,  1.7430e-01, -1.6959e-01,\n",
       "            -2.5342e-01,  3.0638e-02,  2.1068e-02, -2.3585e-01,  5.6874e-01,\n",
       "            -9.4685e-02,  1.8589e-02,  4.8009e-03, -2.1594e-01,  1.3936e-03,\n",
       "            -1.1064e-01, -2.4301e-02, -6.9834e-01,  1.5861e-01,  1.5418e-01,\n",
       "            -1.5551e-02,  7.2738e-02,  3.5317e-01,  1.4635e-01, -3.4457e-01,\n",
       "            -2.6919e-01, -2.1583e-03, -4.4086e-02, -2.8916e-01,  5.1845e-01,\n",
       "             2.2225e-01, -4.5838e-02, -7.7711e-01,  4.3453e-01, -1.3660e-01,\n",
       "             2.9742e-02, -3.0400e-01, -4.7006e-01,  2.0129e-02,  4.1128e-01,\n",
       "             3.5821e-01, -4.1246e-01, -1.8462e-01,  5.0308e-01, -3.4125e-01,\n",
       "            -4.9836e-01, -8.1295e-01,  3.5106e-01,  4.1607e-01,  8.6006e-02,\n",
       "            -7.8437e-01,  1.5836e-01, -3.4352e-01,  1.6909e-01, -1.5419e-01,\n",
       "            -1.7514e-01, -1.9667e-01, -1.3541e-01, -1.5515e-01, -7.0289e-01,\n",
       "             5.8103e-02,  1.5523e-01, -5.2696e-01,  1.2529e-01,  2.1384e-01,\n",
       "             6.5886e-01, -7.4298e-02,  1.8866e-01, -3.4123e-02,  2.5443e-01,\n",
       "            -8.6387e-02,  4.3965e-01,  6.4339e-02,  1.8569e-01, -7.0401e-01,\n",
       "             2.3886e-01,  4.0264e-01, -4.0907e-01, -2.7325e-01, -1.4859e-01,\n",
       "             5.6757e-01, -2.1631e-01, -1.1699e-01, -3.7955e-02,  1.5591e-01,\n",
       "            -5.8620e-02,  3.3804e-01,  8.0703e-03,  1.6631e-01,  4.2959e-02,\n",
       "            -9.0288e-02,  3.0449e-01,  3.1481e-01,  1.7755e-01,  1.4714e-01,\n",
       "            -3.1154e-01,  3.4905e-01,  6.0906e-03, -4.9672e-01,  6.3420e-01,\n",
       "            -2.1838e-04, -3.5651e-01, -8.9090e-02,  8.7360e-02, -4.2958e-01,\n",
       "             1.2856e-01,  1.7059e-01, -4.9579e-01,  9.2284e-02,  1.1475e-01,\n",
       "            -4.9711e-02, -7.5457e-02,  1.9773e-01, -2.1585e-01, -1.0040e-01,\n",
       "            -2.8348e-01, -4.0153e-01,  5.1367e-02, -5.3939e-02,  1.4258e-01,\n",
       "            -1.4165e-01, -4.0245e-01, -2.3156e-01,  3.7846e-02, -4.0567e-02,\n",
       "             1.3815e-01,  2.1576e-01,  4.3939e-01,  4.6565e-02,  3.3664e-01,\n",
       "            -2.4410e-01,  2.2003e-01, -8.9645e-02, -2.2242e-01,  2.7574e-02,\n",
       "            -1.6176e-01,  1.9367e-01, -1.5215e-01,  1.3187e-01,  6.2043e-03,\n",
       "            -1.3449e-01, -4.6303e-01, -6.6910e-02,  1.7710e-02,  6.9240e-02,\n",
       "            -2.4827e-01,  3.2962e-01,  7.3832e-02,  1.0736e-01, -1.6343e-02,\n",
       "             1.4566e-01, -7.3343e-02,  5.0226e-01,  1.0516e-01, -6.8177e-01,\n",
       "            -7.6349e-01,  2.5587e-02, -3.1456e-02, -2.9986e-01,  1.5411e-01,\n",
       "             1.6234e-01,  8.1120e-02,  2.7369e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,\n",
       "               15,   754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,\n",
       "             6485,   275, 12604,   366,     0]])),\n",
       "  (tensor([[-4.6108e-01,  2.6165e-01,  1.4746e-01,  3.8407e-01,  2.0403e-01,\n",
       "            -2.3351e-01, -3.2911e-01,  1.0043e-01,  1.7183e-01,  1.6041e-02,\n",
       "            -2.7366e-01,  5.3928e-01,  2.6007e-01, -2.3750e-01,  2.6611e-01,\n",
       "             1.3586e-01,  1.0412e-01, -7.0307e-01, -3.0345e-01,  1.1347e-01,\n",
       "            -3.1314e-01,  2.7725e-02, -5.4848e-01,  1.3109e-01, -9.6438e-02,\n",
       "            -1.0528e-01,  1.8106e-01, -3.0622e-01, -2.9615e-01,  1.2000e-01,\n",
       "            -5.7601e-02, -2.2961e-01, -1.8506e-01,  3.3791e-01,  6.3132e-01,\n",
       "             9.5961e-02,  8.5513e-02, -3.8876e-02, -2.3199e-01, -1.0848e-01,\n",
       "            -8.9724e-02,  2.8235e-01,  1.6688e-01,  2.0685e-01, -2.4676e-01,\n",
       "             5.2216e-01, -2.3799e-01, -4.8478e-02,  2.0023e-01, -1.9212e-01,\n",
       "             4.2710e-01, -7.3946e-02, -8.7244e-02, -1.4218e-02,  1.3686e-01,\n",
       "            -8.4670e-02,  3.6480e-01,  3.4269e-01,  1.1989e-01, -2.8480e-01,\n",
       "             4.4970e-03,  1.7436e-01, -9.8883e-02, -2.2353e-02,  3.1716e-01,\n",
       "             4.1393e-01, -2.1690e-03, -7.9675e-02,  1.7218e-01, -1.6445e-01,\n",
       "             1.0645e-01,  2.6561e-01,  1.8206e-01,  1.2914e-01, -2.7936e-02,\n",
       "            -1.0092e-01, -2.6666e-01, -1.6084e-01, -4.3600e-01,  2.9288e-01,\n",
       "             1.5059e-01, -1.9002e-02, -4.9570e-02, -7.1768e-03, -1.7810e-01,\n",
       "             1.2924e-01,  1.1140e-01, -3.2264e-01,  3.3005e-01, -2.3096e-01,\n",
       "             3.0905e-01, -8.8132e-02, -8.0060e-03,  1.0119e-02, -2.6586e-01,\n",
       "             4.3302e-02,  2.1351e-02, -3.9988e-01, -1.3496e-01, -8.8171e-02,\n",
       "            -2.0107e-01, -2.6450e-01, -5.3692e-01,  1.1789e-02, -1.5523e-01,\n",
       "             1.4721e-01, -8.9313e-02,  3.5626e-02, -5.5821e-02,  6.6962e-02,\n",
       "            -1.6060e-01,  1.3688e-01, -1.7005e-01,  1.2753e-01, -1.0829e-01,\n",
       "            -8.3931e-03, -7.1484e-02,  4.9965e-01, -1.8256e-01,  1.1799e-01,\n",
       "             2.0897e-02,  8.4525e-02, -1.5593e-01,  1.0346e-01, -3.5374e-01,\n",
       "             2.1775e-01,  3.7187e-01,  1.0187e-01,  1.3686e-01,  3.9509e-02,\n",
       "             1.8925e-01, -8.9046e-02,  4.6245e-02, -1.3953e-01,  4.0694e-01,\n",
       "            -5.1581e-02,  8.4368e-02,  4.2267e-02, -2.4774e-01,  2.4451e-01,\n",
       "             3.9363e-02,  4.0448e-01,  2.2249e-01, -2.0747e-02, -5.0792e-01,\n",
       "             7.2001e-02,  3.4000e-01, -2.1552e-01, -2.7158e-03, -1.4109e-01,\n",
       "             3.0844e-02,  5.1083e-02,  1.4245e-01, -1.6295e-01, -3.4341e-01,\n",
       "            -2.3137e-01, -2.3953e-01, -1.2575e-01,  2.1794e-01, -3.5335e-02,\n",
       "             5.7555e-02, -1.5172e-01, -1.3798e-01,  3.8599e-02,  2.8350e-02,\n",
       "             2.2158e-01,  4.3997e-01, -3.0119e-01, -2.8238e-02,  2.3102e-01,\n",
       "            -1.6217e-01,  5.1407e-02, -3.1030e-01, -9.9053e-03, -6.8788e-02,\n",
       "            -5.7429e-02, -5.0203e-03,  1.0988e-01,  1.2414e-02, -2.5546e-01,\n",
       "            -3.1297e-02,  7.2061e-02, -1.5020e-01, -1.9056e-01, -9.7005e-02,\n",
       "            -7.7556e-02, -1.6293e-01,  2.4245e-02, -9.1059e-02, -4.5735e-02,\n",
       "             4.2539e-01, -2.4273e-01,  5.4312e-01,  5.6860e-02, -2.5529e-01,\n",
       "             7.6803e-02,  2.6560e-01,  1.3901e-01, -7.5683e-02, -2.1975e-01,\n",
       "             3.0402e-01, -5.6357e-02, -3.7797e-02,  5.3771e-01, -1.0543e-01,\n",
       "             1.0382e-01,  3.3945e-02, -2.4843e-01, -4.6278e-02,  1.0633e-01,\n",
       "             2.1287e-01, -4.1056e-02, -2.1355e-01,  8.3049e-02, -1.2005e-01,\n",
       "            -4.5470e-01, -1.5717e-01, -4.6193e-02,  1.6978e-02,  8.9131e-02,\n",
       "            -1.0754e-01, -3.4432e-01,  4.4802e-02, -1.9575e-01, -8.5591e-02,\n",
       "             6.0784e-02,  2.8075e-01, -7.2849e-02,  2.9553e-01,  1.9853e-01,\n",
       "             2.5555e-01,  3.2962e-02, -1.7587e-01,  1.0519e-02, -2.2458e-01,\n",
       "            -2.6209e-01, -2.1356e-02,  4.6289e-02, -1.5410e-01, -8.1174e-02,\n",
       "             3.7635e-01,  2.0229e-01, -9.7093e-02, -9.4636e-03, -1.5437e-01,\n",
       "            -1.7845e-01,  5.0582e-02,  1.6941e-01,  7.1094e-02, -7.5231e-02,\n",
       "             8.5171e-02,  3.5424e-02, -5.3075e-01, -2.7267e-01, -1.4616e-01,\n",
       "            -3.6779e-01,  1.7836e-01,  2.1701e-01,  7.9440e-02, -1.3033e-01,\n",
       "            -2.3897e-01,  1.8781e-01,  4.7852e-02,  7.1524e-02,  2.4297e-01,\n",
       "            -3.7946e-02, -2.0837e-01,  4.1788e-01,  2.7618e-01, -1.3065e-01,\n",
       "             2.8679e-02, -1.0903e-01, -1.2175e-01, -1.4250e-01,  3.2285e-01,\n",
       "            -5.4410e-02,  2.3422e-02, -9.8843e-03, -1.4617e-01, -1.1285e-01,\n",
       "            -3.9169e-01,  4.0044e-03,  1.9025e-02,  1.0926e-02,  2.7233e-01,\n",
       "            -1.6371e-01, -5.0815e-01, -4.9460e-01, -1.3873e-01, -6.5495e-02,\n",
       "             2.3267e-02,  9.6027e-02,  1.5544e-01, -3.2074e-01,  4.0446e-01,\n",
       "            -3.8858e-01, -1.2044e-01,  1.0726e-01,  2.7493e-02, -9.1024e-02,\n",
       "            -3.2192e-01, -2.9087e-01, -7.0171e-02, -1.0203e-01,  1.0951e-01,\n",
       "            -2.0527e-01,  2.0376e-02, -1.6676e-01, -1.6817e-02, -1.0394e-01,\n",
       "            -3.6082e-02,  4.0347e-01, -1.3416e-01,  1.5379e-01,  2.2655e-01,\n",
       "            -3.0642e-01, -3.1519e-01,  2.0863e-01, -6.2414e-02, -3.4051e-01,\n",
       "             1.7896e-01, -2.7382e-01, -7.1423e-02, -7.0864e-02, -7.4389e-02,\n",
       "            -2.3689e-01,  9.8530e-03,  2.8205e-02, -2.1129e-01,  2.2936e-01,\n",
       "            -1.1559e-01,  1.8029e-01, -3.7482e-02, -2.0289e-02, -1.9123e-01,\n",
       "             2.0046e-01, -2.4004e-02, -3.3263e-02,  1.3368e-01,  1.0775e-01,\n",
       "            -9.3491e-02, -3.6514e-02, -1.3281e-01,  1.5816e-01,  1.4450e-01,\n",
       "             2.0155e-01,  1.4942e-01,  4.6086e-01, -4.2605e-02, -1.1202e-02,\n",
       "             3.1918e-01, -3.3099e-01,  1.2952e-01, -2.7441e-02, -1.5370e-01,\n",
       "             2.6587e-01, -1.6296e-01, -1.5171e-02, -8.2927e-02,  3.5197e-01,\n",
       "            -1.2067e-01,  6.3056e-02,  2.2734e-01, -5.4069e-02,  7.8861e-02,\n",
       "            -5.4043e-02, -5.1905e-01, -1.3128e-01, -4.1952e-01, -2.9015e-01,\n",
       "             1.5137e-02, -7.6108e-02,  1.0425e-01,  8.4918e-02, -1.8799e-01,\n",
       "             1.8926e-01,  9.1588e-02,  2.1269e-01, -1.0296e-01,  1.9173e-01,\n",
       "             1.2325e-01,  8.5494e-02, -2.0202e-01, -4.9914e-01,  2.6728e-01,\n",
       "             3.4686e-01,  5.8429e-01, -1.2609e-01,  1.3036e-01,  1.9521e-01,\n",
       "            -1.0038e-01,  5.9893e-01, -3.0545e-01,  3.6155e-01, -2.9419e-02,\n",
       "             2.0982e-01, -1.8257e-01,  1.2124e-01,  3.6587e-01,  1.8915e-01,\n",
       "             8.7863e-02, -7.5372e-01,  1.1895e-01, -1.9749e-01,  3.8245e-02,\n",
       "             1.7602e-01, -1.7930e-02,  2.2325e-01,  3.7894e-02, -5.9379e-03,\n",
       "            -6.3094e-01,  1.4432e-01,  1.1617e-01,  6.9499e-02,  1.4292e-01,\n",
       "             5.5086e-01, -7.0019e-02,  2.1132e-01,  6.1083e-01,  1.9638e-02,\n",
       "             3.2420e-02,  3.1266e-02, -1.3911e-01, -5.1489e-02, -2.0478e-02,\n",
       "            -1.9913e-01, -2.2468e-02,  5.1395e-01, -3.3284e-01,  2.3779e-02,\n",
       "            -2.0870e-01, -4.3080e-01, -7.4678e-02,  6.1364e-02,  2.3960e-01,\n",
       "             2.4116e-01,  2.2083e-01,  1.9659e-01, -2.6836e-01, -2.0741e-01,\n",
       "            -2.6798e-01,  2.7234e-01,  3.2777e-01,  2.2856e-01, -3.0757e-02,\n",
       "             1.2767e-01, -5.8619e-01,  5.2828e-02, -4.1008e-01, -2.1674e-01,\n",
       "             1.3541e-01, -2.1309e-01,  4.4891e-01,  3.9071e-01,  3.7226e-01,\n",
       "             3.9966e-01, -9.8729e-02, -1.9474e-01, -1.8867e-01,  8.1306e-02,\n",
       "            -1.4043e-01,  1.6375e-01,  2.8440e-01,  2.2314e-02, -3.3873e-01,\n",
       "             1.2632e-01,  4.2292e-01,  1.7922e-01, -3.0640e-01,  5.4772e-02,\n",
       "            -4.0922e-01, -8.4275e-02, -3.1301e-03,  5.3103e-01,  3.3225e-01,\n",
       "             3.5914e-01, -3.0569e-01, -2.3004e-01, -1.3517e-01,  1.3205e-01,\n",
       "             2.7243e-01, -1.1655e-01, -5.0550e-02,  2.0076e-01,  1.5704e-01,\n",
       "            -4.0752e-01,  1.8961e-02,  4.8057e-02,  3.3936e-01, -4.4877e-01,\n",
       "             3.2923e-01,  1.3249e-01,  5.6668e-01, -1.7766e-01, -6.8820e-02,\n",
       "             4.9641e-01, -1.8645e-01,  1.6912e-01,  2.1387e-01, -1.4819e-01,\n",
       "            -2.8531e-01,  2.1562e-01, -4.8067e-01,  4.2225e-01, -1.6872e-01,\n",
       "             5.0096e-02, -1.4621e-01, -9.0640e-02,  5.1916e-02, -1.3927e-01,\n",
       "             3.5071e-02, -2.4915e-01, -2.1451e-01, -4.7235e-01, -1.3673e-01,\n",
       "             2.6989e-01, -4.6271e-03,  2.1781e-02, -1.8030e-02, -2.1579e-01,\n",
       "             1.5736e-01,  2.1482e-01, -6.5247e-02,  5.8969e-02, -1.4394e-03,\n",
       "             1.5242e-01, -3.6691e-02, -4.1233e-01,  7.3760e-01, -2.3234e-01,\n",
       "            -1.6699e-01, -2.9170e-01, -2.0191e-01,  1.4179e-01, -4.6233e-02,\n",
       "            -2.0074e-01, -1.2459e-01,  6.6678e-03,  5.1929e-01,  2.8116e-01,\n",
       "            -3.8551e-01, -2.5458e-01,  4.4075e-01, -1.9122e-01,  1.5575e-01,\n",
       "            -4.4804e-01, -3.4001e-01,  7.4948e-02,  4.0821e-01, -5.2328e-01,\n",
       "            -7.2624e-01, -1.9794e-02, -7.7270e-01, -1.6805e-01, -1.2664e-01,\n",
       "            -5.8639e-02,  4.4560e-02, -2.3467e-01, -2.4175e-01, -3.1807e-01,\n",
       "             5.3482e-01, -2.5287e-01, -1.3691e-01, -1.2290e-01, -3.7672e-01,\n",
       "            -1.6119e-01, -3.3488e-01, -2.2180e-03, -3.3098e-01,  5.1495e-01,\n",
       "            -3.7210e-03, -6.8391e-02, -6.6220e-02,  3.2554e-01,  1.9360e-02,\n",
       "            -4.2555e-01, -1.1947e-01, -3.0673e-02, -3.3993e-01, -1.0372e-01,\n",
       "             9.0856e-02,  6.5788e-01,  2.8059e-01,  8.0216e-02, -3.0936e-01,\n",
       "            -1.9322e-01, -4.6750e-01, -9.1182e-02, -6.6819e-02, -7.9249e-02,\n",
       "             4.7472e-01,  6.2605e-02, -3.7482e-02,  1.0218e-01, -5.0033e-01,\n",
       "            -2.3809e-01,  7.0525e-02, -1.1279e-01, -1.8723e-01, -4.7337e-01,\n",
       "             2.3276e-01,  4.4802e-01, -1.2834e-03, -2.0012e-01, -7.5822e-02,\n",
       "            -3.7430e-01,  2.6135e-01, -4.3485e-02,  4.6467e-02, -2.5240e-01,\n",
       "            -1.0295e-01, -4.2532e-02,  3.0149e-01, -1.4610e-02,  4.7020e-01,\n",
       "            -2.5501e-01,  5.5887e-01, -1.7554e-01,  4.3027e-02, -2.8673e-01,\n",
       "             2.6710e-01, -1.6639e-01, -4.8503e-01,  4.7514e-01, -3.3664e-01,\n",
       "             3.6158e-02, -1.4140e-01,  1.5897e-01,  3.9903e-01, -4.1545e-01,\n",
       "             1.5295e-02, -1.0815e-01, -3.6599e-01, -2.9858e-01, -2.7965e-02,\n",
       "             2.3686e-01, -2.5404e-01, -6.5180e-01, -1.9082e-01,  2.8820e-02,\n",
       "             1.7885e-01, -2.7896e-01, -7.0760e-02,  1.7402e-02,  4.4542e-01,\n",
       "             3.9147e-01, -2.5756e-02, -1.0521e-01,  5.3125e-01, -2.2071e-01,\n",
       "            -3.1243e-01, -1.5564e-01,  2.0088e-01,  1.4745e-01,  4.9431e-02,\n",
       "            -7.2987e-01, -2.9203e-01,  3.7716e-01,  3.7019e-01, -3.9116e-01,\n",
       "            -2.1434e-01, -1.9165e-01, -2.5853e-01, -2.5747e-01, -3.0559e-01,\n",
       "             2.1211e-01, -1.3347e-01, -1.7995e-01,  5.1149e-01, -3.1870e-01,\n",
       "             2.6294e-01, -3.1161e-01,  2.4129e-01, -3.3487e-01,  6.2527e-02,\n",
       "            -1.9277e-01,  6.3001e-01, -2.2814e-02,  1.7099e-01, -9.0063e-01,\n",
       "            -2.0946e-01,  1.9574e-01, -1.6697e-01, -1.8522e-01, -3.5586e-01,\n",
       "             2.0396e-01, -6.9959e-02,  2.5057e-02, -9.2898e-02,  3.9406e-01,\n",
       "            -2.1088e-01,  1.7876e-01, -9.4605e-02,  1.3116e-01,  3.5236e-01,\n",
       "             3.9201e-02,  3.5702e-01, -1.0958e-01, -3.3108e-02,  5.5065e-01,\n",
       "            -4.1040e-01,  6.3012e-01,  2.5725e-01,  1.8420e-01,  3.2614e-01,\n",
       "            -2.5359e-01, -4.1830e-01, -1.0140e-02,  8.4118e-02,  1.9695e-02,\n",
       "             1.5610e-01,  2.0414e-01, -5.2044e-01,  3.5543e-01, -1.0060e-01,\n",
       "             1.4207e-02, -3.3196e-01, -8.1871e-02, -2.7800e-01,  3.0193e-02,\n",
       "             7.5985e-02, -2.3454e-01, -8.9969e-02,  2.9161e-01,  5.6138e-01,\n",
       "            -2.3093e-01, -6.0574e-01, -5.1550e-01,  1.5567e-01,  1.9489e-01,\n",
       "             1.7379e-01,  4.5683e-01,  3.2647e-01, -2.8620e-01,  2.9535e-01,\n",
       "            -9.6397e-02,  2.9966e-01, -2.9440e-01,  6.0159e-02,  3.4382e-01,\n",
       "             5.4781e-02, -1.5130e-01, -1.4954e-01,  9.9064e-02, -1.6282e-01,\n",
       "             1.5418e-01, -1.5493e-02, -2.6459e-01, -1.5442e-02, -2.7683e-01,\n",
       "            -3.8632e-01,  2.0349e-01,  2.3673e-02,  6.1002e-04, -1.2334e-01,\n",
       "            -4.3784e-02,  3.8354e-01,  3.9623e-01,  4.0025e-02, -2.3662e-01,\n",
       "            -2.5128e-01,  1.2180e-01, -3.5073e-01,  8.9468e-05,  1.8678e-01,\n",
       "            -4.8329e-01,  2.3966e-01,  6.0307e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  2374, 11161,    13,  5171,   369,  5686,\n",
       "              275,  4693,    15,   754,   310,   655,  1107,  1711,    15,  5171,\n",
       "              310,   271,  6485,   275, 13814,     0]])),\n",
       "  (tensor([[-4.1190e-01,  8.7659e-02,  3.9218e-03, -1.0799e-01,  3.0993e-03,\n",
       "            -8.9712e-02, -3.9883e-01,  5.3427e-02,  2.5505e-01, -1.1292e-01,\n",
       "            -3.2889e-01,  2.3688e-01,  3.9659e-01, -1.4210e-01, -3.7566e-02,\n",
       "             7.2423e-02, -1.3990e-01,  3.1435e-02, -1.4538e-01,  2.6123e-01,\n",
       "            -4.3451e-02, -6.3839e-02, -5.9183e-01,  5.1635e-02, -1.2754e-02,\n",
       "             2.0816e-01, -1.1460e-01, -2.6682e-01, -3.8523e-01, -2.1983e-01,\n",
       "            -1.7218e-02, -7.0867e-02, -1.3101e-01,  2.5708e-01,  4.1516e-01,\n",
       "            -9.4861e-02, -2.0168e-01, -8.4338e-02, -3.3567e-01,  9.4471e-02,\n",
       "            -7.1953e-02,  7.4952e-02,  3.4067e-01,  1.3615e-01, -4.8031e-01,\n",
       "             1.3456e-01,  4.7582e-02, -1.3223e-01,  2.0530e-02, -4.1100e-01,\n",
       "             2.2211e-01,  2.2212e-01, -2.6938e-02,  2.0145e-02, -9.4961e-02,\n",
       "            -1.1739e-01,  2.1668e-01, -1.5497e-01,  2.2975e-01, -2.6129e-02,\n",
       "            -2.8976e-01,  2.5694e-01,  9.6086e-02, -2.6323e-01,  2.0002e-01,\n",
       "             1.5165e-01, -1.0144e-01,  1.0053e-01, -1.0738e-01, -4.2008e-01,\n",
       "             2.3112e-01,  7.8381e-02, -3.6535e-03,  5.8883e-02,  1.3237e-01,\n",
       "            -3.8009e-01, -5.6912e-02,  5.0439e-02, -1.8939e-01,  1.7445e-01,\n",
       "            -3.4837e-01,  4.0136e-02, -3.4043e-02, -2.0330e-01, -2.8940e-01,\n",
       "             1.6855e-01,  2.4455e-01, -1.7962e-01,  3.2138e-01, -2.8059e-01,\n",
       "             3.3650e-01, -1.4996e-01,  2.0181e-01, -2.3594e-01,  1.0185e-01,\n",
       "             6.1982e-03, -6.8055e-02, -3.8439e-01, -1.7444e-01, -3.1904e-01,\n",
       "            -3.0945e-01, -2.8967e-01, -1.9165e-01, -1.0016e-01,  3.4989e-02,\n",
       "             3.3904e-01, -1.7321e-01,  2.0512e-01,  5.8400e-02,  1.3721e-01,\n",
       "             8.2410e-02,  3.1310e-01, -5.5422e-02,  1.5137e-01, -2.5835e-02,\n",
       "             2.2465e-02, -1.9593e-01,  3.4879e-01, -3.3480e-02, -3.5986e-02,\n",
       "             2.0265e-01,  3.0582e-01, -1.2523e-01,  3.2674e-01, -7.3789e-02,\n",
       "             1.4513e-01,  5.3266e-01, -2.6291e-01, -2.0782e-01, -9.4172e-02,\n",
       "             1.5970e-01,  2.3311e-01, -1.6182e-01, -2.8901e-01,  1.2544e-01,\n",
       "            -1.5336e-01, -6.9039e-01, -1.2215e-01, -2.7649e-01, -6.4212e-02,\n",
       "            -9.6367e-02,  9.4220e-02,  1.5754e-01, -1.7285e-01, -4.8588e-01,\n",
       "            -1.0424e-01,  1.6797e-01,  8.9316e-02, -9.7695e-02, -2.0420e-01,\n",
       "            -3.1058e-02, -5.9952e-02,  1.2922e-01, -4.3337e-02, -1.4694e-01,\n",
       "            -7.9656e-02,  1.0723e-01, -2.1878e-01, -1.8998e-02, -2.0219e-02,\n",
       "             5.0550e-02,  2.3437e-02, -3.5744e-01, -5.8407e-02, -7.2867e-02,\n",
       "            -3.1010e-02,  6.4557e-01, -1.4908e-01,  1.6410e-01,  1.6546e-01,\n",
       "            -5.1451e-03,  4.0902e-01, -8.4191e-02,  8.9323e-02, -1.2632e-01,\n",
       "             3.5300e-02, -1.0277e-01, -5.1103e-02, -8.8545e-02, -1.8473e-01,\n",
       "            -2.1907e-01,  1.6532e-02, -1.0007e-01, -3.6876e-01, -2.1668e-01,\n",
       "            -2.2518e-01, -2.2022e-01,  1.6926e-01, -4.3916e-02,  2.4494e-02,\n",
       "             1.1434e-01, -2.2503e-01,  1.9755e-01,  1.7331e-01, -7.6454e-02,\n",
       "             1.2212e-01,  1.8820e-01,  8.5554e-02, -5.2463e-02, -1.5636e-01,\n",
       "             3.7028e-01,  1.8092e-01,  1.5538e-01,  2.7207e-01,  7.4725e-02,\n",
       "             1.9347e-01, -6.2132e-02, -1.8972e-01, -2.6201e-02,  7.0268e-02,\n",
       "             1.8015e-01, -1.4801e-01,  6.3580e-02,  1.3236e-01, -1.5286e-01,\n",
       "            -6.3815e-01, -2.5272e-01,  4.0250e-02, -2.3922e-02,  2.1620e-01,\n",
       "             1.4101e-01, -1.5655e-01,  1.9432e-01, -6.8024e-02, -1.9719e-02,\n",
       "             5.2860e-02,  9.5837e-02, -1.4506e-01,  2.0083e-01,  1.3086e-04,\n",
       "             6.0093e-02, -4.6821e-02, -3.2615e-01, -3.5402e-02, -1.9375e-02,\n",
       "            -4.6398e-02, -2.0183e-01,  1.9999e-01, -4.5152e-02, -3.6490e-02,\n",
       "             3.3264e-02,  1.8782e-01,  1.3264e-01,  2.7616e-02, -2.1191e-01,\n",
       "            -5.5097e-02,  3.2320e-01, -1.6599e-01,  9.5645e-02,  3.8613e-02,\n",
       "             2.4359e-02, -2.3835e-01, -6.0886e-01, -2.4905e-01, -4.9059e-01,\n",
       "            -3.5077e-01,  7.2059e-01,  3.4229e-01,  1.1611e-01,  2.8522e-02,\n",
       "            -1.6986e-01,  1.1052e-01,  2.7023e-02, -3.0511e-01,  4.2092e-01,\n",
       "             1.1982e-01, -2.3413e-01, -6.0163e-02,  1.4378e-01, -1.3944e-01,\n",
       "            -2.6739e-01,  4.0479e-02,  1.7484e-01, -3.0556e-01,  2.7394e-01,\n",
       "            -1.2598e-02, -1.6945e-01, -1.3533e-01, -2.8969e-02,  2.2757e-01,\n",
       "             3.3068e-02, -7.9055e-02,  2.3075e-01, -1.5929e-01,  1.1962e-01,\n",
       "             1.9872e-01, -3.7461e-02, -1.7805e-01, -1.4420e-01, -2.4269e-01,\n",
       "             6.8102e-02, -9.8292e-02,  4.4151e-01, -2.7993e-02,  6.5579e-01,\n",
       "            -2.0773e-01,  2.5243e-01,  1.6163e-01, -1.6182e-01, -9.4474e-02,\n",
       "            -1.2386e-01, -3.4614e-01, -1.8728e-01, -4.2424e-02,  7.6983e-02,\n",
       "            -3.8597e-01,  2.8593e-01, -4.5079e-01, -2.5651e-01,  1.5386e-01,\n",
       "             4.4896e-01,  2.0649e-01, -1.4552e-01, -6.2470e-02,  1.0644e-02,\n",
       "            -2.9025e-01, -2.3959e-01,  1.7228e-01, -1.1546e-01, -2.2055e-01,\n",
       "            -2.5443e-01, -2.4088e-01,  1.4014e-02,  2.5191e-01, -2.2629e-01,\n",
       "            -2.5708e-01,  1.2985e-02,  9.7767e-02, -4.4028e-01,  9.6629e-03,\n",
       "            -5.9425e-02,  1.5937e-01, -7.2419e-02,  5.8294e-03,  3.4574e-02,\n",
       "            -1.2303e-01,  1.9627e-02, -1.5031e-01,  1.0204e-01,  9.0483e-02,\n",
       "             1.2240e-03, -1.4888e-01,  4.2442e-02, -1.3129e-02,  1.5021e-01,\n",
       "             1.8122e-01, -4.5805e-03,  3.3079e-01, -1.8280e-01, -2.7627e-01,\n",
       "             6.3474e-02, -1.6211e-01, -2.2023e-01, -3.1517e-01, -3.2360e-01,\n",
       "             3.3362e-01, -1.2422e-01,  2.4850e-03,  1.3661e-01,  4.3607e-01,\n",
       "            -1.7418e-01, -1.2101e-01,  2.7502e-01, -7.4588e-02, -8.1004e-02,\n",
       "            -7.8991e-02, -1.9333e-01, -2.3143e-01, -3.4241e-01, -1.3433e-01,\n",
       "            -2.0111e-01,  3.7527e-02,  1.0967e-01,  3.9672e-01,  2.7027e-01,\n",
       "             1.3448e-01,  1.3284e-01,  6.0367e-02, -8.4065e-02, -2.9798e-02,\n",
       "            -1.5120e-01,  1.0041e-01, -4.2237e-01, -6.2915e-03,  4.6465e-02,\n",
       "            -1.4533e-01,  3.3448e-01, -3.6223e-01, -1.0988e-01,  8.7285e-02,\n",
       "            -1.4925e-02,  2.4267e-01,  3.4525e-03,  4.6339e-01, -2.7621e-01,\n",
       "             7.0841e-02,  6.9238e-02,  1.6046e-01,  5.8951e-02,  2.6522e-02,\n",
       "             1.1177e-01, -7.0266e-01, -1.9458e-01, -6.9028e-02,  4.2459e-01,\n",
       "            -4.0271e-03,  3.1482e-01,  4.9943e-02,  2.5053e-01, -1.0337e-01,\n",
       "            -2.9096e-01,  3.3707e-02,  9.8218e-03, -9.1419e-02, -3.2675e-01,\n",
       "             1.4165e-01,  1.4886e-01,  6.6062e-01,  5.2602e-01, -3.0607e-01,\n",
       "             1.1608e-01, -1.3682e-01, -1.9261e-01, -1.6816e-01,  1.2202e-01,\n",
       "            -4.0520e-02,  1.1129e-01,  2.0387e-01, -1.1357e-01,  2.2122e-01,\n",
       "             1.1827e-01, -8.4903e-02,  7.0265e-03, -2.1658e-01,  1.8005e-01,\n",
       "             2.9747e-01,  1.7202e-01, -2.2880e-01, -1.6259e-01,  1.6540e-02,\n",
       "            -5.4558e-01,  1.4794e-01,  1.5196e-01,  4.5789e-01,  1.6217e-02,\n",
       "            -1.8272e-01,  1.2150e-01, -2.7501e-01, -1.3980e-01, -2.8254e-01,\n",
       "             9.8076e-03,  5.9021e-02,  4.9853e-01, -9.7299e-02,  1.8523e-01,\n",
       "             5.4070e-02, -1.3695e-01, -2.7693e-01, -3.3282e-01,  3.2457e-01,\n",
       "             4.4104e-01,  1.3265e-01, -1.4695e-02,  2.3339e-01, -2.9849e-01,\n",
       "             1.3571e-01,  7.8071e-02,  9.3591e-02,  9.1578e-02,  2.5842e-02,\n",
       "            -1.8126e-01, -1.3025e-01, -1.4841e-01,  3.2576e-01, -3.4478e-01,\n",
       "             2.5686e-01, -2.6078e-01, -1.0732e+00,  1.1064e-01,  3.1764e-01,\n",
       "            -3.7960e-01,  1.2434e-01, -1.3220e-01,  2.3149e-01,  2.1716e-01,\n",
       "            -1.7360e-02, -4.2420e-02,  7.0161e-02,  1.8282e-01, -1.3665e-02,\n",
       "             1.6382e-01,  3.1395e-01, -1.0402e-01,  1.5472e-01,  5.4233e-01,\n",
       "             7.9694e-01,  3.0870e-02,  3.0180e-01,  1.8419e-01, -5.6891e-01,\n",
       "             2.0977e-02,  2.0534e-01, -2.4779e-01,  6.1801e-01, -3.1453e-01,\n",
       "             9.2645e-02,  3.2509e-01,  4.3582e-01,  1.4122e-01, -4.1862e-01,\n",
       "            -2.7968e-03, -1.9533e-01, -4.3435e-01, -2.2301e-01,  1.2141e-03,\n",
       "             7.7226e-02,  3.9682e-02,  3.2615e-01,  2.0440e-01, -2.7123e-01,\n",
       "             1.5859e-01, -1.8059e-01,  1.7582e-01,  2.9706e-01,  3.6638e-01,\n",
       "            -3.7429e-01,  6.6963e-03, -6.3106e-01,  2.3961e-01, -1.6955e-01,\n",
       "             6.9511e-02, -4.0754e-01, -2.6737e-01, -3.1567e-01,  6.1456e-02,\n",
       "            -1.5749e-01, -1.6105e-01,  7.5750e-02,  3.7914e-01,  2.4679e-01,\n",
       "             1.7203e-01, -3.3712e-01,  2.3887e-01,  1.3977e-01, -5.7717e-01,\n",
       "            -2.7949e-01, -1.2268e-01,  3.6358e-01,  2.5415e-01,  2.2325e-01,\n",
       "            -2.5014e-01,  5.7536e-02, -2.9314e-01, -3.3393e-02, -3.2278e-01,\n",
       "             2.6141e-02,  5.9149e-02, -1.1896e-01, -3.8557e-03, -5.5181e-01,\n",
       "            -2.8917e-01, -4.0484e-01, -1.5783e-01, -3.2075e-01, -1.1975e-02,\n",
       "            -5.9982e-02, -2.2325e-01,  3.3217e-01, -3.1154e-01,  3.9797e-01,\n",
       "             4.3866e-01, -2.4615e-02, -8.9962e-02,  2.4102e-01, -3.7563e-01,\n",
       "            -6.4049e-01, -3.7629e-01,  2.4612e-01,  3.1258e-01,  5.5451e-01,\n",
       "            -1.2170e-01,  4.1537e-01,  2.8197e-01, -2.2064e-05,  2.0169e-01,\n",
       "            -2.8445e-01, -2.3593e-01, -9.2173e-02,  2.1865e-01, -1.6498e-01,\n",
       "            -1.6561e-01, -7.1400e-02, -2.6492e-01,  2.6642e-01, -3.0243e-01,\n",
       "            -3.1008e-01,  3.3326e-01, -2.5681e-01,  8.4238e-02, -3.2068e-01,\n",
       "             1.3819e-01,  2.6039e-01,  2.2412e-01, -1.1578e-01,  3.1369e-01,\n",
       "            -4.0214e-01,  1.0905e-01,  2.9322e-01, -6.9733e-02,  1.9892e-02,\n",
       "            -3.2520e-01,  1.3122e-01, -8.3307e-02, -3.9477e-01,  1.5775e-01,\n",
       "            -2.5597e-01, -1.5242e-01, -4.7611e-01, -1.2633e-01, -6.1445e-02,\n",
       "             1.9899e-01,  2.2244e-01, -3.2183e-01,  5.6979e-01, -2.7563e-01,\n",
       "            -2.5568e-01, -1.9122e-01,  4.3787e-02, -5.3129e-02,  1.7839e-02,\n",
       "             7.3735e-03,  3.1511e-01,  2.6009e-01, -4.9534e-02,  8.5054e-01,\n",
       "             2.3673e-01,  3.0985e-01, -5.6526e-01,  1.5155e-01,  1.0499e-01,\n",
       "             2.7622e-01, -4.9236e-01,  3.4561e-02, -2.9278e-01, -2.9946e-01,\n",
       "             5.1301e-01, -1.9920e-01,  3.5403e-01,  1.1407e-01, -7.1047e-02,\n",
       "            -6.2754e-01, -2.9895e-02, -4.8054e-02,  2.2978e-02,  3.6884e-01,\n",
       "            -5.1848e-02,  5.1407e-02,  4.2760e-01,  1.8629e-01,  3.0078e-01,\n",
       "            -5.9667e-01,  1.8133e-01, -7.2837e-02, -2.7250e-01, -3.6291e-01,\n",
       "             4.8183e-01,  4.9725e-01, -8.1113e-01,  2.8031e-01, -1.2806e-01,\n",
       "             6.8509e-02,  1.4699e-01,  6.2207e-02, -1.3744e-01,  7.6652e-02,\n",
       "             9.0261e-02,  8.2348e-01, -2.2803e-02,  1.4917e-01, -2.8058e-01,\n",
       "            -2.1345e-02,  5.2566e-02, -1.6247e-01, -4.2122e-01, -5.2458e-02,\n",
       "             9.8711e-05, -1.3359e-01, -1.1613e-01,  2.1189e-01,  4.1908e-01,\n",
       "            -3.8028e-01,  4.1725e-01, -3.7867e-01, -5.3568e-02,  1.8412e-01,\n",
       "             1.7048e-01,  1.6911e-01,  8.0744e-02,  6.6542e-02,  5.5482e-01,\n",
       "             1.3675e-01,  7.1789e-02, -4.7105e-02, -5.2416e-01,  2.2129e-01,\n",
       "            -2.1811e-01, -3.0155e-01,  1.3547e-01, -2.3065e-03, -2.6880e-01,\n",
       "            -5.6255e-02, -6.4770e-02, -1.5575e-01, -8.3146e-03,  3.7901e-01,\n",
       "            -4.0273e-01, -1.1651e-02, -2.8517e-01, -2.5972e-01, -2.8836e-01,\n",
       "            -1.6532e-01,  1.3654e-01,  1.3905e-01,  8.5951e-02,  6.2991e-01,\n",
       "            -1.2076e-01, -8.8052e-01, -3.4705e-01,  1.5900e-01,  2.0188e-01,\n",
       "             2.5993e-01,  6.4598e-01,  2.7529e-01, -4.2859e-01,  2.2779e-01,\n",
       "            -2.6804e-02,  1.5673e-02, -5.2319e-01, -1.0014e-01,  1.2068e-01,\n",
       "             1.9207e-01, -1.9293e-01,  1.1677e-01,  6.3304e-02, -1.8762e-02,\n",
       "            -1.4508e-02, -4.1727e-01,  2.7556e-02,  2.6618e-01,  3.6553e-01,\n",
       "            -6.6876e-02,  4.2288e-01, -2.2701e-01,  2.0957e-01, -7.0942e-02,\n",
       "             8.3421e-02,  1.8542e-01,  3.4955e-01,  2.1786e-01, -1.5309e-01,\n",
       "            -3.5828e-01,  1.3938e-01, -1.7541e-01, -3.2165e-03, -1.9502e-01,\n",
       "            -5.3150e-02,  3.1805e-01,  5.7603e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,\n",
       "              443, 28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,\n",
       "             3153,   275,  7785,    15,   309,   717,   271,  6485,   275, 34619,\n",
       "                0]])),\n",
       "  (tensor([[-0.1724,  0.2113,  0.1216,  0.1398, -0.1457, -0.1352,  0.2104, -0.1043,\n",
       "            -0.2765, -0.0465, -0.0895, -0.0048,  0.5437,  0.1928,  0.7745, -0.1600,\n",
       "             0.2837, -0.4297,  0.3196, -0.1527, -0.2074,  0.0450, -0.3591,  0.5640,\n",
       "             0.4786, -0.0242, -0.1241, -0.0980,  0.1051, -0.2700,  0.1054,  0.3037,\n",
       "            -0.1535, -0.3444, -0.2435,  0.1462, -0.2726, -0.3352, -0.3462,  0.0563,\n",
       "             0.0017,  0.0728,  0.4106, -0.0451, -0.1755,  0.1070,  0.3050,  0.0439,\n",
       "            -0.3232, -0.4582, -0.5267, -0.1880,  0.1636,  0.0234, -0.1723,  0.0986,\n",
       "            -0.2083,  0.1800,  0.2327, -0.1657,  0.1150,  0.2787, -0.0266, -0.0271,\n",
       "             0.2659, -0.0111,  0.0110, -0.2100,  0.0251, -0.3497,  0.4480, -0.1831,\n",
       "             0.2505,  0.1114, -0.1554, -0.2343,  0.0919,  0.0306, -0.0028,  0.0824,\n",
       "            -0.0751, -0.0593, -0.3991, -0.4171, -0.0882, -0.0048, -0.0177, -0.3594,\n",
       "             0.4359, -0.3284, -0.1783, -0.2750, -0.1280,  0.1643,  0.0625, -0.1588,\n",
       "            -0.1846, -0.3132,  0.0391, -0.1974, -0.0119, -0.0351,  0.1089, -0.0635,\n",
       "            -0.0755,  0.3079, -0.0778, -0.2821, -0.0999,  0.0286, -0.0312, -0.0723,\n",
       "             0.0654,  0.3401,  0.0079, -0.0792,  0.0470,  0.0676, -0.0225, -0.4708,\n",
       "            -0.0384,  0.1331,  0.0353,  0.2211,  0.0624, -0.4913, -0.2495, -0.2079,\n",
       "             0.0252, -0.0232,  0.4125,  0.0522, -0.4895,  0.2031,  0.5522,  0.1271,\n",
       "             0.1467,  0.1668,  0.0081, -0.2680, -0.2158,  0.1785,  0.2299, -0.0877,\n",
       "             0.2840,  0.0588,  0.0529, -0.2082, -0.0094,  0.2597,  0.3988,  0.1965,\n",
       "             0.3185, -0.4913, -0.1449,  0.3313, -0.1086, -0.1914,  0.2696, -0.0790,\n",
       "            -0.0255,  0.7089, -0.2042,  0.4119, -0.0422,  0.2116,  0.2720,  0.0067,\n",
       "            -0.0344, -0.2124, -0.4317,  0.2472,  0.1744,  0.1990, -0.1531, -0.3378,\n",
       "            -0.0339, -0.1421,  0.1219,  0.3993, -0.1668,  0.1319,  0.2776, -0.0089,\n",
       "            -0.1880,  0.1675, -0.1672, -0.1508, -0.4918, -0.0153, -0.0036,  0.2349,\n",
       "             0.4796, -0.1073,  0.0640,  0.1906,  0.1331, -0.3400, -0.0021,  0.2760,\n",
       "             0.1310, -0.1557, -0.2133, -0.1683, -0.2176,  0.5727, -0.0439,  0.1200,\n",
       "            -0.1130, -0.2525, -0.0090, -0.0199,  0.2117,  0.3349, -0.0306, -0.4822,\n",
       "             0.0188, -0.5810,  0.0194,  0.1357, -0.2205,  0.0523,  0.0113, -0.1871,\n",
       "            -0.0839, -0.0863, -0.2337, -0.1352,  0.0694,  0.3596,  0.6321, -0.2122,\n",
       "             0.0324, -0.1083,  0.2882, -0.1998,  0.1936, -0.0640,  0.1008, -0.1083,\n",
       "             0.0997, -0.1460, -0.0071,  0.2459, -0.1171, -0.3097,  0.0902,  0.0666,\n",
       "             0.2204,  0.3874, -0.0776, -0.0163, -0.0242, -0.2878, -0.2903, -0.1117,\n",
       "             0.3049, -0.0639,  0.1560,  0.0332, -0.0356,  0.0898,  0.1045, -0.1226,\n",
       "             0.3180, -0.1944, -0.4698, -0.0233, -0.1592, -0.0326,  0.2877,  0.0273,\n",
       "             0.0925, -0.1159,  0.4961, -0.3373,  0.2899, -0.2160,  0.0134, -0.0216,\n",
       "            -0.5210, -0.1465, -0.2814,  0.3812, -0.2222,  0.1747, -0.1385,  0.3653,\n",
       "            -0.0168,  0.0607, -0.1964,  0.3262, -0.0011, -0.5671,  0.0578, -0.3303,\n",
       "            -0.0139,  0.0648,  0.1540, -0.2039, -0.0658, -0.2750,  0.2054, -0.0476,\n",
       "             0.0649, -0.0690,  0.6656, -0.2889,  0.2359,  0.1469,  0.6558, -0.2400,\n",
       "            -0.1399,  0.4177,  0.0423,  0.0645, -0.0047, -0.3430,  0.2264,  0.2410,\n",
       "             0.3286, -0.2039,  0.0169, -0.1120, -0.0824, -0.1020, -0.4149,  0.3583,\n",
       "            -0.1907,  0.0088,  0.1521,  0.0110, -0.3756,  0.0977, -0.2330,  0.4560,\n",
       "            -0.0508,  0.1263,  0.3211, -0.3810, -0.3889,  0.0457,  0.0631, -0.0178,\n",
       "            -0.4095, -0.0355,  0.0830,  0.3700,  0.0642,  0.1811, -0.0082,  0.0654,\n",
       "             0.2104, -0.0648,  0.0071,  0.0376, -0.4480,  0.0427, -0.0124,  0.1232,\n",
       "            -0.1169, -0.1138, -0.0386,  0.0827, -0.0695, -0.5838,  0.0526, -0.0141,\n",
       "             0.1398, -0.2007, -0.0065, -0.1391, -0.1147, -0.2227, -0.1023,  0.4502,\n",
       "             0.4499,  0.0910,  0.1872, -0.0433, -0.3001,  0.1247,  0.1289, -0.2046,\n",
       "            -0.0358,  0.2737,  0.4182, -0.6856, -0.0482, -0.2683, -0.4391,  0.3515,\n",
       "             0.3010,  0.3699, -0.2060,  0.2351, -0.1435,  0.1283,  0.4221,  0.2807,\n",
       "             0.1457, -0.7321, -0.1926,  0.2137, -0.2898, -0.0471, -0.0131,  0.4174,\n",
       "            -0.3649,  0.3496, -0.3807, -0.4621, -0.0586, -0.2971, -0.3525,  0.0298,\n",
       "             0.0225, -0.0088, -0.1887, -0.1430, -0.3986,  0.1589,  0.1071,  0.1797,\n",
       "             0.2972,  0.3563,  0.1818,  0.0046, -0.2606, -0.3719,  0.0802,  0.0267,\n",
       "             0.1616, -0.4863,  0.5871,  0.2613,  0.0131,  0.6026, -0.3883,  0.3402,\n",
       "            -0.0566,  0.3178,  0.0226, -0.1322,  0.4162, -0.3662,  0.2824, -0.5412,\n",
       "            -0.1895, -0.2508, -0.1946, -0.2258, -0.2895, -0.1443,  0.1586, -0.0369,\n",
       "            -0.0590,  0.2694,  0.4433,  0.2249,  0.1451, -0.3686, -0.1427,  0.1129,\n",
       "            -0.0951,  0.2549,  0.3974,  0.0851,  0.1768,  0.0606,  0.1355,  0.0621,\n",
       "             0.0633,  0.0783,  0.0379,  0.6093, -0.0228, -0.3792,  0.2535, -0.0492,\n",
       "            -0.1205,  0.1759,  0.0245, -0.0387, -0.1580, -0.1011,  0.1957,  0.2346,\n",
       "            -0.5439,  0.0065, -0.1793,  0.1649,  0.0249, -0.2299, -0.2828, -0.1300,\n",
       "            -0.3582, -0.0036,  0.0846,  0.3201, -0.3475,  0.2325,  0.0841, -0.2813,\n",
       "            -0.4419,  0.2799,  0.0474,  0.3838, -0.2605,  0.1005,  0.0502, -0.1657,\n",
       "            -0.2923, -0.0595,  0.0807, -0.0878, -0.1343, -0.0149,  0.1633,  0.0010,\n",
       "             0.2423,  0.1533,  0.0184, -0.7904, -0.6524, -0.2097, -0.3008, -0.1285,\n",
       "            -0.1627,  0.2745, -0.5932, -0.2054, -0.0633, -0.0204, -0.0113,  0.1767,\n",
       "             0.0282, -0.5281,  0.2673, -0.4578, -0.2609,  0.3364, -0.4504, -0.2798,\n",
       "            -0.1259, -0.2773, -0.0469, -0.4588,  0.2975,  0.0534,  0.0849,  0.4670,\n",
       "             0.1540, -0.3011, -0.5444, -0.2623,  0.3078, -0.0354,  0.1202, -0.0637,\n",
       "             0.0939, -0.0744, -0.0098, -0.5484,  0.1260,  0.1238,  0.0680, -0.0807,\n",
       "            -0.2416,  0.0553,  0.2188,  0.1140,  0.3850, -0.1153, -0.0122, -0.1510,\n",
       "             0.0087, -0.0863, -0.0566, -0.2371,  0.5177,  0.0769, -0.2931,  0.1147,\n",
       "             0.7786, -0.1142, -0.3640,  0.3126,  0.1712,  0.0383, -0.6603,  0.3781,\n",
       "             0.2462,  0.3065, -0.1278,  0.3828, -0.1028, -0.1864,  0.5180, -0.3325,\n",
       "            -0.4179,  0.0039, -0.0369,  0.2212,  0.0650, -0.0157, -0.2575, -0.0674,\n",
       "             0.1267,  0.1218,  0.0893,  0.2197,  0.3674,  0.2351, -0.1759, -0.1408,\n",
       "            -0.0970, -0.2923,  0.1370, -0.4285,  0.0728,  0.0693, -0.2227, -0.0341,\n",
       "            -0.2090, -0.2686, -0.2549, -0.2130,  0.0321,  0.1500, -0.0487,  0.2716,\n",
       "             0.4459, -0.2176, -0.0363,  0.1460,  0.5675, -0.2197,  0.1174, -0.2542,\n",
       "             0.0538,  0.2403,  0.1136,  0.0858,  0.7161, -0.2173, -0.4276, -0.1241,\n",
       "            -0.0740,  0.1019,  0.0522,  0.3829,  0.2741,  0.2178,  0.0098,  0.0677,\n",
       "            -0.1840,  0.0672, -0.5893,  0.1545,  0.0771,  0.0575, -0.0607, -0.0383,\n",
       "            -0.3313, -0.0359, -0.4884,  0.0916, -0.0887, -0.5110,  0.3099, -0.2795,\n",
       "             0.0486,  0.0716,  0.4087,  0.0701,  0.2670, -0.0784,  0.2725, -0.3569,\n",
       "             0.2147, -0.0263, -0.1652, -0.5661,  0.1112,  0.2917,  0.1191, -0.4287,\n",
       "             0.3106,  0.0323,  0.0850,  0.4795, -0.0728,  0.2126, -0.0525, -0.1586,\n",
       "             0.3641, -0.0806, -0.1023,  0.0983,  0.0486,  0.1236, -0.1872, -0.2965,\n",
       "             0.1698,  0.0348, -0.3640, -0.0789,  0.1213, -0.3187,  0.2498,  0.0167,\n",
       "            -0.1344, -0.2704,  0.0132, -0.1615, -0.3715, -0.0625, -0.0895,  0.0901,\n",
       "             0.0831, -0.1458,  0.0530, -0.0919, -0.0988, -0.4932,  0.1089,  0.2484,\n",
       "            -0.0049,  0.1186, -0.2689, -0.6892,  0.0921, -0.2289, -0.0662, -0.5321,\n",
       "            -0.0100,  0.3651,  0.0626, -0.1628, -0.2214,  0.3767, -0.1653, -0.0133,\n",
       "            -0.4262,  0.5597, -0.3447, -0.1031,  0.2384,  0.1333,  0.0451,  0.0463,\n",
       "            -0.2484,  0.0043,  0.1526,  0.0718, -0.1315, -0.2863, -0.0278,  0.5137,\n",
       "            -0.2379,  0.0448, -0.3225, -0.2870, -0.0406, -0.0467,  0.0080,  0.2446]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  1552,   269,   297,   592, 18776,   285,\n",
       "             5459,   863,  9174, 15995,   634, 17210,     0]])),\n",
       "  (tensor([[-2.9035e-01, -1.5265e-01,  9.5503e-02,  2.5933e-01, -1.9393e-01,\n",
       "             1.2567e-01,  5.0876e-02,  4.9945e-01, -1.0975e-01,  1.6182e-01,\n",
       "            -1.2389e-01,  5.2037e-01,  1.9504e-01, -4.3985e-02,  7.0420e-02,\n",
       "            -4.8126e-02, -8.0783e-03,  5.6945e-01,  3.4947e-02, -5.6074e-02,\n",
       "             1.2371e-01, -3.2648e-01, -2.9817e-01, -9.4722e-02,  1.9297e-01,\n",
       "            -7.0241e-02, -2.1055e-01,  1.9030e-01,  7.2815e-03, -9.1190e-02,\n",
       "             1.1853e-01,  3.5972e-01, -5.9370e-02,  1.9552e-01, -8.7665e-02,\n",
       "             1.6033e-01, -1.9592e-01, -5.3253e-01,  1.0189e-01,  3.2481e-01,\n",
       "            -2.3022e-02, -1.8589e-01,  1.7627e-01,  2.6511e-01, -8.9893e-02,\n",
       "             1.7009e-01, -2.3274e-01,  3.4080e-03, -1.3183e-01, -3.2621e-01,\n",
       "             2.0301e-01, -3.9095e-01,  1.8957e-01, -6.0549e-02, -1.9990e-01,\n",
       "             1.4551e-02, -1.6543e-01, -4.0586e-02,  7.3386e-02,  3.3422e-02,\n",
       "            -1.8339e-02,  5.8645e-02,  1.3494e-01,  1.4966e-01,  6.2387e-02,\n",
       "             2.4070e-01,  9.6690e-02, -2.3707e-01,  2.4415e-01, -8.1682e-02,\n",
       "             4.8162e-01, -3.1819e-01, -7.9000e-02, -6.2441e-02, -1.8155e-02,\n",
       "            -4.1581e-01,  1.1609e-02, -1.3387e-02, -1.6437e-01,  1.7156e-01,\n",
       "             2.8969e-02, -4.3716e-01,  1.4806e-01, -4.8065e-01, -3.2348e-01,\n",
       "             6.9453e-02,  2.8156e-01, -1.0944e-02, -9.9534e-03, -2.9871e-01,\n",
       "            -6.8319e-02, -2.9483e-02,  2.5243e-02, -2.2234e-01,  4.3397e-02,\n",
       "            -2.1612e-01, -1.9371e-01, -3.9209e-01, -1.7052e-01,  2.1575e-01,\n",
       "            -2.4146e-01, -4.5102e-01, -9.7459e-02, -1.5738e-01,  2.1795e-01,\n",
       "             1.6770e-01, -9.9678e-03,  1.0368e-01,  1.5628e-01, -3.7127e-01,\n",
       "            -7.2937e-02, -1.1651e-01,  5.7645e-02,  1.5959e-01,  1.2989e-01,\n",
       "            -3.6609e-02, -9.6924e-02, -1.6585e-01,  2.9273e-02,  1.8377e-01,\n",
       "            -9.7703e-02,  1.4151e-01,  8.1834e-02,  1.0108e-01, -2.0532e-01,\n",
       "            -1.5609e-01,  2.2033e-01,  1.1081e-01,  3.9789e-02, -3.7006e-01,\n",
       "            -3.8786e-01, -1.4470e-01, -3.2320e-02, -1.0017e-01,  4.3281e-01,\n",
       "            -2.0336e-01, -7.1427e-02, -8.0615e-02, -3.2077e-02, -7.0807e-02,\n",
       "            -1.6591e-01,  3.6462e-01,  3.7251e-03, -3.6455e-01, -2.0607e-02,\n",
       "             1.5534e-02,  3.0357e-01, -3.3720e-02, -1.7008e-01, -2.2429e-02,\n",
       "             3.5098e-01,  4.4773e-03, -1.0930e-01, -1.3077e-02, -3.1847e-02,\n",
       "             2.2900e-01,  1.5781e-01,  1.6272e-01,  4.3445e-02, -5.6710e-03,\n",
       "            -1.2528e-01,  2.5480e-01, -1.4726e-01, -1.7703e-01,  1.3699e-01,\n",
       "             3.5632e-01,  3.9862e-01, -2.1058e-02,  2.2956e-02, -2.6290e-01,\n",
       "            -6.7181e-02, -9.7992e-02,  4.2171e-02,  1.0555e-01,  1.0084e-01,\n",
       "            -1.1810e-01, -6.2693e-01, -2.2598e-01,  1.0492e-01,  1.4935e-01,\n",
       "            -7.5021e-02,  1.3490e-01, -1.0632e-01, -4.4451e-01, -2.9739e-01,\n",
       "            -9.1462e-02, -2.0423e-01, -1.7533e-01, -2.6551e-01,  1.1906e-01,\n",
       "             4.5281e-02, -4.5327e-02,  7.4343e-01, -1.3932e-01,  2.7660e-01,\n",
       "            -3.1687e-01, -1.1452e-02,  1.0984e-01, -2.2170e-01,  3.3367e-01,\n",
       "             5.5376e-03, -1.1724e-01, -1.0773e-01, -4.5826e-02, -1.3502e-01,\n",
       "             3.3697e-01, -1.9469e-01, -4.3159e-02, -9.8663e-02, -1.8401e-01,\n",
       "            -4.4226e-02,  1.4241e-01, -4.7115e-03,  7.5720e-02,  2.4246e-01,\n",
       "            -4.8927e-01, -1.4227e-02, -4.6855e-01,  3.7304e-01,  3.6541e-01,\n",
       "            -2.6340e-01,  3.0054e-01, -1.8247e-01,  9.7107e-02,  9.9114e-02,\n",
       "             2.7552e-01,  3.2051e-02,  7.6321e-02,  1.3803e-01,  2.5519e-01,\n",
       "            -2.0243e-01, -8.6029e-02,  1.2511e-01,  4.4380e-02, -2.4371e-01,\n",
       "            -3.0887e-01, -2.1522e-01, -2.1618e-01, -4.7899e-02, -2.4009e-01,\n",
       "            -8.5569e-02,  3.9759e-01,  3.0439e-01,  1.6843e-01,  3.9999e-02,\n",
       "            -2.0708e-01,  2.2610e-01, -2.3000e-01, -9.3619e-02, -6.9954e-02,\n",
       "             4.3204e-02,  7.3677e-02, -5.1054e-01, -5.4613e-01, -3.8460e-01,\n",
       "             2.2620e-01,  7.9508e-02,  1.5020e-01, -8.3827e-02,  3.1449e-01,\n",
       "            -1.2438e-01, -6.9193e-02,  1.0581e-01,  9.7632e-02,  1.2932e-01,\n",
       "             9.8106e-02, -4.0409e-01, -5.2616e-02, -1.5407e-01,  3.8157e-01,\n",
       "             7.0167e-02, -3.9533e-02, -2.2275e-01, -3.8146e-01,  1.6665e-01,\n",
       "             2.3188e-01,  1.4750e-01,  2.5275e-02,  2.7551e-01, -1.9140e-01,\n",
       "            -4.9070e-01, -4.1544e-02,  2.0184e-01,  8.7006e-02,  1.8715e-01,\n",
       "             2.3348e-01, -1.6183e-01,  1.7423e-02,  1.0233e-01, -2.3655e-01,\n",
       "             4.1036e-01,  2.3781e-01,  2.8052e-01,  3.1607e-01,  7.7653e-01,\n",
       "             2.9156e-01,  1.7258e-01,  4.2415e-01,  1.9884e-01, -2.1293e-01,\n",
       "            -7.4033e-02, -3.9768e-01,  1.0384e-01,  1.8538e-02, -1.8968e-02,\n",
       "             1.3964e-01,  2.9912e-01, -2.4971e-01, -1.6805e-02,  1.3774e-01,\n",
       "             1.2051e-01,  4.3546e-01, -4.0473e-02,  3.9680e-01,  3.2113e-01,\n",
       "            -5.8415e-02, -9.6505e-02, -5.4482e-02, -2.4236e-01,  2.7420e-01,\n",
       "            -3.3384e-02, -5.9018e-02, -3.4072e-02,  5.2689e-01,  1.7798e-01,\n",
       "            -7.3648e-02, -1.4557e-01,  5.4451e-02, -4.2587e-01,  4.0870e-01,\n",
       "            -2.7438e-02,  2.4597e-01, -1.7268e-01, -1.0407e-02, -3.4762e-01,\n",
       "             2.1110e-01,  5.6812e-01, -2.2911e-01,  7.1538e-02, -9.7606e-02,\n",
       "            -2.3520e-01, -1.4698e-01,  2.0030e-01, -8.3328e-02, -1.1560e-01,\n",
       "             4.0375e-02,  1.5315e-01,  2.6044e-01, -2.0927e-01,  2.5975e-01,\n",
       "            -9.5823e-02, -8.4529e-02,  4.9418e-01,  6.7951e-02, -2.8858e-01,\n",
       "            -1.0252e-01, -6.3113e-02, -1.7128e-01,  2.8085e-03,  8.2178e-02,\n",
       "             1.7964e-01, -8.7712e-02,  3.7225e-01,  1.6886e-01, -1.6032e-01,\n",
       "            -6.1976e-01, -1.7433e-01, -1.4197e-01, -2.8708e-01, -5.6919e-01,\n",
       "            -6.9833e-02,  1.6054e-01,  2.2775e-01, -2.5003e-01, -2.7543e-01,\n",
       "            -9.0525e-02,  2.0438e-01,  1.3598e-01,  1.6730e-01,  6.4555e-02,\n",
       "            -5.7921e-02,  6.9446e-02, -2.1249e-01,  5.4278e-02,  3.8186e-01,\n",
       "             2.0905e-01,  4.8522e-01, -3.7709e-01, -3.3542e-01,  2.8442e-02,\n",
       "             1.0113e-01, -1.8691e-01, -2.9778e-01, -2.3249e-02, -2.5214e-01,\n",
       "            -2.6855e-01,  1.2765e-01,  5.3228e-01,  5.5715e-02,  1.7333e-01,\n",
       "            -3.5047e-01, -2.8902e-01, -5.6930e-01,  3.0823e-01,  2.0635e-02,\n",
       "            -1.3218e-01,  7.0790e-01,  1.6180e-01, -5.5221e-02, -7.8048e-02,\n",
       "            -1.3185e-01, -2.0064e-01, -1.4214e-01, -2.2205e-01, -3.8703e-01,\n",
       "             2.4802e-01, -3.9164e-03,  5.4231e-02, -1.4672e-01, -6.4553e-02,\n",
       "            -2.0622e-01, -2.4761e-01,  3.9413e-01, -4.6020e-01,  3.3695e-01,\n",
       "             4.1913e-02,  2.6108e-01, -5.3588e-02, -1.6131e-01,  3.2145e-01,\n",
       "            -1.5753e-01,  6.6523e-01,  2.1967e-01, -3.7129e-01, -5.0355e-03,\n",
       "             5.9812e-01,  4.7737e-02, -6.7404e-02,  1.5344e-02, -1.4365e-01,\n",
       "            -5.2502e-01,  3.7804e-02,  2.6782e-01, -1.0281e-01,  1.7952e-01,\n",
       "            -6.2679e-01,  1.3027e-01, -4.6532e-01, -2.3416e-01,  1.0852e-01,\n",
       "             1.9661e-01,  2.7418e-01, -2.2826e-01, -1.0578e-01,  2.6958e-01,\n",
       "             4.5413e-01, -3.5409e-01, -2.7906e-01,  2.6720e-02,  6.1576e-02,\n",
       "             3.8299e-02, -9.1112e-02, -5.1663e-02,  1.4762e-01, -1.1813e-01,\n",
       "             2.6922e-01, -4.1392e-02,  5.2800e-01,  2.8990e-01, -3.7973e-02,\n",
       "             2.1419e-01,  3.0796e-01, -2.1796e-01,  8.1579e-02, -2.7802e-01,\n",
       "             4.5812e-01, -6.4153e-02, -9.9470e-01, -3.9393e-01,  8.3780e-02,\n",
       "            -1.8562e-01,  2.2292e-01, -2.9837e-01,  2.8633e-01,  6.2052e-02,\n",
       "             3.2215e-01,  1.7185e-01,  6.7199e-02, -2.5199e-01, -4.2885e-02,\n",
       "             3.2789e-02, -3.8378e-01,  4.9145e-01,  4.1573e-01,  8.8690e-01,\n",
       "            -2.9148e-01, -3.8420e-01,  8.9336e-02, -2.3331e-01, -6.1151e-01,\n",
       "            -1.6487e-01,  3.4475e-01, -2.3273e-01,  1.2862e-01,  1.2060e-01,\n",
       "             6.8086e-01,  1.5016e-02,  1.1131e-01, -2.1614e-01, -1.7529e-01,\n",
       "             3.0508e-01, -1.8227e-01,  2.0232e-01,  5.5897e-02,  2.8852e-02,\n",
       "             4.2020e-01,  2.1040e-01,  2.7153e-01,  1.4786e-01, -2.6181e-01,\n",
       "            -1.9216e-01, -3.4906e-01,  2.0364e-01, -5.3590e-01, -2.2455e-01,\n",
       "            -1.7309e-01, -4.7964e-02, -4.1124e-02, -1.8057e-01, -9.9974e-02,\n",
       "            -9.4190e-02,  3.4209e-02, -6.3711e-01, -1.7783e-02,  1.8897e-01,\n",
       "             3.3041e-01, -1.3274e-01,  4.0547e-02,  1.1653e-01, -3.2473e-02,\n",
       "            -2.1346e-01, -1.4821e-02,  1.5112e-01, -1.8816e-02, -5.4251e-01,\n",
       "            -2.7271e-01, -1.8319e-01, -2.6214e-01,  6.8078e-02,  6.2953e-02,\n",
       "            -1.1868e-01,  3.9549e-01,  8.0056e-02, -5.5851e-01, -5.2691e-01,\n",
       "             2.8630e-01, -9.0415e-02, -5.0649e-01, -1.4589e-01, -1.9296e-01,\n",
       "            -2.8989e-01,  4.4140e-01, -1.6671e-01, -2.4423e-01, -5.9575e-01,\n",
       "            -1.3069e-02, -1.3148e-04, -4.3614e-02,  1.7104e-01,  3.7817e-01,\n",
       "             1.2972e-01, -3.6529e-01, -4.1411e-01, -1.5631e-01, -2.7219e-01,\n",
       "             1.7753e-01, -2.4122e-01, -3.6996e-02, -3.1213e-01,  4.6823e-01,\n",
       "             2.3399e-01,  2.2872e-01, -2.1804e-01,  6.1008e-02,  4.6887e-01,\n",
       "             2.4245e-01, -1.3979e-01,  1.0422e-01,  4.0265e-01, -1.0186e-01,\n",
       "            -6.4431e-01, -4.2333e-01, -3.4225e-01,  3.2684e-01,  3.0770e-01,\n",
       "            -1.5675e-01,  1.2916e-01,  2.3179e-03,  4.0792e-01, -1.8341e-01,\n",
       "             1.1041e-01, -1.1857e-01,  4.9764e-01, -1.3391e-02,  1.8276e-01,\n",
       "            -2.4117e-03, -1.8672e-01,  6.1561e-02,  4.8358e-03, -6.0990e-02,\n",
       "            -2.3388e-01,  1.4327e-01,  6.6200e-01, -7.0336e-01,  3.4460e-02,\n",
       "             6.8780e-02, -1.3222e-01, -4.5515e-02, -3.2050e-01, -4.6156e-01,\n",
       "             1.2897e-01,  1.5113e-01, -5.1466e-01, -1.4970e-01, -2.6966e-02,\n",
       "            -3.0467e-01, -2.5578e-01, -8.7650e-02, -2.0109e-01,  9.6129e-02,\n",
       "            -2.3345e-01,  6.5872e-01,  1.6007e-01,  8.8436e-02,  3.0920e-01,\n",
       "             2.9040e-01,  2.3569e-02, -5.6262e-01,  1.7939e-01, -2.2829e-01,\n",
       "            -1.2722e-01, -2.4078e-03,  1.5435e-01,  4.9847e-01,  6.4886e-01,\n",
       "             6.9615e-02, -2.6752e-01,  2.3713e-01, -5.0416e-01, -1.0701e-01,\n",
       "            -1.3535e-01, -3.0036e-01,  7.0817e-02,  2.2154e-01,  1.5219e-01,\n",
       "            -3.7653e-01, -2.6389e-02, -6.2034e-01, -3.9361e-01, -2.6255e-02,\n",
       "             3.8439e-01, -1.8926e-01,  1.0007e-02, -8.4377e-02, -3.4198e-01,\n",
       "             6.4573e-02,  9.5403e-02, -3.6971e-01, -1.2813e-01, -2.3601e-01,\n",
       "             2.4656e-01, -5.2256e-01,  1.2516e-01, -4.4029e-01, -2.0135e-01,\n",
       "             5.1736e-01, -1.3879e-01, -3.9488e-01,  4.1214e-01, -4.5318e-01,\n",
       "             2.5420e-01,  1.7855e-02,  5.5397e-02, -1.2103e-01,  8.9642e-02,\n",
       "             5.6379e-01,  6.1002e-02,  3.6925e-02, -9.7529e-03, -6.8648e-02,\n",
       "            -4.5983e-01,  1.9886e-01,  2.0166e-02,  5.8341e-01,  2.8861e-01,\n",
       "             2.0046e-02,  2.3124e-01,  1.4443e-01,  2.4544e-01,  2.0316e-02,\n",
       "            -2.0685e-01, -2.4108e-01, -1.0591e-01, -1.4207e-01,  5.2176e-01,\n",
       "             2.0495e-02, -4.3850e-01,  9.2238e-02, -4.7259e-01, -6.4067e-02,\n",
       "            -1.2542e-01, -5.2321e-02,  1.0485e-02, -2.8397e-01, -2.0015e-01,\n",
       "            -3.2671e-01,  1.1530e-01, -2.1840e-01,  9.3374e-02,  4.8823e-02,\n",
       "            -2.2141e-01, -3.1383e-01,  5.2239e-01,  2.9479e-01,  2.0000e-01,\n",
       "            -2.2847e-01,  4.7398e-02,  9.2249e-02,  8.5068e-02, -2.2302e-01,\n",
       "            -6.3834e-02, -7.7537e-02,  3.4710e-01, -4.8485e-01,  2.5117e-01,\n",
       "            -1.0106e-01, -1.2590e-01, -1.8455e-01,  3.4969e-01,  2.8704e-01,\n",
       "            -1.4102e-02, -6.7020e-02,  1.3728e-01,  2.9075e-01, -1.2823e-01,\n",
       "             1.3288e-01, -2.4858e-01,  4.0903e-02,  6.5743e-02, -1.3481e-01,\n",
       "            -2.8266e-01,  2.8542e-01, -3.4005e-01, -1.3174e-01,  1.6636e-01,\n",
       "             9.6228e-02, -2.0705e-01,  1.0745e-01, -3.4799e-02,  3.1188e-02,\n",
       "            -4.5835e-01,  1.2317e-01, -1.0689e-01, -6.0780e-01, -4.8131e-02,\n",
       "             7.4239e-01, -1.0406e-02,  1.7241e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  1989,   253, 19153,  1930,   273,   436,\n",
       "             5691,   310, 14779,  5107,     0]])),\n",
       "  (tensor([[-4.1091e-01, -4.3852e-01,  4.0231e-02,  1.6403e-01, -4.0001e-02,\n",
       "            -5.0047e-02,  2.2104e-01,  2.0207e-01, -5.2331e-01,  1.6417e-01,\n",
       "            -3.9201e-01,  2.4265e-01,  3.2878e-01,  3.5502e-02,  3.0665e-01,\n",
       "            -3.1328e-02,  1.8283e-01,  1.5666e-01,  1.6046e-02,  4.6415e-02,\n",
       "             6.6107e-02, -1.2615e-01, -4.4453e-01, -1.2395e-01,  2.9096e-01,\n",
       "            -5.5652e-01, -1.2942e-01, -9.7091e-02, -1.2840e-01, -5.3674e-01,\n",
       "             1.8117e-02,  2.0551e-01, -4.1341e-01,  2.7604e-01,  2.6935e-01,\n",
       "             3.3829e-01, -1.5733e-01, -1.5020e-01, -4.7616e-01,  1.9264e-01,\n",
       "             3.2915e-01,  8.5022e-03,  1.9617e-01,  4.3641e-02, -2.2428e-01,\n",
       "             2.2816e-01,  1.2650e-02,  5.9356e-02, -2.0521e-01, -3.2693e-01,\n",
       "            -1.2078e-01, -3.5510e-01,  9.4415e-02,  2.3598e-01,  3.6273e-02,\n",
       "            -6.4774e-02,  3.4170e-02,  1.6391e-02,  9.7683e-02,  5.3806e-02,\n",
       "             9.2535e-03,  2.6161e-01, -8.0154e-02, -3.7146e-01,  2.8416e-01,\n",
       "             1.2757e-01, -2.3231e-02, -1.0505e-01,  2.4087e-01, -3.6221e-01,\n",
       "             2.5035e-01,  1.1832e-01,  1.6255e-01,  1.0126e-01, -1.2558e-01,\n",
       "            -3.9955e-02, -3.6986e-03,  1.7556e-01, -3.4391e-01,  2.9673e-01,\n",
       "            -1.7900e-02,  3.3446e-02,  5.3647e-02, -3.3177e-01, -1.9837e-01,\n",
       "             1.8969e-02,  3.0552e-01, -5.4309e-01,  4.0705e-01, -2.9392e-01,\n",
       "             2.2438e-01,  3.7911e-02, -1.2285e-02, -1.9777e-01, -1.2654e-01,\n",
       "            -1.3854e-01,  5.2523e-02, -4.1418e-01,  2.0074e-01, -2.7662e-01,\n",
       "             7.6247e-02, -1.3207e-01, -4.4046e-01,  1.7910e-02, -2.6712e-01,\n",
       "             7.8421e-02, -1.6509e-01, -2.4427e-01,  3.3428e-02, -2.4443e-01,\n",
       "            -3.4948e-01,  4.1295e-01,  6.0438e-02,  7.5490e-02,  7.9793e-02,\n",
       "            -4.1011e-02, -1.8577e-01, -4.6537e-01,  1.1758e-01, -1.5665e-01,\n",
       "            -3.4167e-01,  1.7449e-01,  4.0606e-01,  1.0314e-01, -9.6490e-02,\n",
       "            -2.0627e-01, -2.1864e-02, -7.9936e-02,  6.1526e-02,  9.8153e-02,\n",
       "            -6.7555e-02,  8.4010e-02, -2.7873e-01, -3.4399e-01,  5.4932e-01,\n",
       "             2.1340e-02,  1.4788e-01,  1.7593e-01, -1.7775e-01,  8.1267e-02,\n",
       "            -7.3605e-03, -1.1799e-01,  9.8311e-02, -1.5199e-01,  3.2989e-01,\n",
       "            -3.3519e-01,  4.3536e-01, -8.3148e-02, -5.4735e-02, -2.5190e-02,\n",
       "             1.2071e-01,  1.6722e-01,  3.4664e-01, -1.9815e-01, -4.6314e-01,\n",
       "             2.6706e-01,  1.8042e-01,  7.9418e-02, -1.2250e-02, -1.6614e-01,\n",
       "             1.0386e-01,  7.6869e-02, -1.1610e-01,  4.9397e-02,  1.1993e-01,\n",
       "             8.8134e-03,  3.9042e-01,  2.2747e-01, -3.3967e-01, -1.6542e-01,\n",
       "            -4.0629e-01, -4.8751e-01,  2.2935e-01,  2.0082e-01, -1.3529e-01,\n",
       "             1.2435e-01, -4.7243e-01, -1.8733e-01,  1.6973e-01, -1.5618e-03,\n",
       "             4.0022e-03,  3.7319e-01,  7.0987e-02, -1.2112e-01, -3.4070e-01,\n",
       "            -8.4064e-02, -1.3743e-01,  1.0953e-01, -6.4069e-01,  2.9654e-01,\n",
       "             3.1075e-01,  2.7825e-01,  5.0554e-01,  1.4540e-01, -1.6033e-01,\n",
       "             8.2175e-02,  2.5126e-01, -1.4621e-01, -2.2414e-01,  5.7036e-01,\n",
       "             3.6559e-03,  1.7602e-02, -3.5000e-01,  2.3801e-01,  3.3890e-02,\n",
       "             2.5413e-01, -3.5909e-03, -1.2773e-01,  1.4795e-01, -1.4135e-01,\n",
       "             2.3327e-01,  1.9375e-01,  1.8912e-02,  4.3849e-02,  5.7174e-03,\n",
       "            -2.8187e-01, -1.3922e-01, -2.6574e-01,  3.9073e-02,  3.1288e-01,\n",
       "            -2.0178e-01,  5.0157e-02, -1.5180e-01,  3.0811e-01,  5.6155e-02,\n",
       "             4.5425e-01,  1.4060e-01,  2.3265e-01,  2.8704e-01,  6.2618e-01,\n",
       "             4.5190e-01,  1.8516e-01, -2.5775e-01, -1.6705e-01, -6.4217e-02,\n",
       "            -1.6835e-01,  8.7003e-02, -9.6907e-02,  1.7756e-01, -3.2546e-01,\n",
       "            -1.7086e-01,  1.6463e-01,  2.2187e-01,  3.0377e-01, -1.9179e-01,\n",
       "            -2.2254e-01,  2.0896e-01, -2.3239e-01,  2.8397e-01,  2.8591e-02,\n",
       "             3.2261e-02,  5.8302e-02, -3.7018e-01, -6.0977e-01, -1.1108e-01,\n",
       "            -1.7309e-01,  2.6068e-01,  9.8276e-02, -1.9662e-02,  7.8077e-02,\n",
       "            -3.1186e-01,  3.1335e-01,  1.8224e-02, -2.3824e-01,  5.6575e-01,\n",
       "             3.9450e-01, -4.1347e-01,  5.8367e-01, -9.9457e-02, -1.1724e-01,\n",
       "             8.4064e-03,  1.7504e-01, -1.5280e-01,  2.1477e-01, -1.5646e-01,\n",
       "             4.5396e-01, -2.5091e-02, -2.3061e-01,  8.9712e-02, -3.7293e-01,\n",
       "            -3.1743e-01, -3.8856e-01,  7.8249e-02,  1.3056e-01,  2.1724e-01,\n",
       "            -1.6511e-01, -3.7293e-01, -8.1811e-02, -2.0756e-01, -2.0707e-01,\n",
       "             1.2135e-01,  2.2760e-01, -5.5307e-02, -2.0516e-01,  5.7673e-01,\n",
       "            -8.4211e-02,  1.8130e-01,  2.7208e-01,  3.2646e-02, -1.3610e-01,\n",
       "            -1.0200e-01, -1.1601e-01,  2.4438e-02,  1.2107e-01, -1.8130e-02,\n",
       "             1.5196e-01,  2.0095e-01, -7.9676e-02, -4.2605e-02,  1.3312e-01,\n",
       "             3.3798e-01, -1.6426e-01,  2.8657e-01,  3.0355e-01,  2.1841e-01,\n",
       "             1.2184e-01,  1.9694e-01, -3.7138e-02,  2.8060e-02, -1.8144e-02,\n",
       "             4.3856e-01, -3.5594e-01, -3.3785e-02,  5.2526e-01,  1.7416e-01,\n",
       "            -1.5533e-01, -1.6965e-01,  2.1670e-01, -7.7276e-02,  1.3478e-01,\n",
       "            -2.6132e-01,  3.5436e-01, -1.7696e-01, -7.6789e-02,  2.1696e-02,\n",
       "            -2.4375e-02,  4.5377e-01,  1.7321e-02, -1.0272e-01, -2.2539e-02,\n",
       "            -1.0811e-01,  2.9425e-01,  1.1581e-01, -3.3791e-01, -4.7629e-01,\n",
       "             3.3025e-01, -1.1291e-02,  2.7314e-01,  2.4201e-03,  7.4092e-01,\n",
       "             1.3359e-02, -1.2610e-01,  1.8262e-01,  1.7771e-01, -3.1704e-01,\n",
       "             2.0806e-01, -5.9780e-01, -4.5931e-03, -4.4958e-02, -7.6649e-02,\n",
       "             2.9918e-01, -1.7371e-02,  5.3812e-01,  3.0761e-02, -4.2014e-02,\n",
       "            -4.2861e-01,  4.8680e-02, -2.1641e-01,  6.4153e-02, -1.2649e-01,\n",
       "            -5.3049e-02,  3.1345e-04, -2.0201e-01,  3.2283e-01, -3.8169e-01,\n",
       "             2.5418e-01,  9.2773e-02,  1.0159e-01,  3.6700e-03,  1.8048e-01,\n",
       "             3.1067e-01, -1.4206e-01, -3.5431e-01, -1.4660e-01,  2.9618e-01,\n",
       "             4.8424e-01,  5.9836e-01, -6.3182e-01,  8.7622e-02,  1.8293e-01,\n",
       "             1.7768e-01,  6.4386e-02,  4.0289e-01,  2.7104e-01, -2.9529e-01,\n",
       "             5.5194e-02,  4.9424e-01,  6.7713e-01, -3.0976e-01,  3.9930e-02,\n",
       "             4.3881e-02, -5.5551e-01, -5.3477e-01,  5.7444e-02,  1.3206e-01,\n",
       "            -4.3775e-01,  5.5923e-01,  1.4764e-01, -6.9449e-01,  8.4514e-02,\n",
       "            -2.6052e-01, -8.0419e-02,  2.9955e-01, -2.2705e-01, -9.1274e-02,\n",
       "             1.9125e-01,  3.8739e-01,  2.8235e-01,  1.5371e-01, -1.6333e-01,\n",
       "             7.1477e-02,  1.4063e-01,  9.3858e-03, -3.7101e-01,  5.3253e-02,\n",
       "             1.9683e-01,  2.4241e-01,  4.2897e-02, -3.3101e-02,  2.3085e-01,\n",
       "            -1.3557e-01,  3.7744e-01,  6.9810e-01, -5.1129e-02,  6.5883e-02,\n",
       "             2.0498e-01, -5.4487e-02,  4.1101e-01, -5.0815e-01, -5.7290e-02,\n",
       "            -7.0993e-01, -6.0412e-02,  2.6110e-01,  4.8735e-02,  1.1723e-01,\n",
       "            -3.8171e-01,  2.2931e-01, -1.2294e-01,  4.5754e-02, -2.4417e-01,\n",
       "            -2.8359e-01,  5.0808e-02, -1.8224e-01, -3.6826e-01,  1.6933e-01,\n",
       "             3.4382e-01, -2.5513e-01,  1.1690e-01,  8.1078e-02,  1.8390e-01,\n",
       "            -2.4289e-01, -3.9251e-02, -1.4581e-01, -4.8236e-02, -4.5122e-01,\n",
       "             2.4973e-01,  5.9397e-02,  1.6859e-01,  4.5512e-01, -1.7226e-03,\n",
       "             3.6088e-01, -2.7498e-02,  1.0745e-02, -3.1466e-01, -2.1463e-01,\n",
       "            -1.0663e-01, -3.8661e-01, -6.5486e-01,  2.4714e-01, -3.4921e-01,\n",
       "             1.0240e-01,  1.0584e-01,  1.3833e-01,  8.8601e-02,  2.8683e-01,\n",
       "             1.1129e-01,  3.0965e-01,  7.8472e-02, -2.5510e-01, -4.4671e-01,\n",
       "             1.4583e-01, -2.4811e-01,  3.8699e-01, -1.7115e-01,  4.9473e-01,\n",
       "             5.7253e-03, -7.8369e-02, -2.0983e-01, -5.1979e-01, -6.0529e-01,\n",
       "            -1.0117e-01,  1.4020e-01, -3.5516e-02,  1.4156e-01, -3.6471e-01,\n",
       "             3.0230e-01,  1.6131e-01,  1.4953e-01, -6.1969e-01, -4.9088e-02,\n",
       "             1.5529e-01, -5.8513e-01,  3.6198e-01, -5.4277e-02, -3.0198e-01,\n",
       "            -1.7868e-01, -1.4149e-01, -1.7892e-01, -3.9003e-03, -1.4053e-02,\n",
       "            -2.0188e-02, -1.3847e-01, -4.7158e-02, -4.0938e-01, -4.1752e-01,\n",
       "            -2.5540e-02, -2.0239e-01, -1.5307e-01, -1.9712e-01,  1.4870e-01,\n",
       "            -3.5645e-01,  1.1381e-01, -4.9777e-01, -4.4234e-01, -1.2794e-01,\n",
       "             3.5038e-01, -1.0710e-01,  6.5974e-02,  9.3212e-02, -6.9767e-03,\n",
       "            -1.4183e-01, -2.0533e-01,  4.4852e-01, -5.3253e-01, -8.7525e-01,\n",
       "             7.0215e-02, -8.3618e-02, -3.6917e-01,  7.7838e-02,  3.3620e-01,\n",
       "            -1.7321e-01,  3.4609e-01, -8.2042e-02, -2.6718e-01, -1.3714e-01,\n",
       "             1.2774e-01, -9.4220e-02, -2.2605e-01,  1.9323e-01, -6.7351e-01,\n",
       "             3.8012e-01, -3.0440e-01, -5.0288e-02, -1.6478e-01, -4.8459e-01,\n",
       "            -1.9664e-01, -2.5561e-02,  4.6810e-02,  3.5540e-02,  5.9146e-01,\n",
       "             1.5749e-01, -1.0321e-01, -1.3311e-01, -1.6755e-01,  7.9045e-02,\n",
       "            -2.2781e-01, -4.2416e-01, -1.0493e-01, -4.1722e-02, -1.2634e-01,\n",
       "             2.3564e-01,  1.2066e-01, -2.3692e-01, -2.9408e-01,  1.6640e-01,\n",
       "            -2.0748e-01,  1.0650e-01, -8.0336e-02,  2.2267e-03, -1.2349e-01,\n",
       "             3.1517e-02, -1.2281e-01, -3.0870e-02,  5.2334e-01, -3.4205e-01,\n",
       "            -4.8178e-01, -8.1400e-02, -2.2104e-01,  2.1136e-01, -1.5392e-01,\n",
       "             2.5547e-01,  1.3612e-01,  4.7514e-01,  2.6119e-01,  2.2378e-01,\n",
       "             3.7326e-01, -1.7057e-01, -4.5222e-01,  2.3244e-01,  9.6431e-02,\n",
       "             2.1655e-02,  1.4092e-01,  2.6802e-01, -7.2092e-01,  4.1041e-01,\n",
       "             2.6813e-01, -3.2768e-01, -3.7773e-02, -4.0918e-01, -1.1570e-01,\n",
       "             3.7846e-01,  3.5729e-01,  3.9714e-02, -3.5669e-01,  4.5235e-02,\n",
       "             6.2394e-02, -1.7902e-01, -5.2788e-03, -1.0008e-01,  6.0046e-02,\n",
       "            -2.5098e-01,  2.6661e-01,  1.3694e-01, -3.4359e-01, -2.3941e-01,\n",
       "            -2.1876e-01,  2.5294e-01, -3.5670e-01,  2.1555e-01, -3.1919e-01,\n",
       "             4.1791e-01, -3.1829e-01,  3.9655e-01,  1.9799e-01,  3.9565e-01,\n",
       "             1.6341e-01, -4.3816e-01,  4.4782e-01,  4.3324e-01, -2.2091e-01,\n",
       "             6.1023e-03, -8.4905e-02, -1.9508e-02,  1.6611e-01,  2.7042e-01,\n",
       "            -2.0328e-01, -1.6124e-01,  1.3621e-01, -4.9108e-01,  4.1342e-01,\n",
       "            -5.6312e-02, -1.5119e-01, -5.3699e-02, -2.9515e-01, -5.3081e-01,\n",
       "             1.9607e-01, -4.5052e-02, -5.6337e-01, -2.6429e-01, -2.3016e-01,\n",
       "             3.8815e-01, -1.4603e-01, -7.4039e-02, -1.5825e-01,  8.0499e-02,\n",
       "             1.8356e-01, -8.7132e-02, -1.6897e-01,  1.8482e-01, -2.7233e-02,\n",
       "             4.9391e-03, -2.1339e-01, -7.1470e-01,  6.0347e-02, -7.3250e-03,\n",
       "             6.0467e-01,  4.4654e-02, -1.4444e-01,  1.5519e-01,  7.8296e-02,\n",
       "            -1.7081e-01,  7.4603e-01,  3.2646e-01,  3.6815e-01, -2.0252e-01,\n",
       "             2.0064e-02, -1.4091e-02,  1.0517e-01,  2.2427e-01,  2.4955e-01,\n",
       "             1.5798e-01, -3.5820e-02, -1.5011e-01,  1.5176e-01,  2.9833e-01,\n",
       "            -1.9904e-01,  2.2679e-01,  1.1729e-01, -1.0163e-01, -2.8013e-01,\n",
       "             7.1882e-02,  5.4642e-01,  3.1170e-02, -4.4364e-01,  8.9091e-02,\n",
       "             1.2638e-01, -3.6159e-02,  4.6765e-02, -6.0852e-02,  1.1324e-01,\n",
       "            -4.1405e-01, -5.0646e-01,  1.0150e-02, -2.8653e-01,  8.3648e-03,\n",
       "            -6.1045e-01,  1.4931e-03, -4.0029e-01, -1.8311e-02, -1.2635e-01,\n",
       "             1.9066e-02, -3.2390e-01,  7.2767e-02, -1.8246e-01,  7.1326e-02,\n",
       "            -4.8486e-01,  1.5971e-01, -2.0327e-01,  1.8454e-01,  4.4463e-02,\n",
       "             1.0060e-01, -4.1757e-02, -1.8916e-01,  9.6757e-02, -3.8034e-02,\n",
       "             4.3319e-01, -2.5508e-01,  9.7304e-02,  5.7901e-02, -2.5398e-01,\n",
       "            -3.5625e-01,  4.2740e-01, -2.2550e-01,  2.0663e-01, -8.8008e-02,\n",
       "            -1.1163e-01, -2.7707e-01, -3.1522e-02, -3.1855e-01,  2.2704e-01,\n",
       "            -9.7210e-01,  2.6957e-01, -2.0637e-01, -4.5899e-01,  9.8025e-02,\n",
       "             2.6906e-01, -1.6796e-01,  1.3789e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,   510,   806,  3213,   310,   281,  4271,\n",
       "              253,   987,   952,   281,  1421,   253,  1818,     0]])),\n",
       "  (tensor([[-1.0227e-01, -2.5072e-01, -4.2400e-01,  3.5261e-02, -2.3898e-01,\n",
       "            -1.2671e-01, -1.8096e-01,  5.5146e-02, -2.6217e-01,  3.7490e-01,\n",
       "            -1.8526e-01,  6.0974e-01,  6.1964e-02,  2.7767e-01, -1.4583e-02,\n",
       "             3.3558e-01, -2.0464e-01,  2.8927e-01, -4.0967e-02, -2.6235e-02,\n",
       "            -1.4375e-01, -4.5703e-01, -5.2226e-01, -4.3887e-02, -1.7234e-02,\n",
       "             4.0807e-02, -2.7782e-01, -9.9605e-02,  2.7205e-01, -1.4001e-03,\n",
       "             2.8255e-01, -6.0341e-03,  1.4323e-02,  9.2761e-02, -4.1012e-01,\n",
       "             4.8025e-02,  3.1936e-01, -2.1157e-01, -4.7495e-01,  8.1937e-02,\n",
       "            -1.6566e-01, -1.9831e-02,  1.8910e-02, -1.1587e-01,  1.7778e-01,\n",
       "             2.2275e-01,  3.7284e-01, -5.0035e-02, -1.5971e-01,  4.9213e-02,\n",
       "             4.7626e-02, -1.6454e-01,  1.5721e-01, -1.2497e-03, -1.1119e-01,\n",
       "            -1.7730e-01, -3.8525e-01, -7.2127e-02,  4.5252e-01, -2.6996e-01,\n",
       "            -1.9775e-01,  2.6525e-01, -8.3567e-02,  2.3062e-01,  5.3964e-01,\n",
       "             3.0415e-01,  1.7069e-03, -2.1618e-02,  3.4283e-01, -1.0343e-01,\n",
       "             5.0328e-01,  9.1885e-02, -4.4430e-02, -1.3535e-01, -3.1928e-02,\n",
       "            -2.3700e-01, -1.4262e-01,  5.9608e-01, -9.5276e-02, -1.5197e-01,\n",
       "            -4.8273e-02, -7.4370e-02, -1.1558e-01, -3.3123e-01,  7.0943e-02,\n",
       "             4.1694e-03,  2.3924e-01, -4.0308e-01, -3.5041e-01, -3.5740e-01,\n",
       "            -3.6437e-02,  7.6610e-02,  2.2735e-02, -3.1512e-01,  1.1264e-01,\n",
       "            -1.0932e-01,  1.1579e-02, -8.5942e-02,  2.5259e-01, -1.8262e-01,\n",
       "            -2.9749e-01, -3.6781e-02,  2.0358e-01, -4.9076e-02, -2.9332e-01,\n",
       "             2.1834e-01,  1.3515e-02,  1.3678e-01, -9.0241e-03, -2.0640e-01,\n",
       "             1.0737e-02,  4.2597e-01, -1.3531e-02, -5.1513e-02, -9.0120e-02,\n",
       "             3.3751e-01,  2.3154e-01,  4.4623e-02,  3.4087e-01, -2.6874e-02,\n",
       "             1.1316e-02,  1.3272e-02,  3.0281e-01, -2.6623e-02,  6.6635e-02,\n",
       "            -1.6663e-01,  1.3271e-02, -4.3615e-02, -1.6821e-01,  3.5177e-02,\n",
       "            -2.8112e-01, -3.7153e-02,  4.9449e-02, -2.7525e-01,  3.4025e-01,\n",
       "             2.3452e-01,  1.0066e-01,  2.6139e-01,  1.9199e-01, -3.2888e-01,\n",
       "            -6.4851e-02, -3.1432e-02, -4.1714e-01, -1.8542e-02, -1.2570e-01,\n",
       "            -3.4201e-01,  3.9427e-01,  7.6152e-03,  1.0714e-01, -3.3505e-02,\n",
       "            -1.8583e-01, -1.4993e-01, -1.3782e-01, -1.3209e-01,  1.0192e-01,\n",
       "             1.4438e-01, -5.1431e-02,  2.7399e-01, -2.4186e-01,  1.5011e-01,\n",
       "            -6.1221e-02, -1.4292e-01, -1.6677e-01, -2.4033e-01,  2.8056e-01,\n",
       "             1.9506e-01,  3.4422e-01,  1.5521e-02,  1.5039e-01, -1.3054e-01,\n",
       "            -6.3310e-02, -2.0335e-01, -3.1832e-01,  2.8289e-01, -2.0500e-01,\n",
       "             1.1744e-01, -6.6109e-03,  2.4361e-01,  2.2265e-01,  2.3874e-01,\n",
       "             9.8971e-02, -9.9036e-02, -3.9131e-02, -3.5154e-01, -1.1548e-01,\n",
       "            -5.9468e-01, -9.7378e-02,  2.6376e-01, -1.9942e-01, -1.7091e-01,\n",
       "             1.5225e-01, -3.3952e-01, -4.5225e-02,  1.3448e-01,  2.3395e-01,\n",
       "            -6.0681e-03,  1.7357e-01,  1.9450e-01,  1.4073e-01,  2.7713e-01,\n",
       "             2.3356e-01, -3.6006e-01,  3.0064e-01,  2.9066e-01,  2.2832e-03,\n",
       "            -2.1343e-01,  1.0546e-01,  1.0179e-01,  1.2941e-01, -2.0379e-01,\n",
       "             4.2500e-02,  1.4886e-01,  1.4920e-01, -6.8373e-02,  1.6809e-01,\n",
       "            -3.4434e-01, -4.8770e-02, -6.5630e-01,  3.7514e-01,  2.9678e-03,\n",
       "            -3.4584e-01,  2.1527e-01,  1.0029e-01,  1.9674e-01,  2.0792e-01,\n",
       "             5.2074e-01, -1.2315e-01,  1.6895e-01, -7.0589e-02, -1.5512e-01,\n",
       "             1.8834e-01, -3.1570e-01, -6.9264e-02,  1.8401e-02, -7.5754e-02,\n",
       "            -2.0083e-02, -9.5630e-02,  3.6965e-01, -3.2814e-02, -2.5126e-01,\n",
       "            -3.6651e-01,  7.8053e-02,  1.8411e-01,  1.2410e-01, -2.0007e-02,\n",
       "            -1.4496e-01,  3.0253e-02, -1.8031e-01,  6.2182e-02,  4.9792e-02,\n",
       "             6.9379e-02, -5.3326e-02, -1.1377e-01, -1.5151e-01, -1.7223e-01,\n",
       "             2.1466e-02,  5.0635e-01, -6.3817e-02, -5.5196e-02,  2.7216e-01,\n",
       "            -6.2538e-02, -1.1070e-03,  1.1688e-01,  2.3309e-02,  5.4392e-01,\n",
       "             3.7254e-01,  1.6231e-01, -6.0480e-02, -1.9712e-01, -8.4626e-02,\n",
       "             2.3143e-01, -1.0800e-01, -4.0139e-02, -3.6968e-01, -1.7487e-01,\n",
       "            -1.4479e-01, -9.3003e-02, -1.2073e-01, -2.8317e-02, -9.9493e-02,\n",
       "            -9.2624e-02, -3.0843e-01,  7.8043e-03, -1.1221e-01, -1.3316e-01,\n",
       "             8.8799e-02,  1.9903e-01,  3.1428e-01,  1.6999e-01, -2.2252e-01,\n",
       "             6.1560e-02, -1.2613e-01, -5.1188e-01, -1.6858e-01,  4.5486e-01,\n",
       "             1.9787e-01,  3.3550e-01,  2.6293e-01, -9.4675e-02, -5.4304e-02,\n",
       "            -2.0403e-01, -1.3142e-01,  2.0323e-01,  2.2622e-01, -4.0809e-04,\n",
       "            -7.8835e-02,  9.1026e-01, -7.8032e-02,  1.5461e-01,  3.6516e-01,\n",
       "             9.8792e-02, -3.4745e-01,  1.1063e-01,  3.7132e-01,  1.6246e-01,\n",
       "            -7.6237e-02,  1.4113e-01,  2.7132e-02, -1.1623e-01,  1.2849e-02,\n",
       "            -4.2831e-02,  1.0890e-01, -1.1702e-01,  2.4000e-01,  4.3288e-02,\n",
       "            -3.0576e-01,  1.3790e-01,  8.7405e-02, -3.4753e-01, -1.1016e-02,\n",
       "             2.7293e-02, -5.8418e-02, -4.5474e-02,  6.8711e-02,  1.8922e-02,\n",
       "             2.1886e-01,  2.3527e-01, -4.0865e-01,  3.0936e-01, -1.7868e-01,\n",
       "            -5.2781e-02,  5.9578e-02,  2.5577e-01, -2.4238e-01,  1.5656e-01,\n",
       "            -1.4361e-01, -1.2285e-01,  1.4400e-01, -2.8425e-02,  2.9478e-01,\n",
       "             1.5702e-01, -2.4633e-01,  2.6726e-01,  1.1848e-01,  2.1604e-01,\n",
       "            -2.6114e-01,  1.5960e-01,  2.4430e-02, -8.9136e-02,  9.6933e-02,\n",
       "             1.9026e-01, -1.1450e-01,  6.0902e-02,  2.0806e-01, -9.5520e-03,\n",
       "            -3.6147e-01, -3.1254e-01, -1.7733e-01,  1.6084e-01,  5.7536e-02,\n",
       "             2.3479e-01,  3.3159e-01,  3.9471e-01, -6.7901e-03,  2.9958e-01,\n",
       "             1.3104e-01,  4.8108e-01, -1.7913e-02,  4.4769e-01,  9.3904e-02,\n",
       "            -2.1910e-01,  3.5315e-02, -2.4977e-01, -4.3666e-01,  1.3844e-01,\n",
       "             2.8010e-01,  2.1950e-01, -2.2325e-01,  1.3698e-01,  1.5285e-01,\n",
       "             6.3864e-02, -1.0314e-01,  6.1238e-02,  3.4777e-01, -3.0333e-02,\n",
       "             7.5947e-02,  4.4718e-01,  1.3811e-01,  4.5281e-01,  4.0368e-01,\n",
       "             2.1891e-02,  3.0569e-01, -1.6507e-02,  1.1725e-01,  3.6833e-01,\n",
       "            -4.8822e-01,  1.6971e-01, -1.5442e-01, -6.2858e-01,  1.4554e-01,\n",
       "            -1.7914e-01,  1.6157e-01,  2.1186e-01, -6.2648e-01, -1.1531e-01,\n",
       "             1.1462e-01,  1.9093e-01,  1.7150e-01, -1.3679e-01, -2.6778e-01,\n",
       "            -3.3360e-01,  1.3806e-01,  3.1851e-01,  1.8158e-01,  2.3595e-01,\n",
       "            -7.9703e-02, -1.6506e-01,  1.9936e-01,  1.2966e-01, -4.8905e-01,\n",
       "            -9.0319e-03, -1.1515e-01, -2.1089e-02,  1.1710e-01, -3.3194e-03,\n",
       "             4.5035e-01, -1.5741e-01,  7.7795e-02, -9.4998e-02, -9.4630e-02,\n",
       "            -2.7825e-01, -2.2257e-01,  1.7692e-01,  1.5055e-01, -8.9143e-02,\n",
       "            -2.8090e-01, -3.6161e-01, -1.2183e-01, -3.0239e-01, -5.2132e-01,\n",
       "            -3.5579e-01,  2.3033e-01, -1.8342e-01, -4.1930e-01,  1.0984e-01,\n",
       "             1.0735e-01, -1.5195e-01,  2.8736e-01, -1.1458e-02,  4.7703e-02,\n",
       "             1.4260e-01, -3.9225e-01,  1.1406e-02,  2.8192e-02,  1.5958e-01,\n",
       "            -2.4531e-02, -2.4949e-02,  2.2890e-01,  1.0527e-01, -3.7831e-01,\n",
       "             9.5818e-02,  2.9381e-01, -3.6639e-01, -4.8889e-01, -4.3060e-01,\n",
       "            -2.1018e-01, -1.2539e-01, -8.0106e-01,  1.8256e-02, -2.1330e-01,\n",
       "             5.2692e-02,  7.2136e-01,  2.9285e-01,  2.7607e-01, -1.1111e-01,\n",
       "            -1.2405e-01, -1.6476e-01,  1.7799e-01,  3.2101e-01, -4.5742e-01,\n",
       "            -1.9966e-01, -3.2119e-01,  1.2480e-01,  2.3746e-01,  2.6247e-01,\n",
       "            -8.1328e-02, -3.8154e-01,  3.5230e-01, -1.6831e-01, -2.8514e-01,\n",
       "             2.5080e-01, -4.2620e-02, -2.1190e-01,  3.9315e-01,  2.7586e-01,\n",
       "             7.0672e-01,  2.8794e-01,  4.0336e-02, -1.8092e-01,  9.8155e-02,\n",
       "             3.6509e-01, -2.3881e-01, -3.7762e-02,  2.3093e-02,  2.5316e-01,\n",
       "            -3.4581e-01, -1.0162e-01, -7.6550e-02,  2.9429e-01,  3.1938e-01,\n",
       "             1.4836e-01, -2.0498e-01,  2.5388e-02,  5.4158e-03, -3.7573e-01,\n",
       "            -5.3096e-01,  2.2779e-02, -3.9560e-01, -1.9672e-01,  5.0289e-01,\n",
       "            -5.1592e-01, -3.1011e-01, -1.1449e-01,  2.7137e-01, -3.3197e-01,\n",
       "             9.6021e-02,  2.0366e-01,  4.0249e-02,  1.7796e-01,  3.2753e-02,\n",
       "            -3.8233e-01, -1.7523e-01,  2.7422e-01,  5.8608e-02, -2.0057e-01,\n",
       "            -5.1477e-02,  4.3368e-02, -4.5153e-01,  2.4446e-01,  3.2160e-01,\n",
       "            -8.7080e-02,  1.3789e-01, -1.9256e-02, -2.9680e-01, -3.4771e-01,\n",
       "            -4.4273e-02,  4.1060e-02,  1.4375e-01, -6.2564e-03,  2.0194e-01,\n",
       "            -2.8744e-02,  3.6890e-01, -4.3223e-01, -6.7688e-01, -7.2925e-01,\n",
       "             1.3737e-01,  1.0544e-01,  1.1443e-01, -2.4710e-01,  8.2767e-02,\n",
       "             1.8129e-01,  1.5373e-01,  2.7590e-01, -1.0941e-01, -5.7525e-01,\n",
       "            -1.2545e-01, -3.3561e-01,  8.3027e-02,  1.9492e-01, -1.8916e-01,\n",
       "            -2.5406e-01, -1.7847e-01,  1.7033e-01, -1.9897e-01,  1.2934e-01,\n",
       "            -3.9155e-01, -5.5050e-02, -2.0461e-01,  2.2667e-01, -1.3463e-01,\n",
       "            -4.9585e-01, -2.0989e-01,  1.6534e-01,  2.3072e-01, -2.5635e-01,\n",
       "            -2.9836e-01,  2.2567e-01, -3.2922e-01,  5.2044e-01,  8.0045e-02,\n",
       "             1.8893e-01, -7.3780e-02,  1.1618e-01, -1.2399e-02, -2.1423e-02,\n",
       "            -2.3610e-01,  2.5794e-02, -3.4067e-01, -3.5592e-01, -2.3778e-02,\n",
       "             3.3894e-01, -3.0730e-01,  4.5137e-02, -2.4280e-01, -1.6739e-01,\n",
       "             5.8736e-01, -1.9656e-01, -2.0694e-01, -1.7499e-01, -7.1286e-01,\n",
       "            -1.0459e-01,  2.1754e-01, -1.9510e-01,  1.3168e-01, -3.0969e-01,\n",
       "            -3.3427e-01, -4.7031e-01,  1.4399e-01,  1.4232e-01, -3.0491e-01,\n",
       "            -1.8415e-01,  9.5789e-02, -2.7755e-01,  1.4268e-01,  3.8119e-01,\n",
       "             3.5934e-02,  1.8805e-01,  2.4013e-02, -3.4255e-01, -3.8113e-01,\n",
       "             7.2240e-02, -3.9098e-01, -9.0526e-02,  8.5274e-02,  3.9863e-01,\n",
       "             3.3018e-02, -1.1820e-01, -4.4606e-02, -1.0950e-01,  3.8750e-01,\n",
       "            -1.0400e-01, -9.1509e-02, -8.6078e-02,  1.6946e-01,  6.5439e-01,\n",
       "            -1.3025e-01, -4.4195e-01, -6.4456e-02, -6.1670e-01,  6.8572e-01,\n",
       "             1.9684e-01,  7.4602e-02,  2.3478e-01, -2.9694e-01,  2.0864e-01,\n",
       "            -1.7933e-01,  2.4945e-01, -6.7968e-01, -3.0209e-01,  5.5370e-04,\n",
       "            -5.8467e-03, -6.1303e-02,  1.1091e-02,  1.0659e-02,  2.3597e-01,\n",
       "            -8.8118e-02,  5.2740e-01, -2.5001e-01, -1.1489e-01, -7.0683e-01,\n",
       "             3.7804e-01, -1.8824e-01, -6.4965e-02, -2.4526e-01,  1.8241e-01,\n",
       "             2.7614e-02, -3.3619e-02,  2.2296e-01, -6.9120e-02,  2.2917e-01,\n",
       "            -1.3091e-01, -3.0265e-01,  4.0249e-01, -1.1366e-01, -4.0008e-01,\n",
       "            -1.8034e-01, -6.0060e-01,  3.7824e-01,  5.3240e-02,  4.5207e-02,\n",
       "             2.8122e-01, -2.2130e-01,  9.4939e-03, -2.2595e-01,  4.1958e-01,\n",
       "            -3.4926e-02, -2.6601e-01, -2.4405e-01,  6.7346e-03, -1.2445e-01,\n",
       "             1.8899e-01,  3.9951e-01,  1.3264e-01, -5.0604e-01, -6.7733e-02,\n",
       "            -2.5905e-01, -2.0310e-01,  3.3801e-02,  2.2051e-02,  2.1075e-01,\n",
       "            -3.3456e-01, -3.1759e-01,  4.4507e-01, -2.0299e-01, -2.3158e-02,\n",
       "            -8.6583e-01,  1.1785e-01, -1.2502e-01,  3.6896e-02,  4.4475e-01,\n",
       "            -4.3198e-01, -1.9902e-01, -3.7899e-02, -3.2132e-02,  3.1136e-01,\n",
       "            -4.7089e-02,  1.3900e-01, -1.7194e-01,  1.3325e-01, -5.8120e-02,\n",
       "             6.9539e-02, -2.4294e-01,  2.1435e-01,  4.7104e-01, -3.1645e-01,\n",
       "             2.9584e-01, -1.7783e-01, -5.2276e-02, -5.5057e-02,  2.0282e-01,\n",
       "            -1.7431e-01,  2.9643e-01, -1.6641e-01,  3.5628e-02, -2.8800e-01,\n",
       "            -5.3130e-01, -2.8698e-01,  2.6612e-01,  1.8531e-02,  1.1824e-01,\n",
       "             5.1886e-02,  1.4644e-01,  3.6319e-01, -2.1062e-01, -2.6879e-01,\n",
       "             2.8638e-02, -5.5420e-02,  9.7601e-02]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 11244,   253,  7012, 19270,   281,  7482,\n",
       "              253,  2600,   273,   253, 25144,    15,   380,  7482,   943,  3831,\n",
       "              337,    14,    19, 14683,   670,  1016,  9400,   275,   253,  7482,\n",
       "               13,  3560,   407,   247,  3048,   281,   247,  4623,  3929,    15,\n",
       "             3166,   417,  3177,   281,   897,  5559, 18589,    84,   390,  7180,\n",
       "              281,  1347,   436,  4836,    15,     0]])),\n",
       "  (tensor([[-9.0915e-02,  4.3223e-02,  4.1484e-01,  2.7672e-01, -2.9636e-01,\n",
       "            -3.9641e-01,  7.5278e-03,  2.1805e-01, -3.5483e-02,  2.5775e-01,\n",
       "            -2.5528e-01,  2.5874e-01,  3.8837e-01, -5.2010e-02,  3.9548e-01,\n",
       "             6.2919e-02, -1.2299e-01,  1.7323e-01, -1.1596e-01,  2.3498e-02,\n",
       "             5.6532e-02, -9.7742e-02, -4.3929e-01,  2.4798e-01,  3.4409e-01,\n",
       "            -2.5306e-01, -1.0239e-01, -1.0510e-02,  1.1772e-01, -2.5843e-01,\n",
       "             9.9059e-02,  2.7084e-01,  6.5873e-02,  5.4408e-01,  1.1586e-01,\n",
       "             1.7559e-01, -5.9489e-02, -3.7661e-01, -5.1587e-01,  1.7438e-01,\n",
       "             1.0372e-01, -1.4780e-01,  2.3542e-01, -2.8163e-02, -1.5811e-01,\n",
       "             2.1477e-01,  5.0035e-02, -1.2899e-01, -1.9167e-01,  8.9899e-02,\n",
       "            -1.3355e-01,  5.9670e-02,  3.3541e-01,  1.2658e-02, -2.0256e-01,\n",
       "            -1.3213e-02, -1.9861e-01,  9.1569e-02,  2.2810e-01,  3.0863e-02,\n",
       "            -2.6227e-02,  3.2834e-01,  4.5715e-02,  1.0379e-01, -1.0369e-01,\n",
       "            -5.8758e-02,  3.0677e-02,  2.2679e-01,  2.0453e-01, -2.3859e-01,\n",
       "             1.9520e-01,  3.2177e-01,  3.5747e-01,  1.2608e-01, -7.2150e-02,\n",
       "             1.5695e-01,  1.1327e-01, -2.6335e-02, -2.2037e-01,  3.8620e-01,\n",
       "            -4.3491e-02, -7.8797e-02, -1.0211e-01, -3.4750e-01,  3.5579e-02,\n",
       "            -5.6878e-03,  2.7683e-01, -5.1555e-01,  4.8143e-01, -4.2368e-01,\n",
       "             2.1034e-01,  3.4022e-02,  3.0953e-01, -2.9424e-01, -2.7895e-01,\n",
       "            -1.7039e-01, -3.9817e-01, -3.5232e-01,  1.2675e-01, -9.8755e-02,\n",
       "            -3.1443e-01, -1.9892e-01, -2.2529e-01,  1.3841e-01,  1.0133e-01,\n",
       "             7.1382e-02, -1.3194e-01,  1.9355e-02, -5.8758e-02, -1.5120e-01,\n",
       "            -1.8935e-01,  1.3505e-02,  1.5130e-01,  1.9937e-01, -6.9287e-02,\n",
       "            -3.9556e-01, -1.0343e-01, -4.8068e-01, -1.6210e-01, -4.4130e-01,\n",
       "             2.8426e-02,  1.3269e-01,  2.4144e-01,  3.3130e-01,  1.1073e-01,\n",
       "            -3.0464e-01, -1.3445e-01, -5.8482e-02, -2.3377e-01, -1.7871e-01,\n",
       "             1.1104e-01,  2.8163e-01, -4.0509e-02, -2.3895e-01,  2.1502e-01,\n",
       "             1.2206e-02, -1.5090e-02,  1.5816e-01, -3.4177e-02,  1.6733e-01,\n",
       "            -2.9472e-01,  1.4205e-01,  1.7752e-01,  3.3579e-01, -1.5332e-01,\n",
       "             1.9624e-01,  4.5512e-01,  1.0007e-01,  4.6288e-03, -6.9685e-03,\n",
       "            -3.0142e-01,  9.0116e-02,  3.5684e-01, -1.9006e-01, -4.9910e-02,\n",
       "             2.2187e-01, -1.6636e-03,  1.8318e-01,  4.3547e-02, -2.2565e-01,\n",
       "             8.1148e-02,  1.5690e-01,  2.9861e-01,  1.6222e-01,  4.9749e-03,\n",
       "            -1.7582e-01,  1.5605e-01, -3.1773e-01, -7.0855e-02, -1.0836e-02,\n",
       "            -1.1278e-01, -5.1044e-01, -7.5143e-02,  3.9543e-01,  1.5987e-01,\n",
       "             1.2148e-01, -4.2851e-01, -2.5135e-01, -6.0832e-02,  2.4876e-01,\n",
       "             2.3636e-02,  2.4241e-01,  1.6532e-01, -4.1250e-01, -5.9359e-02,\n",
       "             1.0308e-01, -8.4393e-02, -4.9110e-02, -2.3513e-01,  2.1240e-02,\n",
       "             1.4141e-01,  2.3120e-02,  3.3713e-01,  4.3083e-01, -4.2689e-02,\n",
       "            -2.7249e-01,  4.4806e-01, -2.6087e-01, -2.3798e-01,  4.1510e-01,\n",
       "             1.1542e-01, -1.8960e-01, -1.7671e-01, -4.6092e-02, -9.3332e-02,\n",
       "             2.1468e-01,  1.2993e-01, -1.4026e-01, -1.0697e-01, -4.7149e-02,\n",
       "             5.0618e-01,  4.4626e-01, -8.9322e-02,  2.9990e-01,  1.2483e-01,\n",
       "            -3.9787e-01, -2.5843e-01,  8.0676e-02, -2.1331e-01, -1.8286e-01,\n",
       "            -2.9616e-01,  2.5638e-01, -7.2489e-02,  1.7196e-01,  3.8460e-02,\n",
       "             3.5060e-01,  1.1491e-01, -7.4479e-02,  1.8120e-01,  1.6733e-01,\n",
       "             1.6495e-01,  9.8708e-02, -1.5447e-02, -5.6140e-02,  1.1249e-01,\n",
       "            -3.0678e-01,  1.7874e-01,  3.1829e-01,  7.3447e-02,  9.5819e-03,\n",
       "            -1.6175e-02,  7.6526e-02,  2.0249e-01,  1.8178e-01, -2.8592e-01,\n",
       "            -4.6604e-01,  6.3149e-02, -1.5043e-01,  3.1331e-02,  3.2332e-01,\n",
       "             1.4671e-01,  1.3604e-01, -7.4629e-02, -2.2688e-01, -2.4109e-01,\n",
       "             3.3606e-02,  5.2448e-01,  1.1862e-01,  8.0110e-02, -1.5011e-01,\n",
       "            -5.5990e-02,  5.5697e-03,  3.1854e-01, -2.6512e-01,  3.1351e-02,\n",
       "             1.9554e-01, -5.7625e-01,  3.6940e-01,  1.4505e-01, -1.7307e-01,\n",
       "             3.1690e-01,  8.4390e-03, -1.2145e-01,  9.9986e-02,  6.2521e-04,\n",
       "             2.3204e-01, -5.0927e-02, -2.1221e-01, -4.5477e-02,  9.2081e-02,\n",
       "            -2.0894e-01, -3.8508e-01, -7.4952e-02,  2.9716e-01,  2.9097e-02,\n",
       "            -8.5913e-02,  6.6718e-03,  1.1408e-01, -1.6546e-01, -5.5639e-02,\n",
       "             1.7772e-01, -4.2855e-02,  3.1812e-01, -1.7046e-01,  1.1850e-01,\n",
       "            -8.4465e-02,  1.0739e-01,  3.0742e-02,  1.9078e-01,  1.4076e-01,\n",
       "             6.3577e-02,  3.0970e-02,  1.6428e-01, -1.0514e-01, -1.3427e-01,\n",
       "             8.5775e-02,  4.3087e-01, -1.6594e-01, -3.8700e-02, -1.6926e-01,\n",
       "             2.4989e-01, -6.3286e-02,  9.7926e-02,  2.4628e-01,  1.5795e-02,\n",
       "             4.7305e-02,  1.2721e-01, -2.0471e-01, -2.6707e-01,  2.3242e-01,\n",
       "             3.1362e-01,  1.8722e-01, -2.9227e-01,  1.0533e-01, -3.5398e-01,\n",
       "            -1.3733e-01, -8.7092e-02,  1.9326e-02, -4.8737e-01,  3.3545e-01,\n",
       "            -2.5045e-01,  2.5486e-01, -2.0073e-01, -1.0777e-01,  2.6146e-01,\n",
       "            -7.4975e-02, -1.4444e-01, -5.1101e-01,  1.2216e-01, -1.0112e-01,\n",
       "             8.2225e-02,  1.5077e-01,  1.5242e-01, -2.4319e-01, -3.9109e-01,\n",
       "             1.5904e-02, -1.6652e-01,  2.6281e-01,  3.6804e-02,  2.0568e-01,\n",
       "             2.1874e-01, -3.4992e-01, -7.4904e-02,  6.7979e-02,  1.0116e-01,\n",
       "             7.4509e-02, -9.5030e-02, -2.6252e-01, -2.7613e-01, -1.3710e-01,\n",
       "            -1.5299e-01, -1.7565e-01,  5.0864e-02,  9.9646e-02, -6.3561e-02,\n",
       "            -7.6830e-02,  1.3719e-01, -1.0065e-01, -6.8725e-02,  8.5825e-02,\n",
       "            -3.0678e-01,  1.7001e-01, -9.0986e-02,  2.6781e-01, -3.1587e-01,\n",
       "             1.2678e-01,  1.2574e-01, -1.5820e-01,  2.0803e-01,  1.2576e-01,\n",
       "            -2.1876e-02, -1.2667e-02, -3.6050e-01, -3.4577e-01,  2.1161e-02,\n",
       "             3.4113e-01,  4.1538e-01, -1.2355e-01,  1.4009e-01, -2.1637e-01,\n",
       "            -1.8293e-01,  2.3611e-01, -1.7867e-01,  2.0934e-01, -3.2152e-01,\n",
       "            -3.2389e-02,  4.2117e-01,  6.8569e-01, -1.7552e-01, -8.1326e-02,\n",
       "            -2.9344e-01, -6.1438e-01, -7.4465e-02, -7.5231e-02, -1.9219e-01,\n",
       "            -1.9296e-01,  2.3317e-01,  1.1497e-01, -2.3911e-01, -2.9045e-01,\n",
       "            -2.5082e-02, -3.0718e-01, -5.1674e-02, -6.7251e-01, -2.7603e-01,\n",
       "             1.3880e-01,  1.1624e-01,  1.4996e-01,  1.4502e-01, -3.6449e-02,\n",
       "            -2.3937e-01, -2.0241e-01, -1.6482e-01, -3.2870e-01, -2.7019e-02,\n",
       "             2.3525e-01, -1.9579e-01,  2.5362e-01, -4.9610e-01,  6.0067e-02,\n",
       "            -1.5768e-01,  2.2512e-01,  2.1160e-01, -8.5461e-01,  2.8022e-01,\n",
       "            -4.3357e-02, -2.1249e-01,  2.7428e-02, -8.9597e-03,  1.8228e-01,\n",
       "            -2.6040e-01,  8.6965e-02,  1.8765e-01,  2.3303e-01, -2.8957e-01,\n",
       "             4.0686e-01,  1.2345e-01, -2.8816e-01, -7.9866e-02, -5.6985e-01,\n",
       "             1.1931e-01,  2.1357e-01,  1.7645e-01, -9.7847e-02, -8.1493e-02,\n",
       "             1.4055e-01,  2.6549e-02,  2.3674e-01,  8.1950e-02,  1.5823e-04,\n",
       "             1.4272e-01, -3.6707e-02,  1.2330e-01,  1.0356e-01,  4.3528e-01,\n",
       "             2.4497e-01,  5.3600e-02,  8.7234e-01,  4.0418e-01, -3.6741e-01,\n",
       "            -1.5627e-01,  1.9387e-02,  4.1149e-01,  1.4810e-01, -3.6639e-01,\n",
       "             2.7003e-01, -5.1665e-01, -3.3822e-01,  1.5353e-01,  2.5867e-01,\n",
       "             5.4582e-02,  2.3540e-01,  1.8768e-01,  3.3108e-01,  4.4073e-02,\n",
       "            -2.3616e-02, -6.6283e-01,  1.2097e-01, -3.4246e-01, -1.6825e-02,\n",
       "             1.9815e-02,  5.0651e-01,  3.9904e-01, -1.0945e-01,  5.9156e-01,\n",
       "             7.1907e-02, -1.0906e-02,  2.2986e-01,  4.4285e-02, -5.9100e-01,\n",
       "             2.1339e-01,  9.7928e-02, -1.6739e-01, -2.8108e-02, -1.2925e-01,\n",
       "             3.7539e-01,  1.5150e-01, -1.2097e-01, -6.5700e-02,  5.0055e-03,\n",
       "             4.4880e-02, -7.9447e-02,  1.5435e-01, -2.7967e-01,  2.0141e-02,\n",
       "             7.0939e-02, -2.9961e-01,  1.2051e-01,  4.7866e-03,  1.7474e-01,\n",
       "            -9.2123e-02,  1.7772e-01,  7.1810e-02, -3.6981e-01, -1.6938e-01,\n",
       "            -5.8919e-01, -3.4771e-01,  3.3690e-01, -5.6165e-01,  1.6267e-01,\n",
       "            -1.8554e-01, -4.1451e-01, -5.8714e-01,  6.0918e-01,  2.3392e-01,\n",
       "             2.5312e-01, -1.8262e-02, -2.5091e-01,  1.5928e-01,  7.6053e-02,\n",
       "            -2.1234e-01, -4.8875e-01,  4.3673e-01, -3.5390e-01,  1.6398e-02,\n",
       "            -1.0780e-01,  2.9954e-01, -2.1064e-01,  6.2914e-01,  5.9052e-01,\n",
       "            -3.8666e-01,  3.6943e-01, -9.9222e-02, -6.8171e-01, -1.2516e-01,\n",
       "            -3.6105e-01,  2.7978e-01, -5.6498e-01, -5.5936e-01, -2.9484e-01,\n",
       "             4.3670e-01, -5.3140e-02, -1.9064e-01, -3.2385e-01, -6.8375e-01,\n",
       "            -2.1948e-01,  1.0540e-01, -3.3308e-01, -2.1435e-01,  3.5677e-01,\n",
       "             2.9310e-01,  3.4744e-02, -4.1702e-02, -5.9325e-02,  2.0962e-01,\n",
       "             1.1595e-01, -3.4992e-01, -1.8951e-01,  1.6967e-01, -2.4980e-01,\n",
       "            -3.2310e-01,  9.7148e-03, -2.7282e-01, -6.8938e-03, -9.4648e-02,\n",
       "             1.0349e-01,  1.5495e-01,  1.7759e-01, -2.7106e-01, -3.6052e-01,\n",
       "            -5.8433e-01, -1.4283e-01, -3.0009e-01,  2.7930e-01, -3.4858e-01,\n",
       "            -1.5575e-01,  5.0175e-01, -4.5056e-01,  2.2285e-01, -5.4570e-01,\n",
       "             3.0429e-01, -3.4337e-01,  3.6049e-01,  4.5270e-02,  2.3222e-01,\n",
       "            -2.1081e-01, -1.6124e-01, -1.3971e-01, -9.1122e-02, -1.1181e-01,\n",
       "             1.1453e-02,  5.2072e-01,  3.5636e-01, -3.4008e-01,  2.0883e-01,\n",
       "             2.7015e-01, -3.2863e-01, -2.6952e-01, -2.1301e-01, -3.1349e-02,\n",
       "            -1.9002e-01,  1.5127e-01, -7.7693e-01,  2.2978e-01, -2.1192e-01,\n",
       "             8.7195e-02, -5.3985e-01,  7.1770e-02, -2.1785e-01,  1.4311e-02,\n",
       "            -4.6833e-01, -6.5198e-02,  1.9967e-01, -7.2182e-01,  2.5507e-01,\n",
       "            -1.2842e-02, -2.5246e-02, -1.2761e-01, -1.5822e-02, -2.3464e-01,\n",
       "             4.9200e-01,  5.8897e-02,  3.4789e-01, -2.5971e-01, -9.9012e-02,\n",
       "            -2.2167e-02, -8.5291e-02, -5.2842e-02, -3.2856e-01,  4.8344e-02,\n",
       "            -2.5096e-01,  1.0547e-01,  8.7538e-02,  2.9988e-01,  1.3677e-01,\n",
       "             3.7673e-01,  3.1508e-01,  4.7810e-02,  3.5072e-01,  8.6341e-01,\n",
       "            -9.1603e-02,  2.6849e-02, -2.9176e-01, -3.0571e-01, -7.3630e-01,\n",
       "            -3.6906e-01,  4.7132e-01, -1.2538e-01,  1.6380e-01, -5.4306e-03,\n",
       "            -9.7697e-02, -4.0207e-01,  1.0174e-02, -2.4856e-01,  6.7894e-01,\n",
       "            -1.6758e-01, -8.0907e-02,  3.4654e-02,  7.5794e-02,  1.2769e-01,\n",
       "            -2.3026e-01, -3.4909e-02, -4.4228e-01, -1.4181e-01, -7.9247e-02,\n",
       "             1.0992e-01,  6.0823e-02, -1.0431e-01, -1.0550e-01,  4.0134e-01,\n",
       "            -2.2895e-01, -5.1321e-02,  4.6649e-01,  1.8101e-01, -3.2676e-01,\n",
       "            -3.2210e-01,  8.5908e-03,  4.1782e-02,  2.0956e-02,  6.9776e-01,\n",
       "            -8.4903e-03,  5.3417e-01,  2.1165e-01,  9.5142e-02,  4.6673e-01,\n",
       "             1.9766e-01, -3.5468e-02, -6.6688e-02,  2.8680e-01, -3.7093e-01,\n",
       "            -3.2262e-01, -2.9353e-01, -3.9564e-01, -1.8270e-01,  2.7309e-03,\n",
       "            -9.1592e-02,  5.4808e-01, -6.9609e-02, -2.9359e-01,  4.1274e-01,\n",
       "            -4.7223e-01, -2.7822e-01,  6.0425e-02,  1.2778e-01, -1.6951e-01,\n",
       "             3.2171e-01, -3.4955e-01, -1.1232e-01, -1.5403e-01, -1.2705e-01,\n",
       "             1.2420e-01, -3.1373e-01, -7.3659e-02, -1.0199e-02,  1.6284e-01,\n",
       "            -1.1651e-01,  3.2818e-01, -7.3881e-01, -1.0019e-01, -2.1853e-01,\n",
       "            -1.2499e-01, -1.7945e-01,  1.9903e-01,  6.7196e-02, -1.8638e-01,\n",
       "             7.7231e-01, -2.7463e-01, -1.6690e-01, -2.0753e-01,  2.6251e-01,\n",
       "            -3.4882e-02, -4.2674e-02,  5.0242e-01, -1.5256e-01, -6.0598e-02,\n",
       "            -3.3909e-01,  1.0309e-01,  1.1565e-01,  1.2524e-01,  1.2221e-02,\n",
       "            -1.7370e-01,  8.0084e-02,  2.0042e-01, -4.3843e-01, -4.6792e-03,\n",
       "             4.1989e-01, -2.9049e-01,  1.4180e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,\n",
       "             9338,   428,   443,  1758,  3532,   567,  2183,   253, 15501,   326,\n",
       "            14980,   310, 24038,  3420, 19156,   434,  3745,   281,  6635, 16256,\n",
       "               15,     0]])),\n",
       "  (tensor([[ 3.1623e-02, -3.4356e-01,  6.5531e-02,  2.4785e-01, -1.8802e-01,\n",
       "             4.6557e-02,  9.0838e-02,  2.9718e-01,  3.4732e-01,  1.9670e-01,\n",
       "            -9.4906e-02,  2.7369e-01,  1.3404e-01,  6.7274e-02,  1.6876e-02,\n",
       "             1.9581e-01, -4.2751e-02,  4.6913e-01, -1.3202e-01,  6.1719e-02,\n",
       "             2.0541e-01, -2.8512e-01, -3.9262e-01, -1.8822e-01,  1.1834e-01,\n",
       "            -3.9775e-02, -1.9861e-01,  7.5245e-02, -8.3194e-02, -3.2996e-01,\n",
       "             1.5393e-01, -9.2988e-03, -2.5336e-02, -1.3254e-01, -1.8533e-01,\n",
       "             9.0845e-02,  2.8906e-02, -7.0476e-02, -4.4547e-01,  1.4719e-01,\n",
       "             1.1688e-02, -4.1364e-01,  1.5157e-01,  1.0184e-01, -2.0279e-02,\n",
       "             1.0667e-01,  1.2584e-01, -2.6685e-01, -3.8014e-01, -4.0762e-01,\n",
       "             1.0227e-01, -3.0332e-01,  7.8783e-02,  8.4816e-02, -6.1133e-02,\n",
       "            -1.2575e-01, -4.2865e-01,  4.6186e-02,  1.9081e-01, -1.7164e-01,\n",
       "            -4.1219e-02,  3.2003e-01,  2.5806e-01, -1.1238e-01, -6.0347e-03,\n",
       "             2.3989e-01,  9.4297e-02,  1.2127e-01,  1.8287e-01, -4.1607e-01,\n",
       "             2.5473e-01, -4.2572e-02,  2.7585e-01,  1.9229e-02, -6.0406e-02,\n",
       "             2.7063e-02,  1.2247e-01,  2.6271e-01, -3.6504e-01, -1.7168e-02,\n",
       "            -1.0904e-01, -2.4461e-01, -3.5076e-01, -3.6706e-01, -7.6525e-02,\n",
       "             3.0174e-01,  4.3841e-01, -4.7812e-01,  2.6805e-01, -2.1631e-01,\n",
       "             1.6017e-01, -1.9245e-01,  3.7896e-01, -1.4552e-01, -2.6954e-01,\n",
       "            -1.4972e-01, -1.5901e-01, -3.0105e-01,  2.6155e-01, -1.6022e-01,\n",
       "            -3.1134e-01, -2.9141e-01,  6.4191e-02,  1.0041e-01, -2.2667e-01,\n",
       "            -3.0645e-01, -4.2160e-02,  1.0924e-01, -8.0038e-02,  1.2346e-02,\n",
       "            -1.6792e-01,  1.2675e-01,  1.7848e-01,  2.6947e-01,  1.4875e-01,\n",
       "            -5.8989e-01, -4.7094e-02, -5.6809e-02, -1.6648e-01, -7.8692e-01,\n",
       "            -2.2057e-01,  3.1354e-01,  2.0094e-01,  2.8032e-01,  7.6601e-02,\n",
       "            -2.7851e-01,  2.7745e-01,  4.2640e-02, -8.5726e-03, -4.9736e-02,\n",
       "            -2.2651e-01, -2.0263e-01, -1.8271e-01, -4.4406e-01,  2.2805e-01,\n",
       "            -5.9288e-02, -4.6518e-02, -1.0987e-01,  6.7069e-02, -1.7498e-01,\n",
       "            -5.3851e-02,  2.3114e-01,  1.9191e-01, -1.4495e-01, -1.8494e-01,\n",
       "            -1.2973e-01,  3.9422e-01,  4.0500e-01, -2.0989e-02,  1.3495e-01,\n",
       "             3.8065e-01, -1.3647e-01, -3.9415e-02, -8.2598e-02,  3.1876e-02,\n",
       "             4.5639e-01,  7.9151e-03,  2.0508e-01,  1.8355e-02, -2.8371e-01,\n",
       "            -2.6929e-02,  1.9002e-01,  1.2827e-01, -5.4043e-01,  1.4719e-01,\n",
       "            -1.9449e-02,  2.7154e-02, -2.8992e-01,  6.3410e-02,  4.4595e-02,\n",
       "             5.4439e-02, -1.8965e-02, -1.1859e-02,  1.4621e-01,  5.5507e-03,\n",
       "             7.0721e-02, -7.7064e-01, -2.9219e-01,  1.0198e-01,  2.2212e-01,\n",
       "             1.6140e-01,  3.3201e-01,  1.6042e-01, -2.7926e-01, -2.8183e-01,\n",
       "            -2.5829e-01,  2.3647e-01,  3.3043e-01, -3.6954e-01, -9.3266e-03,\n",
       "             4.6002e-02,  1.1096e-01,  3.2273e-01, -2.4492e-02, -1.3314e-01,\n",
       "            -2.1383e-01,  3.3800e-01, -1.5523e-01, -6.9624e-02,  4.8719e-01,\n",
       "             1.6704e-01, -2.2918e-01, -2.0491e-02, -2.0183e-01, -8.0203e-02,\n",
       "             2.3325e-01,  5.2440e-02,  6.3802e-02,  1.4929e-01, -1.6558e-01,\n",
       "             3.7073e-01,  1.9251e-01,  4.0699e-05,  4.3434e-01,  7.5979e-03,\n",
       "            -4.1956e-01, -1.4905e-01, -6.7009e-02,  1.3896e-01,  2.1708e-01,\n",
       "            -3.6739e-01,  3.2827e-01, -1.7602e-01,  1.7447e-01,  8.4330e-02,\n",
       "             4.7501e-01,  1.9728e-01,  1.3990e-01,  4.1830e-02,  5.6409e-02,\n",
       "             2.1421e-01,  2.7710e-01, -4.3748e-02, -4.9426e-02,  1.6241e-01,\n",
       "            -3.0688e-01,  1.5983e-01,  1.2477e-01,  1.2927e-01, -1.8922e-01,\n",
       "            -3.6768e-01,  2.2868e-01,  3.7264e-01, -1.0302e-01, -8.5048e-02,\n",
       "            -3.2938e-01,  5.1621e-02, -3.8114e-01,  9.6609e-02,  2.0549e-01,\n",
       "            -1.6618e-01,  3.4692e-01, -1.7491e-01, -3.1945e-01,  2.1862e-01,\n",
       "             2.4062e-01,  1.3335e-01,  9.6456e-02,  7.6871e-03,  4.3946e-01,\n",
       "            -2.2509e-01,  1.4726e-01,  7.1563e-01, -1.7308e-02,  4.3693e-01,\n",
       "             2.5098e-01, -4.7665e-01,  1.0739e-01, -1.6586e-02, -1.0557e-01,\n",
       "             1.4494e-01,  9.3966e-03, -2.1529e-02,  1.2317e-01, -1.3918e-01,\n",
       "             5.4651e-01, -8.1733e-02, -9.5146e-02, -1.5598e-01,  3.0938e-01,\n",
       "            -4.8507e-01, -1.8832e-01,  6.3719e-02,  3.9121e-01,  2.5021e-01,\n",
       "            -1.6706e-01,  3.6677e-02, -1.8914e-01,  9.8859e-02,  2.1330e-01,\n",
       "            -5.3717e-02,  2.3813e-01,  2.4912e-01,  2.3989e-01,  2.7557e-01,\n",
       "             7.2443e-02,  1.4682e-01,  1.4285e-01, -4.3297e-02,  1.1286e-01,\n",
       "            -1.6203e-01, -1.1775e-01, -1.1875e-01, -1.2312e-01,  1.4024e-01,\n",
       "             2.2589e-02,  5.1334e-01, -2.0563e-01,  3.0099e-02, -2.2956e-02,\n",
       "            -3.5516e-01, -3.8400e-01, -3.2013e-01,  1.6228e-01, -1.2077e-01,\n",
       "             2.0304e-01, -2.3959e-01, -1.8527e-01,  7.3900e-02,  2.7793e-01,\n",
       "             2.3660e-01,  1.3165e-01, -5.6740e-02,  5.3403e-01, -1.3671e-01,\n",
       "            -2.4031e-01, -1.7065e-02,  2.7329e-01, -3.5199e-01,  1.4362e-01,\n",
       "            -2.1338e-01,  2.6628e-01, -3.1054e-01, -1.0458e-01,  1.2539e-01,\n",
       "             1.4833e-01,  3.3691e-01, -3.2445e-01, -5.9264e-02, -2.7100e-02,\n",
       "             4.7352e-02,  3.2323e-01,  1.1996e-01, -3.3177e-01, -3.0061e-01,\n",
       "             8.6432e-02, -4.8235e-01,  2.7347e-01, -1.7976e-01,  8.4548e-02,\n",
       "             1.7776e-02,  1.6855e-01, -1.4660e-01, -1.7445e-01, -3.0742e-01,\n",
       "            -1.3241e-01, -1.2540e-01,  6.4588e-02, -4.6272e-02, -1.4528e-01,\n",
       "            -7.5351e-02, -1.5739e-01,  4.1194e-01,  2.4340e-01, -2.6295e-01,\n",
       "            -4.6231e-01,  1.4695e-01, -7.1651e-04,  1.0978e-01, -1.9032e-01,\n",
       "            -5.7480e-02,  2.3084e-01,  4.7477e-02,  1.7509e-01,  8.2248e-02,\n",
       "            -2.1755e-01,  1.6976e-01, -1.5684e-01,  1.5934e-01,  3.9761e-01,\n",
       "            -2.3772e-01,  7.4548e-02, -4.4558e-01, -1.6472e-01,  1.7180e-02,\n",
       "            -1.7001e-01,  7.2738e-01, -4.9036e-01,  1.9551e-01, -3.3268e-01,\n",
       "             4.7213e-02, -7.1690e-02, -2.0233e-01, -2.2508e-01, -2.3424e-01,\n",
       "            -9.3068e-02,  2.3083e-01, -2.9338e-02, -1.2560e-01, -6.7374e-01,\n",
       "            -1.3685e-01, -3.0713e-01, -3.5150e-01, -1.9710e-01, -3.4290e-02,\n",
       "            -5.3864e-01,  8.9367e-01,  1.1486e-01,  1.4962e-01, -2.1468e-01,\n",
       "            -7.1802e-01, -4.1915e-02,  8.9761e-02, -4.2449e-01, -1.4737e-01,\n",
       "             1.6489e-01,  4.5656e-01, -1.3342e-01, -2.2932e-02, -1.6053e-01,\n",
       "            -2.5406e-01, -5.4323e-01, -1.5840e-02, -8.7270e-02,  3.6812e-01,\n",
       "             2.0422e-01,  8.1163e-02,  5.6169e-02, -1.2522e-01, -1.4030e-01,\n",
       "            -4.4755e-01,  2.6402e-01,  2.8730e-01, -4.3232e-01, -1.2044e-01,\n",
       "             3.2832e-02, -1.2684e-01, -8.6038e-02, -5.9294e-01,  1.5983e-01,\n",
       "            -4.1454e-01,  6.4267e-02, -1.7970e-01,  9.6027e-02,  2.8311e-02,\n",
       "            -1.6355e-01,  1.4072e-02, -3.7777e-02,  1.7933e-01, -2.3575e-01,\n",
       "            -2.1818e-01,  6.7874e-01, -3.5732e-01, -2.9738e-01,  1.6371e-01,\n",
       "             3.4928e-01, -3.4791e-01, -2.9068e-01,  3.8762e-01,  2.8622e-01,\n",
       "            -1.3184e-01,  1.3887e-01, -4.3027e-02,  1.7348e-01, -5.6005e-02,\n",
       "             4.1157e-02, -6.5565e-02,  4.1655e-01,  6.0852e-01,  1.1156e-01,\n",
       "             2.5813e-01, -1.7617e-01, -5.1656e-01, -7.0120e-03, -4.7358e-01,\n",
       "             1.5539e-01, -3.0598e-01, -4.6295e-01,  1.4252e-01, -8.5898e-02,\n",
       "            -7.5464e-02,  4.6369e-02, -1.0019e-02,  1.9881e-01,  7.3943e-02,\n",
       "             2.2603e-01, -4.8798e-01,  1.5407e-01,  1.1992e-04,  5.1685e-02,\n",
       "             1.4385e-01,  4.0415e-02,  9.1972e-02,  3.7465e-01,  5.0049e-01,\n",
       "            -1.3361e-01, -1.9467e-01,  1.3710e-01, -3.0325e-01, -9.4015e-01,\n",
       "             2.1029e-02,  5.4909e-02, -1.4354e-01,  7.5753e-02, -2.1403e-01,\n",
       "             6.4179e-01,  1.0547e-01,  5.0379e-01,  3.3314e-01,  4.5358e-02,\n",
       "            -5.1258e-02, -5.7546e-02, -1.5191e-01, -2.0198e-02, -2.9167e-02,\n",
       "            -2.3837e-01, -1.3563e-01,  3.5549e-01, -6.3487e-02, -5.8851e-02,\n",
       "            -9.8549e-02, -4.0422e-05,  1.8915e-01,  3.5819e-02, -8.9946e-02,\n",
       "            -4.5630e-01,  2.4764e-03, -2.3765e-01, -2.5108e-01,  2.7888e-01,\n",
       "             1.4264e-02, -8.6585e-02, -6.8701e-01,  4.7851e-01,  1.8090e-01,\n",
       "             3.7627e-01, -2.0836e-01, -3.0918e-01,  3.2304e-01,  1.3266e-01,\n",
       "            -5.3221e-01, -5.8946e-01,  4.9293e-01, -2.1263e-01, -1.2397e-01,\n",
       "            -2.8610e-01, -1.3615e-01, -2.1689e-01,  2.0918e-01,  3.5956e-01,\n",
       "            -3.8427e-01,  7.5474e-02,  3.7070e-03, -1.4827e-01, -2.5639e-01,\n",
       "            -2.8556e-01, -3.4278e-03, -4.2511e-01, -1.6325e-01, -3.4678e-01,\n",
       "             2.0365e-01, -4.5355e-02, -1.9692e-01, -2.5300e-01, -7.1846e-01,\n",
       "             9.2379e-03, -8.6151e-02, -6.4825e-02,  2.0904e-01,  6.8319e-02,\n",
       "             4.5144e-01,  1.8387e-01,  4.3943e-04,  3.6157e-01, -8.0909e-02,\n",
       "             1.2338e-01,  6.8853e-02, -1.2011e-01, -2.7509e-02, -2.1569e-01,\n",
       "            -2.8830e-01, -1.2993e-02, -2.0893e-01, -1.0958e-01,  3.2946e-02,\n",
       "             3.9472e-01,  3.5945e-01,  3.4564e-01, -2.3923e-01, -2.5229e-01,\n",
       "             8.8117e-02, -2.2389e-01,  2.5124e-01,  2.5609e-01, -2.4209e-01,\n",
       "            -3.1014e-02,  2.9250e-01, -2.1787e-01,  3.0699e-01, -2.8523e-01,\n",
       "             5.3828e-01, -3.4067e-01,  4.5488e-01, -1.2307e-01,  2.2867e-01,\n",
       "            -6.9126e-02, -2.1471e-01,  1.8588e-02, -2.4667e-01,  9.4414e-02,\n",
       "             4.6568e-02,  1.2549e-01, -1.7399e-02, -1.0847e+00, -1.1959e-01,\n",
       "             8.9575e-02,  9.0849e-02,  7.1080e-02, -1.8089e-01, -2.1534e-01,\n",
       "             1.1259e-01,  4.5367e-01, -3.1495e-01,  3.3883e-02,  4.3099e-01,\n",
       "            -7.3953e-02, -2.6437e-01, -1.4959e-01,  5.1753e-01,  1.3646e-01,\n",
       "            -4.1217e-01,  1.6997e-01,  3.3564e-01, -1.8158e-01,  2.8226e-01,\n",
       "            -3.6528e-02, -2.7170e-01,  7.4004e-02,  1.1024e-01, -1.8644e-01,\n",
       "             4.3929e-01, -4.5702e-01,  1.9202e-01,  2.0458e-02, -1.8388e-01,\n",
       "             8.7761e-02, -1.3544e-01,  2.3581e-01, -4.1723e-01, -3.5287e-01,\n",
       "             6.0575e-02,  4.0300e-02, -9.4939e-02,  1.4788e-01,  2.3561e-01,\n",
       "            -7.7881e-02,  4.1226e-01, -3.0619e-01, -4.6131e-01,  3.3308e-01,\n",
       "             1.4558e-02,  7.7252e-02, -7.2566e-02,  5.8555e-02, -5.3177e-01,\n",
       "             2.9149e-01,  4.9056e-01, -5.2092e-01,  3.2864e-02, -3.2596e-01,\n",
       "            -1.6929e-01, -4.5262e-01,  1.9316e-01,  1.2350e-01,  4.4560e-01,\n",
       "             1.7827e-01, -1.8821e-01,  5.2827e-02, -5.2819e-02, -4.6999e-01,\n",
       "             1.4179e-01, -1.2648e-01, -2.4237e-01, -1.3746e-01, -2.2500e-01,\n",
       "             1.2467e-01,  8.3468e-03, -1.2231e-01, -5.4863e-02,  6.8457e-01,\n",
       "            -3.7499e-01,  2.8009e-01,  3.4190e-02,  3.8921e-01, -2.6794e-01,\n",
       "            -8.5784e-02,  1.7586e-01, -9.2658e-02, -8.7135e-02,  4.0704e-01,\n",
       "             6.8304e-02,  1.6808e-01,  1.4742e-01,  5.0908e-01,  8.5893e-02,\n",
       "             3.1866e-01, -2.3922e-01,  1.8762e-01, -1.4161e-01,  5.8721e-02,\n",
       "            -1.2295e-01, -7.1754e-02, -6.8061e-02, -4.4472e-01,  4.5917e-01,\n",
       "            -1.1217e-01,  1.9458e-01, -3.0647e-01,  2.8299e-01, -2.5589e-02,\n",
       "            -1.9536e-01, -5.9535e-01,  2.6334e-01,  1.2153e-02,  8.5082e-02,\n",
       "             8.2852e-02, -1.2770e-01, -3.7953e-02, -3.5327e-02,  8.4791e-02,\n",
       "             4.0111e-01, -3.4534e-01,  1.6211e-01,  2.5315e-01,  3.4908e-01,\n",
       "            -1.9641e-01, -6.8474e-02,  5.6101e-02,  3.3757e-01, -7.8325e-02,\n",
       "            -1.0081e-01, -4.2879e-01, -2.3860e-01,  1.3294e-01, -3.0521e-01,\n",
       "             2.0235e-01, -3.9017e-01, -8.4768e-02, -1.5827e-01,  1.5250e-01,\n",
       "             5.6958e-02,  1.4055e-01,  2.1748e-01, -8.2099e-02,  1.2696e-01,\n",
       "            -3.3227e-01, -1.7180e-02,  3.3081e-01,  1.5744e-02, -3.2478e-02,\n",
       "            -4.1596e-01, -4.8692e-02,  8.0913e-02, -3.2871e-01, -1.5850e-02,\n",
       "             5.9146e-01, -2.1633e-01,  5.0389e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,\n",
       "              281, 26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,\n",
       "              281,  3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,\n",
       "             4583,    15,     0]])),\n",
       "  (tensor([[-3.4791e-01, -3.8447e-01, -3.2296e-01,  8.2799e-02,  1.5801e-02,\n",
       "            -1.2534e-01, -2.3514e-01,  7.3981e-02, -9.6268e-02, -3.7791e-01,\n",
       "            -1.4916e-01,  9.1298e-03,  3.0230e-01, -1.0760e-01,  2.9573e-01,\n",
       "            -1.0806e-01, -1.4384e-01,  1.5319e-01, -5.4832e-03, -2.6034e-03,\n",
       "            -4.0013e-01, -2.2632e-02, -6.4852e-01, -9.2686e-02,  1.3187e-01,\n",
       "             1.6485e-01, -7.7111e-02, -2.4842e-02, -1.6513e-01,  1.5497e-01,\n",
       "             1.5925e-01, -5.9938e-02, -2.2914e-01,  1.5554e-01,  6.6562e-01,\n",
       "             1.7615e-01, -1.7793e-01, -4.0920e-01,  8.9877e-02, -8.6800e-02,\n",
       "            -7.3387e-02, -2.0531e-01, -3.5928e-03,  2.9478e-01, -1.5547e-01,\n",
       "             2.1179e-01, -1.6760e-02, -2.0945e-01,  9.7968e-02, -2.1914e-01,\n",
       "             5.3487e-02, -1.9567e-01,  8.9585e-03,  8.1743e-02, -4.3849e-02,\n",
       "            -2.8258e-01, -2.3910e-01,  3.7307e-01, -1.0854e-01, -2.8893e-03,\n",
       "            -1.1329e-02,  1.4465e-01,  2.6411e-02, -3.9609e-01,  9.1624e-02,\n",
       "             3.0249e-02,  8.8812e-03,  4.4450e-02, -6.7931e-02, -4.7976e-02,\n",
       "             1.8705e-01, -2.0103e-01,  1.6895e-01,  1.6038e-01,  2.0095e-01,\n",
       "            -1.3483e-02,  2.9712e-01, -3.7278e-01, -1.5555e-01,  1.7478e-01,\n",
       "             4.4171e-01,  4.2432e-02, -9.9483e-02, -1.5568e-01, -2.7050e-01,\n",
       "             1.5188e-01,  9.2271e-02, -2.3785e-01, -4.0384e-01, -2.7925e-02,\n",
       "             2.1851e-01,  7.3370e-03,  2.2532e-02,  3.6933e-02, -3.3080e-01,\n",
       "             1.5988e-01,  4.0952e-01, -3.4940e-01,  1.4564e-01, -2.8671e-02,\n",
       "            -3.1855e-01,  3.7955e-02, -1.7321e-01, -1.6598e-01,  1.1421e-01,\n",
       "             4.0976e-02, -2.0608e-01, -6.9080e-02,  1.6064e-01, -2.0197e-01,\n",
       "            -1.9747e-01, -2.8227e-01, -4.6704e-01, -6.9761e-02, -1.1359e-01,\n",
       "            -4.2990e-01,  1.1107e-01,  5.4326e-01,  3.4331e-01, -3.4706e-02,\n",
       "            -1.2731e-01,  4.2610e-02,  3.0338e-01,  6.0881e-02, -1.9162e-01,\n",
       "             3.4865e-01, -3.9792e-02, -5.0527e-01, -5.0294e-01,  1.6007e-01,\n",
       "            -7.0053e-02, -1.7274e-01,  1.8371e-01, -2.8551e-01,  2.1864e-01,\n",
       "             2.8814e-02,  7.1216e-02,  4.6220e-01, -1.1581e-01, -7.5401e-02,\n",
       "             8.2738e-02,  9.7679e-02,  3.3997e-01, -1.2718e-01, -4.3457e-01,\n",
       "            -1.1885e-01,  2.8175e-01,  3.0529e-02, -4.7395e-01, -1.7325e-01,\n",
       "             1.2200e-01, -2.7739e-01,  1.2946e-01, -6.6240e-02,  8.5723e-02,\n",
       "             1.5610e-01,  1.8220e-01,  1.6751e-01, -8.5562e-02, -3.1673e-02,\n",
       "             2.0094e-01,  4.5582e-01, -9.8807e-02, -8.7669e-02,  8.0734e-02,\n",
       "             5.3142e-01, -1.7515e-01, -1.6225e-01,  5.2466e-02,  4.7845e-02,\n",
       "             1.4528e-01, -1.8840e-02, -1.6455e-01,  3.2745e-01,  1.3164e-01,\n",
       "             5.6260e-02, -1.2022e-01, -5.6564e-02, -8.8529e-02, -3.7519e-02,\n",
       "            -5.8928e-02,  2.6389e-02, -4.2730e-02,  8.3254e-02,  2.7371e-01,\n",
       "             1.0547e-02, -4.7187e-02, -1.0122e-02,  2.3965e-01,  1.4183e-01,\n",
       "            -5.4787e-02, -6.1780e-02,  2.9004e-01,  2.6321e-01,  1.1571e-01,\n",
       "            -3.6322e-01, -5.1172e-02, -8.8875e-02,  3.2530e-01, -2.6639e-01,\n",
       "            -2.5458e-01, -1.9971e-02, -1.3958e-01, -1.9205e-01, -4.1523e-02,\n",
       "             1.6664e-01, -9.7926e-02, -1.0454e-01, -5.2229e-03,  2.6368e-01,\n",
       "            -1.1367e-01,  3.5285e-01,  1.1091e-02,  1.0067e-01,  2.3322e-01,\n",
       "            -1.0130e+00,  4.2517e-02, -2.2845e-01,  1.0338e-01,  1.6292e-01,\n",
       "            -1.1554e-01,  6.3953e-02,  1.0973e-01,  3.1438e-01,  2.0514e-01,\n",
       "             9.1436e-02, -6.0274e-02, -1.0752e-01,  4.5846e-01, -2.0723e-01,\n",
       "            -4.6265e-02, -3.0433e-01,  1.2913e-01,  1.2241e-01, -1.1479e-01,\n",
       "            -2.5970e-01, -1.2031e-01, -1.1590e-01, -2.3779e-01, -8.9721e-02,\n",
       "            -5.9639e-02,  1.1342e-01,  5.6319e-01, -2.1386e-01,  6.4817e-02,\n",
       "            -2.7500e-01,  1.5360e-01,  2.2215e-02, -1.4362e-01, -1.8993e-01,\n",
       "             4.2169e-02,  1.0876e-01, -1.2492e-01, -2.0841e-01, -2.5446e-01,\n",
       "             2.1356e-01,  5.6900e-02,  2.2369e-01, -2.1540e-01, -6.1087e-03,\n",
       "            -2.8892e-01,  1.4037e-02,  6.5244e-02, -1.9609e-01,  1.2135e-01,\n",
       "             2.9754e-01, -1.5326e-01,  5.1418e-01, -1.5759e-02,  8.3850e-02,\n",
       "            -1.6780e-01,  9.2371e-02, -4.3186e-01,  5.3811e-02,  1.6469e-01,\n",
       "             2.3605e-01,  2.2655e-02, -1.4554e-01, -4.1217e-01, -2.0291e-01,\n",
       "            -1.2563e-01,  4.1287e-02, -4.0294e-04,  5.2008e-02,  1.9361e-01,\n",
       "            -5.2273e-02, -2.6033e-02,  3.5311e-01, -1.1907e-01, -2.7445e-01,\n",
       "             1.9606e-01, -4.9500e-01,  8.0681e-01, -6.6183e-02,  7.0196e-01,\n",
       "            -2.9194e-02, -6.0007e-02, -3.1382e-01, -7.4001e-02,  1.3650e-01,\n",
       "             6.0418e-04, -2.5810e-01,  1.9948e-01,  1.9865e-02,  6.5198e-02,\n",
       "             5.1989e-02, -2.7936e-04, -6.2254e-02, -3.6125e-01,  2.3647e-02,\n",
       "             4.1659e-01,  1.6378e-01, -1.9063e-01, -1.0061e-01, -4.3962e-02,\n",
       "             3.6903e-01, -2.4114e-01,  2.3937e-01, -4.7606e-03, -1.8529e-01,\n",
       "            -3.5965e-01, -2.2341e-01, -5.8812e-02,  1.6965e-02, -9.1593e-02,\n",
       "            -6.8841e-02,  1.0071e-01,  1.0073e-02, -3.0566e-01, -2.1007e-01,\n",
       "            -1.3550e-01,  1.9073e-01,  8.6961e-02,  5.7094e-02, -1.5959e-01,\n",
       "            -9.2772e-02, -9.0277e-02, -9.0700e-02, -7.4141e-02, -9.6105e-03,\n",
       "            -1.9442e-01, -1.0972e-01, -2.5544e-01, -1.5752e-01, -4.5312e-01,\n",
       "             6.7783e-02,  4.5998e-02,  2.4656e-01, -9.6815e-02, -1.0113e-01,\n",
       "             2.6542e-01,  6.8669e-02,  1.4766e-01, -6.8491e-02,  2.6338e-02,\n",
       "             1.8396e-01, -1.1071e-02, -1.7733e-01,  1.3416e-01, -4.6616e-02,\n",
       "             7.7168e-02, -4.9533e-02,  1.3965e-02, -1.3679e-02,  9.8800e-02,\n",
       "             2.1629e-01, -2.1599e-01,  8.8092e-02, -3.7338e-01, -9.5619e-02,\n",
       "            -9.1532e-02,  3.0675e-02, -1.8818e-01,  7.6928e-02,  6.2934e-02,\n",
       "            -1.9292e-01, -3.9204e-01, -2.3919e-01,  1.2084e-01,  7.7115e-02,\n",
       "             2.7784e-01, -1.0182e-01, -3.5695e-01, -2.5400e-01,  3.8241e-01,\n",
       "             9.7170e-03,  3.2814e-03,  1.9805e-01, -8.2625e-02,  2.5611e-01,\n",
       "            -7.8153e-02,  1.4551e-01, -1.9627e-01,  5.3334e-01,  2.1486e-01,\n",
       "            -6.8202e-03,  2.2548e-01,  6.4306e-01,  2.5193e-01, -6.6489e-01,\n",
       "            -2.2701e-01,  1.6736e-01, -1.4995e-01, -1.2448e-01, -2.2051e-01,\n",
       "            -8.8151e-02, -6.4981e-02,  1.7571e-01, -1.4317e-01, -2.7883e-01,\n",
       "             9.8147e-02, -1.4283e-01, -6.3917e-02,  1.3637e-01,  3.3318e-01,\n",
       "             4.9104e-02, -3.7605e-01,  2.2858e-01,  1.2428e-01,  1.9122e-01,\n",
       "            -1.8598e-02, -2.1197e-01,  1.6195e-01, -6.2726e-01, -1.7605e-01,\n",
       "            -1.6151e-01,  6.5875e-02, -1.9491e-01,  2.9134e-01,  3.1839e-01,\n",
       "            -1.6505e-01, -2.7710e-01, -1.8375e-01, -6.0779e-01, -1.8874e-01,\n",
       "            -6.7109e-02, -4.1994e-02, -4.1487e-01, -4.9935e-02, -2.2834e-01,\n",
       "            -1.2516e-01,  1.6689e-01,  8.9916e-01,  1.3372e-01,  1.6257e-01,\n",
       "            -7.8526e-02, -4.1251e-02, -4.7276e-01, -3.5907e-01,  8.5864e-02,\n",
       "            -2.4624e-01,  7.3496e-02,  3.1677e-01,  1.1364e-01,  2.1178e-01,\n",
       "             4.8724e-01,  1.1175e-01, -5.5741e-01, -3.2681e-01,  4.1041e-01,\n",
       "            -1.1459e-01,  1.5966e-01, -3.2258e-01, -3.3669e-01,  5.2415e-01,\n",
       "             7.0848e-01,  9.1015e-02,  6.4009e-01,  1.6898e-01,  5.3566e-02,\n",
       "             3.2952e-01,  1.0980e-01,  2.1170e-01, -1.9834e-01,  3.1973e-01,\n",
       "             2.1104e-01,  9.6821e-02, -6.5153e-01, -4.3796e-02,  1.0486e-01,\n",
       "             3.6428e-02,  3.0252e-01,  5.1998e-02,  3.5075e-02,  3.3688e-01,\n",
       "             5.2536e-02, -3.4791e-01, -1.2911e-01, -4.3158e-01, -3.5748e-01,\n",
       "            -3.7929e-01, -2.8187e-01,  4.2064e-01,  2.2513e-02,  1.8233e-01,\n",
       "            -2.0632e-01, -4.5249e-01,  2.0037e-01, -1.7252e-01, -1.0726e+00,\n",
       "             2.5025e-02, -1.1771e-01, -1.9506e-01,  1.5371e-01, -6.8946e-02,\n",
       "            -3.3907e-01, -2.6554e-01,  2.0981e-01, -2.0715e-01, -1.4506e-01,\n",
       "            -7.1685e-02, -4.0484e-02,  2.1565e-01, -8.4965e-02,  4.5844e-01,\n",
       "             1.1963e-01, -1.8710e-01, -1.9166e-01, -2.2232e-02, -2.4458e-01,\n",
       "            -1.4580e-01,  3.6376e-01,  3.6575e-01, -3.7757e-01, -1.0752e-01,\n",
       "             1.1277e-01, -2.5434e-01, -7.9387e-02, -1.9212e-02, -2.5248e-02,\n",
       "             1.1904e-01, -1.2845e-01, -2.7415e-01, -3.3720e-01,  1.9031e-01,\n",
       "             5.2141e-01,  4.1104e-02, -4.2267e-01, -4.2410e-02, -5.3546e-02,\n",
       "            -1.3655e-01,  2.3053e-01, -1.6195e-01,  1.2749e-01, -4.0316e-01,\n",
       "            -1.2522e-01, -1.6857e-01,  5.8619e-02,  2.0315e-01, -2.2585e-01,\n",
       "             3.3740e-01,  4.3348e-02, -3.0321e-01, -9.5042e-02,  2.0467e-01,\n",
       "             4.8825e-02, -1.1009e-01,  5.1275e-02,  5.2346e-02, -1.3266e-01,\n",
       "             3.2966e-01,  4.2637e-01, -1.8128e-01, -7.6716e-02, -4.5651e-01,\n",
       "            -3.9319e-03, -7.8232e-02,  1.3316e-01, -2.7475e-02,  3.7631e-01,\n",
       "             2.3960e-02, -1.9874e-01, -2.1216e-02,  2.3296e-02,  1.2719e-01,\n",
       "             2.8503e-01, -3.7294e-01,  4.0796e-01, -1.7433e-01,  2.6202e-01,\n",
       "            -2.0340e-01,  2.3677e-01,  9.9597e-02,  4.2657e-02, -2.0379e-02,\n",
       "             1.2790e-01, -1.6200e-01,  2.9168e-01,  1.0688e-01, -6.1294e-01,\n",
       "            -3.6053e-05,  7.1539e-02,  1.5687e-01,  2.9632e-01,  4.7905e-02,\n",
       "             2.6724e-01,  7.2904e-02, -3.1394e-01,  2.4703e-01, -9.1835e-02,\n",
       "             1.9963e-01,  1.9168e-01,  1.6062e-01,  3.6341e-01, -4.3910e-02,\n",
       "            -3.4876e-04, -6.5256e-01,  6.5519e-03, -2.4831e-01, -1.3233e-01,\n",
       "             1.0282e-01, -1.0501e-02,  3.2548e-01, -3.9302e-02, -7.8472e-02,\n",
       "            -1.8882e-01,  1.5873e-01, -1.9870e-01, -1.4239e-01,  3.0561e-01,\n",
       "             2.4946e-02,  3.0131e-01, -6.4722e-01,  5.2985e-01, -1.6821e-01,\n",
       "             5.3708e-02, -7.4867e-02,  2.4291e-01, -4.3374e-01, -2.5929e-01,\n",
       "             1.2188e-01,  1.7839e-01,  1.5919e-01, -2.9162e-02,  5.3332e-01,\n",
       "             1.7574e-02, -2.5368e-01, -1.7228e-01, -2.0125e-01, -2.4663e-01,\n",
       "             7.0759e-02, -5.0013e-02, -5.0777e-02,  2.4127e-01,  1.0713e-02,\n",
       "             3.6847e-01,  3.0552e-01, -2.7205e-02,  5.7517e-01, -3.9125e-01,\n",
       "            -1.5236e-01, -5.2831e-01,  4.6349e-01, -1.0424e-01, -4.7434e-02,\n",
       "            -1.9881e-01,  2.1166e-01, -1.6900e-01,  3.0531e-01,  1.4093e-01,\n",
       "            -1.0092e-01, -1.6057e-01,  9.0822e-03, -4.2324e-01, -6.9512e-01,\n",
       "            -1.1400e-01,  3.2288e-01, -2.1693e-01,  6.4254e-02, -2.2301e-01,\n",
       "             2.6417e-01, -1.1715e-01, -1.9574e-02,  1.0386e-01,  2.5213e-01,\n",
       "             3.5444e-01, -2.4416e-01, -7.5323e-03,  2.6103e-01, -6.4503e-01,\n",
       "             1.0542e-02,  1.6419e-01, -8.6751e-02, -2.7577e-01, -2.1367e-01,\n",
       "             5.2344e-01,  5.0197e-01,  9.6086e-02,  1.3986e-01, -1.1108e-01,\n",
       "             3.9141e-01, -2.1440e-01,  5.4616e-02,  9.5757e-02,  5.0169e-02,\n",
       "            -6.3904e-02,  2.9899e-02,  3.2866e-01, -2.1503e-01, -9.4982e-03,\n",
       "            -2.7921e-01,  3.1443e-02,  1.6375e-01, -4.1465e-01,  4.2678e-01,\n",
       "             4.6967e-01,  2.3601e-01, -2.9830e-01,  4.4525e-02, -1.9886e-01,\n",
       "            -5.4031e-01, -2.7022e-02, -8.6288e-02,  8.5971e-02,  2.7996e-01,\n",
       "            -1.9458e-01, -2.0214e-01, -3.9521e-01, -4.1784e-01,  1.8689e-01,\n",
       "            -6.4724e-01, -2.7577e-03, -3.6677e-02,  3.0836e-01,  1.2777e-01,\n",
       "             4.4524e-01, -1.8782e-01,  8.2429e-02,  1.6767e-02, -2.9061e-01,\n",
       "             2.3117e-02,  1.5341e-01,  3.6575e-02,  1.0934e-01,  1.8488e-01,\n",
       "             2.6737e-01,  1.6400e-01, -3.4256e-01, -3.1028e-01, -7.3285e-02,\n",
       "             1.5509e-01, -1.6965e-01,  1.7646e-01,  7.2611e-02, -2.4566e-01,\n",
       "             8.8826e-02,  2.6854e-01, -8.0998e-02,  2.9996e-03,  4.0502e-01,\n",
       "            -6.5759e-02,  3.0975e-01,  2.7345e-01, -8.0791e-03, -9.3187e-02,\n",
       "             2.6752e-01, -1.0339e-01,  2.9408e-01, -7.5119e-02, -5.5631e-01,\n",
       "            -4.0464e-01,  1.5098e-01, -8.8195e-02,  1.2920e-01,  5.4685e-01,\n",
       "             1.5015e-01, -1.4501e-01,  6.6814e-02]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,   247,\n",
       "            16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,   567,\n",
       "              285,   399,    15,   378,    15, 34167,   323, 41069,    15,   733,\n",
       "              310,   271, 15644,   273,   329, 16865,   273, 22078,   285,  8726,\n",
       "               13,  6086,   416,    15,   416,    15,  8698,   434,  2962,   273,\n",
       "            16879, 19204,    13,   253,   806,   273,   534,   310,   329, 10850,\n",
       "              273,   596, 22334,    15,   380,   921,   369,  1097,  4197,   285,\n",
       "            32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,    15,\n",
       "                0]])),\n",
       "  (tensor([[ 3.5370e-01, -4.9419e-02, -2.2692e-01,  1.3179e-01,  6.5528e-02,\n",
       "             1.9719e-01,  1.6841e-01,  1.4474e-01,  1.3580e-01, -8.7032e-02,\n",
       "            -6.3276e-03, -1.7097e-01, -1.4173e-01, -2.6931e-02, -1.0992e-01,\n",
       "            -1.2557e-01, -2.9759e-01,  2.9731e-01, -1.4904e-02, -5.8066e-02,\n",
       "            -2.5083e-01,  1.2201e-01, -1.4797e-01,  9.6371e-02, -5.2242e-02,\n",
       "             2.8156e-01, -2.5112e-01, -1.2283e-01, -4.7515e-01,  1.0429e-01,\n",
       "             2.1733e-01,  9.8732e-02,  1.3068e-01,  2.0399e-01, -8.6940e-02,\n",
       "            -1.8154e-01, -1.9956e-01, -2.7469e-01, -2.8802e-01,  2.2545e-01,\n",
       "            -3.7121e-01, -1.6691e-01,  9.3970e-02, -1.3578e-01,  5.4671e-03,\n",
       "             9.4601e-02,  2.4480e-01, -2.2383e-01, -3.6424e-01, -4.0427e-02,\n",
       "            -5.6291e-02, -8.2478e-01,  5.4343e-01, -2.7711e-01, -7.6199e-02,\n",
       "             9.7222e-02, -4.3580e-01, -2.6827e-01,  5.5845e-02,  7.9445e-02,\n",
       "            -2.7045e-01,  8.8748e-02, -5.6934e-03, -2.6121e-01,  3.8008e-01,\n",
       "             2.8817e-01, -5.3420e-02, -1.1315e-01,  1.2582e-01, -2.7185e-01,\n",
       "             3.3930e-01, -3.2866e-02, -7.1036e-02, -3.5688e-01, -1.8308e-01,\n",
       "            -6.8632e-02,  1.8929e-01,  2.6889e-01,  2.0205e-01, -7.8049e-02,\n",
       "            -2.0913e-02,  3.8526e-02,  6.2225e-02, -2.9201e-01, -7.6603e-02,\n",
       "            -1.4567e-02,  2.2172e-01, -2.1750e-01,  6.9221e-02,  5.0152e-02,\n",
       "             1.5813e-01, -1.5710e-01,  2.1151e-01,  4.5294e-01, -1.3768e-01,\n",
       "            -3.3266e-01, -2.4250e-01, -5.6792e-01, -4.7295e-01,  1.1824e-01,\n",
       "            -3.3402e-01, -1.3111e-01,  3.2111e-01, -2.1126e-01,  2.2188e-01,\n",
       "            -1.6987e-01,  9.7648e-02,  2.7303e-01, -1.2088e-01, -7.3103e-02,\n",
       "            -1.9926e-01,  1.2529e-01,  1.7609e-01,  1.5298e-01, -5.6694e-02,\n",
       "             5.5221e-02,  3.2381e-01,  2.9417e-01, -1.1252e-01, -2.4274e-01,\n",
       "            -5.1054e-01,  8.0440e-02,  1.1249e-01,  2.9109e-01, -6.3453e-02,\n",
       "             1.8063e-01,  2.7572e-01,  4.3198e-02,  1.4002e-01, -2.4731e-01,\n",
       "            -6.9371e-02, -1.9817e-01, -3.8114e-02,  2.0013e-01,  4.7491e-01,\n",
       "            -3.0187e-01, -4.7824e-01,  2.1205e-01,  8.2927e-02, -1.1040e-01,\n",
       "            -1.7527e-01,  2.8854e-01, -8.6488e-02, -4.1055e-01,  7.2049e-02,\n",
       "            -9.8965e-02, -1.4512e-01,  8.7141e-02, -2.6871e-01, -2.3868e-01,\n",
       "             3.2706e-01, -8.6848e-02,  2.6633e-01, -2.1545e-01,  6.1692e-02,\n",
       "             5.6382e-02, -2.7660e-01,  5.7718e-01, -3.1879e-01, -1.3496e-01,\n",
       "            -5.2373e-01,  8.6399e-02,  1.6930e-01, -4.1097e-01,  2.9929e-01,\n",
       "             5.6136e-01,  2.7233e-01, -3.0717e-01, -8.2541e-02, -8.6230e-02,\n",
       "             1.9582e-01,  7.5196e-01, -2.5801e-01,  1.3162e-01, -6.5791e-02,\n",
       "            -1.7215e-02, -2.9313e-01, -4.6430e-01,  1.8311e-01,  3.7104e-01,\n",
       "            -6.7287e-02, -4.5176e-01, -1.4887e-01, -1.3243e-01, -3.0150e-01,\n",
       "            -1.3472e-01,  2.0463e-01,  1.8273e-01,  7.4384e-03, -2.5545e-01,\n",
       "            -1.5626e-01,  1.2075e-01,  4.0976e-01, -1.1212e-01,  1.2186e-02,\n",
       "            -2.4968e-01, -2.2282e-01,  1.2848e-01,  1.5749e-01,  1.2410e-01,\n",
       "            -3.0855e-02, -1.8749e-01,  7.1589e-03, -2.5970e-01, -1.6752e-01,\n",
       "            -3.2473e-01, -1.6982e-01,  1.6623e-01, -7.1222e-02,  1.2546e-01,\n",
       "            -3.6045e-03,  1.1286e-01,  1.9647e-01, -2.1318e-02, -1.5326e-01,\n",
       "            -3.1274e-01,  1.7856e-01, -1.5907e-01,  3.0807e-01,  5.4110e-01,\n",
       "            -4.2083e-01,  1.2196e-01,  2.8795e-01,  7.4369e-02, -2.5307e-01,\n",
       "            -2.4565e-01, -1.7357e-01,  1.6510e-01,  2.9183e-01, -2.4580e-01,\n",
       "             6.5945e-02, -3.9257e-01,  1.1262e-01, -7.5474e-02,  2.5697e-02,\n",
       "            -2.8534e-01,  1.2940e-01,  2.7990e-02, -1.5712e-01, -2.7342e-01,\n",
       "             5.9551e-02,  3.1960e-01,  6.7186e-01,  4.8784e-02, -1.1517e-01,\n",
       "            -3.3341e-01,  2.4643e-02,  4.1708e-02,  3.5316e-02,  1.3275e-02,\n",
       "            -2.5654e-01,  1.1662e-01, -1.7842e-01, -1.5504e-01, -5.7745e-02,\n",
       "            -3.0954e-02, -1.9309e-01, -4.1983e-02,  1.7518e-01,  6.0795e-01,\n",
       "            -1.3390e-01,  7.7244e-02,  3.5337e-01,  2.5740e-01,  2.1731e-01,\n",
       "            -1.7989e-02, -3.4862e-02, -1.2596e-01,  1.7119e-01,  2.9911e-01,\n",
       "            -1.4903e-02,  5.2372e-03,  2.2494e-01, -4.9473e-01, -7.1342e-03,\n",
       "            -3.2969e-02,  4.3716e-01, -2.0213e-02, -1.0984e-01,  6.2415e-02,\n",
       "            -5.2640e-02, -5.5533e-02,  2.0421e-01,  9.9873e-02,  5.1270e-02,\n",
       "             3.2602e-01,  5.3028e-01,  4.3557e-01,  4.3001e-01, -1.2116e-01,\n",
       "            -4.7284e-02, -9.6568e-02, -1.6398e-01,  9.7057e-02,  1.3453e-01,\n",
       "            -3.3331e-02,  2.3822e-01,  3.2348e-01,  7.3658e-02, -7.3808e-02,\n",
       "             8.8741e-02, -2.4727e-01,  2.2991e-01,  8.0521e-02, -1.8588e-02,\n",
       "            -1.8336e-01,  3.4686e-01, -2.4746e-01,  2.5805e-01,  3.6045e-01,\n",
       "            -3.5346e-01,  5.8047e-02, -1.9218e-01,  2.2451e-01, -1.6405e-01,\n",
       "            -1.6811e-01, -6.6257e-02, -6.5691e-02,  1.5937e-02,  4.6383e-01,\n",
       "            -1.6835e-01,  1.3782e-01,  1.7535e-01,  3.0643e-01,  1.9599e-01,\n",
       "            -2.9543e-01,  1.8974e-03,  4.6272e-02, -5.0327e-01,  3.7911e-01,\n",
       "            -1.8806e-01, -2.4783e-01, -1.2848e-01,  1.6225e-01,  6.7265e-02,\n",
       "             3.6749e-01,  7.1597e-02, -7.1396e-02, -3.9353e-01, -1.6645e-02,\n",
       "            -8.3279e-02,  1.2974e-01, -3.8768e-02, -6.9308e-03, -4.1132e-01,\n",
       "            -9.2836e-02, -1.3242e-01, -1.8155e-01, -4.4884e-03, -5.8650e-02,\n",
       "            -8.0870e-02, -2.9620e-02,  5.6629e-02, -3.2917e-01, -1.6092e-01,\n",
       "            -1.9059e-01,  7.9515e-02,  6.3630e-02,  8.2210e-02, -7.1410e-02,\n",
       "             3.9599e-02, -1.6350e-01,  1.4695e-01,  2.1161e-01,  3.6725e-01,\n",
       "            -8.4630e-01, -7.9913e-02, -1.6719e-01,  1.9099e-03, -1.1493e-01,\n",
       "             1.4953e-01,  1.7247e-01,  1.8792e-01, -5.4925e-02,  7.3333e-02,\n",
       "             9.1457e-02, -1.0674e-01, -1.3744e-01, -6.0101e-02, -1.7413e-02,\n",
       "            -1.0996e-01, -1.2069e-01, -2.6607e-01,  1.1836e-02,  3.1036e-01,\n",
       "            -1.3576e-01,  4.8117e-01, -3.3896e-02,  2.0526e-01,  2.3651e-02,\n",
       "            -3.3568e-02,  1.8071e-01,  7.2526e-02,  4.9748e-01, -1.3687e-01,\n",
       "            -3.6589e-02, -1.2899e-01, -4.5243e-02,  1.8739e-01, -3.2512e-01,\n",
       "             3.3552e-01,  1.0700e-02, -1.6428e-01, -8.9463e-02,  9.0952e-02,\n",
       "            -4.9187e-02,  6.7830e-02,  2.1129e-01,  1.6053e-01, -8.3719e-02,\n",
       "            -8.5279e-01, -2.4085e-02,  8.6446e-02, -1.1149e-01, -1.9564e-01,\n",
       "            -9.7286e-02,  9.3530e-02, -1.0870e-01, -3.4320e-01, -1.5546e-01,\n",
       "             1.0227e-01, -5.9357e-01,  4.0274e-01,  5.0725e-01,  4.4088e-01,\n",
       "             3.3999e-01,  3.6678e-02,  7.8927e-02, -2.0573e-01, -1.7678e-01,\n",
       "             2.2116e-01,  1.3384e-01,  2.6939e-02,  1.7552e-01, -5.7221e-02,\n",
       "             4.0046e-01,  4.1305e-01, -7.8813e-02, -1.6517e-01,  2.1822e-01,\n",
       "             1.4293e-02,  6.6999e-02,  1.4627e-01,  5.8781e-04,  1.9994e-01,\n",
       "            -4.4174e-01, -2.7824e-01, -6.6855e-02, -2.3047e-01,  1.4988e-01,\n",
       "             4.7609e-02,  3.8112e-02, -3.7992e-01,  5.1836e-02,  1.1019e-01,\n",
       "             1.3065e-01, -2.9896e-01, -1.7389e-01,  1.1796e-02,  9.6548e-02,\n",
       "             1.8039e-01,  1.0445e-01, -3.3283e-01,  8.2259e-02, -7.0004e-02,\n",
       "            -4.5845e-02, -1.3819e-01,  1.2451e-01,  4.0612e-02,  6.5403e-02,\n",
       "             3.6437e-01,  2.5557e-01, -8.7137e-01,  3.4333e-01, -5.9322e-01,\n",
       "             2.2698e-02,  2.4854e-01, -5.6019e-01, -2.2451e-01,  1.4407e-01,\n",
       "            -2.2321e-01, -7.5625e-02, -3.6518e-01, -7.8293e-02, -7.4201e-02,\n",
       "            -3.4238e-01,  6.1598e-02,  4.7271e-01,  5.8255e-02, -5.2948e-01,\n",
       "             6.9577e-02, -2.9823e-01, -5.3597e-02,  4.1210e-01,  5.0586e-01,\n",
       "            -2.0907e-01, -4.4513e-02,  2.4953e-02,  1.4477e-01, -4.0644e-01,\n",
       "            -1.9381e-01,  1.8625e-01,  2.7124e-02, -1.9405e-01, -1.2039e-01,\n",
       "             5.9178e-01, -8.5873e-02,  3.0958e-02,  2.1861e-01, -2.6536e-01,\n",
       "             4.1866e-02, -2.4233e-02, -2.4514e-01, -5.1183e-02,  8.9223e-02,\n",
       "            -3.1059e-01,  2.6508e-01,  4.5214e-02, -2.8762e-02, -6.2415e-02,\n",
       "            -2.0062e-01, -3.3525e-01,  4.0959e-01,  2.3942e-02,  1.0907e-01,\n",
       "            -2.4594e-01, -8.3418e-02, -4.1868e-01,  6.9423e-02,  2.6896e-01,\n",
       "             1.3720e-01, -1.7279e-01, -4.2218e-01, -3.6610e-01, -8.9633e-02,\n",
       "             3.0789e-01, -3.9913e-01,  4.3491e-02,  3.6636e-01,  1.1012e-02,\n",
       "            -5.2627e-01, -3.2684e-01,  1.3625e-01,  3.3512e-01, -3.7224e-01,\n",
       "            -3.0513e-01, -5.6540e-01, -5.3868e-02,  1.2119e-01,  3.1523e-01,\n",
       "            -8.6752e-02, -9.3566e-02, -3.5507e-02, -8.1049e-02, -4.3400e-01,\n",
       "             2.4204e-01, -9.2965e-02, -1.2994e-01,  6.7521e-01, -3.4967e-01,\n",
       "            -2.0112e-01, -2.1040e-02, -6.7576e-02,  7.3515e-03, -2.1137e-01,\n",
       "            -8.5685e-02,  4.4689e-01,  1.4394e-01, -3.2800e-01,  4.7435e-02,\n",
       "             2.2136e-01,  9.4733e-02, -1.2226e-01, -1.2546e-01, -4.2677e-01,\n",
       "             1.0785e-01,  1.0774e-01,  1.0106e-01, -1.0449e-01,  8.4132e-02,\n",
       "             1.3040e-01, -1.8767e-01,  1.7578e-01,  4.9621e-01,  3.4100e-01,\n",
       "             1.5904e-01,  1.5744e-02, -2.4413e-02, -7.8634e-02, -9.5509e-02,\n",
       "            -1.5217e-01, -1.3837e-01,  2.9637e-02,  4.4421e-01,  6.0220e-01,\n",
       "             1.2722e-01,  1.9552e-02, -2.4239e-01,  5.0913e-01, -3.2099e-01,\n",
       "            -1.0762e-01, -1.0697e-01,  3.8193e-02,  3.5120e-02,  4.2227e-02,\n",
       "            -6.1154e-02, -1.8117e-01,  8.8146e-03, -4.1351e-01, -6.0061e-02,\n",
       "            -3.6206e-02, -1.6912e-01,  1.7074e-03, -8.5909e-02,  4.5543e-02,\n",
       "             1.4132e-01,  2.9684e-01,  8.9259e-02, -6.7422e-02, -3.8283e-01,\n",
       "            -7.5837e-02,  4.5820e-01, -5.4877e-01,  7.6769e-02, -9.6775e-02,\n",
       "            -3.0642e-01, -1.9892e-01, -1.6124e-01,  5.4092e-02, -1.1997e-01,\n",
       "            -4.2277e-03,  7.0347e-01,  1.5814e-01,  4.6113e-01,  3.3784e-01,\n",
       "             4.5709e-02, -2.9297e-01, -8.1767e-03,  6.0086e-02, -4.1726e-02,\n",
       "            -2.1682e-02, -7.1626e-01,  8.8559e-02,  1.7796e-01, -6.2613e-02,\n",
       "             1.1890e-01, -9.8308e-02, -5.4270e-03, -4.4165e-01, -2.7934e-01,\n",
       "            -1.3551e-01,  2.3375e-01,  4.6315e-02,  3.8916e-01,  4.1669e-01,\n",
       "             2.3420e-01, -2.3714e-01, -1.8478e-01, -4.3377e-01, -2.0177e-01,\n",
       "             3.2650e-01,  3.2448e-01,  1.9836e-01, -1.2063e-01, -2.5505e-02,\n",
       "             3.5235e-01,  3.6084e-01, -3.7033e-01, -1.5220e-02, -2.8181e-01,\n",
       "            -7.4946e-02,  1.2400e-01,  1.1879e-01,  2.5292e-01, -2.6800e-01,\n",
       "            -1.9289e-01,  2.6346e-01, -2.1578e-01,  2.6568e-02, -3.5194e-01,\n",
       "             1.6343e-01,  3.2900e-01,  4.6422e-01, -1.0541e-01,  2.3737e-01,\n",
       "             2.2251e-01, -3.0365e-03,  3.6903e-01, -2.5203e-01,  7.6549e-02,\n",
       "            -2.2220e-01, -2.4135e-01,  7.2909e-03, -8.8494e-02,  4.0182e-02,\n",
       "            -1.8104e-01,  1.2189e-01,  3.2427e-01,  1.2379e-01,  3.0105e-01,\n",
       "            -9.4151e-02, -4.4532e-02,  2.3362e-01, -3.0536e-02, -6.0927e-02,\n",
       "             2.4866e-01, -5.2017e-01,  8.1867e-02, -1.7902e-01,  7.1599e-02,\n",
       "            -1.7902e-01, -4.1952e-01,  1.4367e-01, -1.4596e-01,  2.2677e-01,\n",
       "            -4.0989e-01, -7.9907e-01, -3.7755e-01,  9.2753e-02,  4.3778e-02,\n",
       "            -1.8922e-01, -3.2486e-01,  3.7245e-01,  1.9769e-01,  2.1759e-01,\n",
       "            -3.2727e-01, -1.7682e-01,  3.1165e-01,  1.7999e-01,  2.9141e-01,\n",
       "            -2.6024e-01, -2.7453e-01,  3.2766e-01, -5.6608e-02,  3.7667e-02,\n",
       "            -1.2349e-01, -6.1891e-01, -1.4156e-01,  1.4016e-01, -2.9111e-01,\n",
       "            -3.1669e-01, -2.5158e-01, -1.9599e-01,  9.7808e-02, -5.6124e-01,\n",
       "             1.0142e-01, -1.7076e-01, -3.0555e-01,  2.9087e-02, -6.6868e-02,\n",
       "            -2.6347e-01,  3.8911e-01, -3.7350e-01,  2.4364e-01,  2.6880e-01,\n",
       "             4.3067e-01, -1.7776e-01,  6.8791e-01,  1.8942e-01,  1.1175e-01,\n",
       "             2.3428e-01,  9.6764e-02, -1.8292e-02, -1.8428e-01,  4.3838e-03,\n",
       "             2.9870e-01, -8.8554e-02,  5.6916e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  6175, 11076,  1037,  6425,   281,  2412,\n",
       "                9,  5530,  4090,     9,    89,  9679,  2509,   841,   767,  5871,\n",
       "            11794,   310, 17357,   285, 27184, 17631,    15,   831,  1159,  4648,\n",
       "              271,  5795, 15895,   281, 11897,   253,  3453,   285, 11786,  9113,\n",
       "               15,     0]])),\n",
       "  (tensor([[ 2.9572e-01,  2.4998e-01, -2.6502e-01,  5.8188e-02,  2.8479e-01,\n",
       "            -7.1047e-02, -2.4833e-01,  2.8595e-01, -3.7894e-03,  4.4099e-01,\n",
       "             9.2722e-02,  4.7066e-01, -2.1279e-01,  2.4258e-02, -1.0650e-01,\n",
       "             1.5752e-01, -1.3628e-01,  4.7372e-01, -2.0772e-01,  2.9160e-01,\n",
       "             1.0184e-01,  3.3084e-02, -5.0125e-01, -3.6184e-01,  2.4578e-01,\n",
       "             4.7030e-01, -2.8478e-01, -2.8441e-01, -4.4371e-01, -8.9583e-02,\n",
       "             1.2888e-01, -1.0047e-01,  5.5540e-02, -2.8997e-03,  1.0433e-01,\n",
       "            -1.2449e-01,  2.0643e-01,  1.8217e-01, -5.9905e-01,  4.3642e-02,\n",
       "            -2.2513e-01, -6.2285e-02, -2.3202e-02, -1.8145e-01, -4.0115e-02,\n",
       "            -1.9249e-01,  2.2899e-01, -3.8655e-02, -1.8391e-01, -1.1133e-01,\n",
       "             2.3238e-01, -1.2361e-01,  1.0972e-02, -1.0456e-01, -1.9232e-01,\n",
       "            -1.5184e-01, -6.3611e-02, -1.4280e-01,  4.8125e-01,  9.3474e-02,\n",
       "            -1.3566e-01,  1.1697e-01, -3.6468e-01, -4.8904e-02,  3.5894e-01,\n",
       "             2.0582e-01, -1.9843e-01,  1.0340e-01,  1.9163e-01, -2.3340e-02,\n",
       "             5.4059e-01, -1.2785e-01, -1.0757e-01, -4.2903e-01, -1.2002e-01,\n",
       "            -3.1859e-01,  3.9550e-02,  4.1540e-01, -1.6950e-01, -3.8554e-01,\n",
       "            -3.0785e-02,  1.8020e-01,  1.0154e-01, -2.2760e-01,  1.3075e-01,\n",
       "            -1.0470e-01,  1.2230e-01, -1.0961e-01, -1.5651e-01,  1.5248e-02,\n",
       "             2.4593e-01,  1.8777e-01,  1.7347e-01, -1.0755e-01,  3.8484e-02,\n",
       "            -1.6323e-02,  1.2975e-02, -5.5923e-01, -3.0392e-01,  1.8328e-02,\n",
       "             2.9465e-03,  1.0650e-01, -1.2293e-02, -1.0163e-03, -1.4436e-01,\n",
       "            -1.4930e-01, -2.6198e-01,  4.4615e-02, -2.2389e-01,  1.3192e-01,\n",
       "            -1.1698e-01,  5.0372e-01,  1.5159e-01,  5.5655e-02, -1.6446e-01,\n",
       "             2.4805e-01, -2.4004e-01,  5.3640e-01,  1.7702e-01, -1.9709e-01,\n",
       "            -1.3459e-01,  4.4707e-01,  1.9095e-01,  1.6216e-01, -2.4919e-01,\n",
       "             7.5773e-03,  1.3759e-01,  1.4445e-01, -1.2004e-01, -5.2838e-02,\n",
       "            -8.9239e-02, -4.0258e-01, -1.3082e-01, -1.2620e-01,  4.9455e-01,\n",
       "            -1.3150e-01, -4.8371e-01, -3.7361e-03, -1.0418e-01, -4.8130e-02,\n",
       "            -2.8865e-01,  1.2348e-01, -7.7412e-02, -9.4229e-02, -3.3389e-01,\n",
       "            -1.9110e-01, -1.5877e-01, -1.0717e-01,  6.6443e-02, -7.3005e-03,\n",
       "            -1.4697e-01,  2.2517e-02,  8.0662e-02,  2.2565e-02,  3.4727e-01,\n",
       "             1.2384e-01,  2.7734e-01,  3.2236e-02, -2.2609e-01,  1.1058e-01,\n",
       "            -5.1244e-01,  1.7407e-01, -1.0221e-01, -1.2886e-01, -7.7542e-02,\n",
       "             2.6142e-01,  3.6702e-01, -2.7523e-01, -1.4107e-01, -2.7709e-02,\n",
       "             3.4897e-02,  3.3769e-01, -2.6091e-01,  1.4591e-01, -2.9411e-01,\n",
       "            -1.1521e-01, -3.3344e-01,  9.1500e-02,  1.2059e-02,  7.6237e-02,\n",
       "             1.1715e-01,  4.8259e-02, -3.1360e-02, -7.2639e-02, -1.0722e-01,\n",
       "            -3.7369e-01, -1.9055e-01,  5.2039e-01, -1.3793e-01, -2.4147e-01,\n",
       "            -1.4977e-01, -2.1190e-01, -6.1308e-02, -1.1097e-01, -1.0184e-01,\n",
       "             7.5172e-02, -5.6691e-03,  3.5566e-01, -5.0090e-02, -1.1835e-02,\n",
       "             1.5677e-02, -2.2874e-01, -4.4209e-02,  2.7016e-01,  8.6623e-02,\n",
       "            -2.9655e-02, -6.5454e-04,  1.0725e-01,  1.1213e-01,  2.6563e-03,\n",
       "             3.4963e-01, -1.6260e-01,  2.6815e-01,  2.9584e-01, -1.1489e-01,\n",
       "            -1.2938e-01,  1.1658e-01, -5.1320e-01, -1.1601e-01,  2.1607e-01,\n",
       "            -2.3608e-01,  2.9277e-01,  1.0157e-02,  1.6584e-01, -1.7514e-01,\n",
       "             2.3767e-01, -2.9716e-01,  2.6037e-01,  1.4828e-01, -1.3742e-01,\n",
       "             1.9236e-01, -8.7375e-03, -2.4939e-01,  8.0663e-02,  1.1736e-03,\n",
       "             4.6702e-02,  1.4718e-01,  1.3406e-02, -2.0297e-01, -1.2376e-01,\n",
       "             4.8224e-02,  1.6058e-01,  1.7180e-02, -1.3885e-01, -2.9903e-01,\n",
       "            -8.1648e-02,  4.0152e-01, -2.6935e-01,  2.2439e-01,  6.9987e-02,\n",
       "            -1.3678e-01, -1.9928e-01,  1.9327e-03,  1.4843e-01, -1.2448e-01,\n",
       "            -1.2512e-01,  4.5471e-01,  2.1411e-04, -1.1867e-01,  2.7495e-01,\n",
       "             8.6916e-02,  3.6468e-01,  1.8655e-01,  7.9592e-02,  5.8949e-01,\n",
       "             2.3061e-01, -6.3397e-02,  4.1504e-01,  1.4592e-01, -4.6316e-02,\n",
       "            -3.1943e-01,  7.4364e-02,  8.5118e-02, -2.3902e-01, -9.0185e-02,\n",
       "             1.6127e-01, -6.5543e-02,  2.4620e-02, -1.9019e-01,  9.9028e-03,\n",
       "            -1.4062e-01, -1.6240e-01,  1.6307e-01, -2.0115e-01,  8.2040e-02,\n",
       "             3.1294e-01,  3.7147e-02,  2.9408e-01, -6.1295e-02,  2.8351e-01,\n",
       "             9.8031e-02, -4.1557e-02,  3.4109e-01, -3.3798e-02,  3.2252e-01,\n",
       "             1.1196e-01,  1.6852e-01,  1.6708e-02,  2.3070e-01, -1.4878e-01,\n",
       "             5.5646e-02, -3.1913e-01,  4.8590e-03,  1.5202e-01, -2.8929e-01,\n",
       "            -5.7265e-02,  9.7975e-01,  1.9255e-01,  2.1379e-02,  5.1928e-01,\n",
       "             1.8457e-01,  4.1699e-02, -2.0741e-01,  1.1166e-01,  6.2392e-02,\n",
       "            -3.1174e-01,  5.2069e-02, -1.1202e-01, -1.4766e-01,  2.3537e-01,\n",
       "            -2.4256e-01,  3.8596e-02, -2.6987e-02, -1.7236e-01, -8.0486e-02,\n",
       "            -1.5798e-01, -8.7445e-02,  6.4484e-02, -5.0699e-01,  2.8291e-01,\n",
       "            -1.3702e-01,  1.0728e-01,  5.6682e-02, -2.8503e-01,  2.1228e-01,\n",
       "             1.5247e-01,  1.9490e-01,  9.4282e-02, -1.0146e-01,  1.0282e-01,\n",
       "             1.1418e-01,  1.7678e-01,  8.8906e-02, -2.9416e-01, -5.9831e-02,\n",
       "             1.3711e-01, -2.2809e-01, -3.4023e-01, -1.2848e-02, -3.9363e-02,\n",
       "            -1.3772e-02, -1.9432e-01,  2.0409e-01, -4.5848e-01, -3.1426e-02,\n",
       "             1.4674e-02, -1.6911e-01, -9.9366e-02,  7.1457e-02,  1.8659e-01,\n",
       "            -8.1006e-02,  5.2648e-02,  5.0673e-02,  2.3244e-01,  1.1425e-01,\n",
       "            -1.0463e-01, -5.7102e-01,  4.4961e-02,  6.3750e-02, -7.9951e-02,\n",
       "            -6.1502e-02,  1.1944e-02,  1.9425e-01,  1.9171e-01,  5.4826e-01,\n",
       "             3.4386e-01,  8.0103e-02,  1.0258e-02,  1.1078e-01,  1.1898e-01,\n",
       "            -1.9086e-01, -3.2863e-01, -5.9974e-01, -2.7578e-01,  8.7173e-02,\n",
       "             2.7397e-01,  1.9283e-01, -2.1217e-01,  2.9878e-01,  2.7037e-01,\n",
       "            -3.1706e-01,  2.4721e-01, -1.0178e-01,  5.8979e-01, -1.8626e-02,\n",
       "             5.6572e-02, -2.0239e-02, -1.1471e-01,  2.0438e-01,  1.2380e-01,\n",
       "             3.4484e-02,  1.3682e-01, -3.0268e-01,  9.8096e-02,  1.7780e-01,\n",
       "            -1.5040e-01,  5.1117e-01, -1.3575e-02, -5.7433e-01, -3.5753e-01,\n",
       "            -4.4081e-01,  1.1963e-01,  3.5103e-01, -3.9614e-01, -4.8712e-02,\n",
       "             4.7382e-01,  2.3535e-01,  1.7936e-02, -2.0616e-02,  9.6910e-02,\n",
       "            -3.2849e-01, -5.0619e-01,  1.8022e-01,  5.8783e-01,  2.1827e-01,\n",
       "             1.1373e-01, -1.4318e-01,  3.7805e-01,  1.7056e-01, -9.2935e-02,\n",
       "            -8.3583e-02,  5.0751e-02,  2.2631e-01,  2.9322e-01, -2.6996e-01,\n",
       "             2.0136e-01,  5.2775e-01, -9.7174e-02, -2.3917e-01,  1.9856e-01,\n",
       "            -5.9091e-02, -2.7516e-01,  3.0838e-02, -9.6030e-02,  1.6895e-01,\n",
       "            -3.7249e-01, -8.2335e-02,  2.2789e-01, -1.5698e-01, -2.8781e-01,\n",
       "            -1.6151e-01,  9.2448e-02,  3.8016e-02, -2.4053e-01,  9.1635e-02,\n",
       "            -2.9911e-01, -2.3879e-01, -3.8268e-01, -2.0355e-01, -1.3386e-01,\n",
       "             2.6352e-01, -1.4288e-02,  2.6595e-01, -9.2605e-02, -1.0935e-01,\n",
       "            -2.0619e-01, -1.0462e-01, -5.3203e-04, -1.1945e-01, -4.6298e-01,\n",
       "             1.4841e-01,  1.1842e-01, -3.9513e-01,  7.3136e-02, -5.3674e-01,\n",
       "             2.2603e-01, -1.2785e-01, -1.0340e+00,  7.7706e-02, -1.0645e-01,\n",
       "            -2.4629e-01,  1.4796e-01,  9.9674e-02,  2.7628e-02,  2.1201e-02,\n",
       "            -4.0572e-01,  4.8431e-02,  2.0380e-01,  9.1547e-02, -7.9336e-01,\n",
       "            -1.9545e-02, -4.0877e-01, -4.1836e-01,  5.9208e-01,  2.3998e-01,\n",
       "            -3.7547e-02,  3.2899e-01,  1.7014e-01,  6.6935e-02, -5.6823e-01,\n",
       "             5.6254e-02,  1.0777e-01,  1.5247e-02,  2.8378e-01, -9.3308e-02,\n",
       "             2.9761e-01,  2.3136e-01,  2.8920e-01,  1.4311e-01, -7.2311e-02,\n",
       "            -9.9740e-02, -3.3404e-01, -3.8677e-02, -1.3359e-01,  3.1023e-01,\n",
       "            -2.5488e-01, -1.1234e-01, -3.7607e-01, -3.1277e-02, -1.5755e-01,\n",
       "            -1.1873e-01, -6.5892e-01,  4.6109e-02,  4.1449e-01,  2.9435e-01,\n",
       "            -3.8494e-01,  6.2783e-02, -8.4863e-01, -2.9035e-02,  1.6015e-01,\n",
       "            -1.6857e-01, -2.3411e-01, -6.2178e-01,  1.0014e-01, -4.1959e-01,\n",
       "            -2.6791e-01, -4.5336e-01,  4.0599e-01,  4.4524e-01,  4.3063e-02,\n",
       "            -1.0492e-01, -6.5377e-01,  6.3825e-01,  2.5411e-01,  1.4148e-01,\n",
       "             7.8618e-02, -5.1659e-01, -1.0366e-01,  1.5075e-01, -1.0380e-01,\n",
       "            -4.5760e-03,  6.6030e-02, -2.4492e-01, -1.7555e-01, -1.9225e-01,\n",
       "            -7.6361e-03,  1.4381e-02,  2.5591e-01,  8.8256e-02,  1.5819e-02,\n",
       "            -4.8776e-03,  3.7323e-03, -7.7376e-02, -5.2767e-01, -2.9569e-01,\n",
       "            -2.3498e-01,  3.8794e-01,  1.7850e-02,  1.0556e-01,  5.1020e-01,\n",
       "             4.8043e-01,  3.0870e-01, -5.6463e-02,  1.6032e-01, -4.8517e-02,\n",
       "            -2.8098e-01, -2.0682e-01,  1.6099e-01,  3.0301e-01,  4.8688e-02,\n",
       "            -9.3816e-02, -1.6721e-01,  2.6808e-01, -2.0638e-03, -4.0180e-02,\n",
       "            -3.4473e-01,  3.0316e-01,  3.6209e-01,  1.4213e-01, -7.3726e-02,\n",
       "             2.0675e-01, -2.1249e-01,  2.1420e-01,  4.5592e-01, -4.3061e-02,\n",
       "            -2.3065e-01,  3.6839e-01, -6.5706e-01,  4.0822e-01, -1.0620e-01,\n",
       "             4.4862e-01, -6.7476e-02,  4.2767e-01,  2.3845e-01, -4.9874e-03,\n",
       "            -2.4845e-01, -2.2415e-01, -3.0703e-01, -3.1979e-01,  4.0072e-02,\n",
       "             1.9990e-01, -3.6350e-01, -7.6367e-01, -3.0183e-01, -1.4284e-01,\n",
       "             2.0739e-02,  4.9657e-01, -3.5510e-01, -2.4353e-02, -4.6367e-01,\n",
       "             5.1432e-01, -9.0695e-02, -3.9421e-02,  3.1814e-01, -4.3825e-01,\n",
       "            -1.0491e-01,  3.4339e-01, -9.7370e-02,  1.2800e-01, -4.9285e-01,\n",
       "             2.3240e-01,  1.5032e-01,  1.8859e-01,  1.3119e-01,  4.8021e-01,\n",
       "             9.2750e-02, -1.0054e-01,  2.0810e-01, -2.2618e-01,  4.2546e-02,\n",
       "             1.2905e-01, -3.2775e-01, -9.3133e-02, -4.3087e-01,  1.1905e-01,\n",
       "             2.3761e-01,  1.6232e-01,  3.7549e-01, -5.8533e-01, -1.8240e-01,\n",
       "            -4.0783e-01,  1.9675e-01,  2.2766e-01,  2.2840e-02,  6.8160e-01,\n",
       "             2.1492e-01, -2.7395e-01,  1.5793e-01, -5.9927e-01,  1.5306e-01,\n",
       "            -1.0211e-01,  4.9507e-01,  3.5651e-01,  9.9358e-03, -3.1183e-01,\n",
       "             3.5220e-01,  2.3418e-03, -6.9787e-01, -3.1485e-01, -8.8462e-02,\n",
       "            -4.6594e-02,  1.8788e-01, -1.4535e-01,  4.7702e-01, -7.1780e-02,\n",
       "             1.0575e-01,  2.9422e-01, -1.8658e-01,  1.3876e-01, -7.8052e-01,\n",
       "             3.7519e-01, -3.3212e-01,  1.2081e-01, -4.2051e-01, -6.1563e-02,\n",
       "            -1.4438e-01, -2.1549e-01,  2.6836e-01,  1.9609e-01,  2.6108e-01,\n",
       "            -6.7677e-01, -2.0115e-01,  1.0904e-01,  2.1059e-01, -2.2459e-01,\n",
       "            -1.4441e-01, -1.6083e-01,  6.3113e-02,  3.7053e-01,  3.3402e-01,\n",
       "             2.0210e-01,  7.9132e-02,  2.9959e-01, -1.2365e-01, -4.8108e-02,\n",
       "            -1.0933e-01,  1.2830e-01,  6.0564e-02,  2.0148e-01, -3.0425e-01,\n",
       "            -2.8287e-02, -1.7492e-01,  2.9282e-01, -2.0626e-01,  7.5443e-02,\n",
       "            -4.9882e-01, -4.5940e-01, -1.1773e-01, -5.6982e-02, -3.2369e-02,\n",
       "            -3.2633e-01,  1.1743e-02,  2.5655e-01, -4.2835e-01,  7.2642e-02,\n",
       "            -4.7479e-02,  1.2619e-01, -3.1852e-01,  8.3211e-02, -2.3036e-01,\n",
       "            -4.6690e-01, -3.9189e-01,  1.3227e-01, -2.7737e-01,  3.7430e-02,\n",
       "            -1.4652e-01,  1.7188e-01, -2.8591e-01,  7.5709e-03, -2.0401e-01,\n",
       "            -9.1570e-04, -6.6220e-02, -3.9185e-01,  8.4113e-02, -5.7130e-01,\n",
       "            -5.5811e-02,  1.5318e-01, -1.8931e-01,  5.4756e-02,  4.4799e-02,\n",
       "            -4.1501e-02,  3.5238e-01, -2.2693e-01,  3.8763e-01, -2.4715e-01,\n",
       "            -2.8654e-01,  1.2891e-01,  3.5407e-01,  6.0140e-03,  1.4588e-01,\n",
       "             1.4363e-01,  2.5332e-01,  4.5271e-01, -1.6195e-01, -8.1279e-02,\n",
       "            -4.0954e-02,  3.8780e-01,  7.6931e-03]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  1231,   476,   897,   253, 13814, 14113,\n",
       "             6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,   209,\n",
       "                0]])),\n",
       "  (tensor([[-6.8418e-01,  1.9223e-01, -1.7987e-01,  3.7849e-02,  5.8432e-02,\n",
       "            -3.4492e-01, -1.1858e-01,  3.0567e-01, -5.4985e-01, -2.6762e-01,\n",
       "             1.9791e-01,  4.3173e-01,  3.2620e-01, -9.9674e-02,  8.7414e-02,\n",
       "             2.7175e-01, -2.8033e-01,  3.7530e-01,  4.3810e-03,  9.0598e-02,\n",
       "             8.6644e-02, -3.3168e-01, -3.0274e-01,  5.8658e-01,  1.3545e-01,\n",
       "             9.5194e-02, -1.1819e-01, -2.2146e-01, -1.1617e-01, -6.1653e-02,\n",
       "             7.5513e-02,  3.2036e-01, -1.1393e-01,  4.6811e-01,  2.8797e-01,\n",
       "             1.5593e-01, -2.8596e-01, -1.9542e-01,  3.2622e-01, -8.4604e-02,\n",
       "            -2.1191e-01, -2.7615e-03,  3.6774e-01,  2.7080e-01, -1.9643e-01,\n",
       "            -4.3588e-01,  7.9537e-02, -6.2204e-02, -3.5547e-01, -1.3563e-01,\n",
       "            -5.6416e-03,  3.4256e-01,  3.6707e-01,  1.4880e-01,  1.1879e-02,\n",
       "            -6.7696e-02,  1.5523e-01, -1.4425e-02,  5.2144e-01, -9.5474e-02,\n",
       "            -5.0220e-01,  2.3898e-01,  6.9576e-02,  2.0389e-01,  2.6947e-02,\n",
       "             3.3720e-02,  3.0708e-02, -1.1800e-01,  1.6587e-01, -2.4826e-01,\n",
       "             2.1399e-01, -6.8451e-02,  3.0505e-02,  2.1300e-01, -3.7253e-02,\n",
       "            -9.7250e-02, -4.8579e-02,  1.4576e-01,  3.0388e-01,  1.4030e-01,\n",
       "            -5.5602e-02, -4.3129e-02,  4.2732e-02, -4.2038e-01, -2.2293e-01,\n",
       "             2.3457e-02,  2.6410e-01, -1.5361e-01,  1.5772e-01,  8.6641e-02,\n",
       "             9.9450e-02,  1.2480e-01, -9.6456e-02, -1.4005e-01,  4.1146e-02,\n",
       "            -6.4087e-02,  1.4548e-01, -1.8857e-01,  4.9218e-03, -2.5842e-01,\n",
       "            -4.4257e-01, -2.4051e-02, -1.1002e-02,  2.1452e-01,  2.2700e-02,\n",
       "            -2.3971e-02, -3.4055e-02, -8.4438e-02,  3.9075e-03,  2.3034e-01,\n",
       "            -6.5150e-02, -2.0426e-02, -1.1318e-01, -1.3800e-01,  1.3821e-01,\n",
       "             3.7320e-01,  2.4579e-01,  3.9802e-01,  1.0199e-01, -6.6877e-02,\n",
       "            -4.5490e-02,  1.2475e-01,  4.1897e-02,  7.0018e-02, -1.4299e-01,\n",
       "             1.4663e-01,  2.3149e-01, -1.8707e-01, -1.3138e-02,  3.7095e-01,\n",
       "             9.4502e-02, -9.5087e-02, -1.3243e-01, -6.7992e-02, -3.7874e-02,\n",
       "            -2.8772e-01, -1.9342e-01,  4.6412e-01, -2.2583e-01,  5.7654e-02,\n",
       "            -5.9642e-02, -1.5580e-01,  3.5658e-02, -3.0988e-02, -2.5912e-01,\n",
       "             1.5275e-01,  1.1566e-01,  4.1136e-01, -1.3130e-01,  2.3229e-01,\n",
       "            -1.0967e-01, -4.8498e-02,  4.8796e-01, -1.5967e-01,  1.1440e-01,\n",
       "             3.9282e-01, -1.0998e-01,  1.5830e-01,  4.7421e-02,  6.6377e-02,\n",
       "            -2.7053e-01,  2.7462e-01, -1.0531e-01, -1.4055e-01, -1.2818e-02,\n",
       "             1.0439e-01,  8.4919e-01,  1.8134e-01, -6.1334e-03,  2.9578e-01,\n",
       "            -1.1861e-04, -1.1102e-01, -1.2770e-01,  2.5522e-02,  3.3448e-01,\n",
       "             2.0306e-01,  1.5305e-01, -1.2146e-01,  2.8764e-02, -1.1146e-01,\n",
       "            -2.2893e-01, -1.2996e-01, -3.4626e-02, -2.7862e-01,  2.4250e-01,\n",
       "             2.5491e-02,  1.0534e-01, -5.1909e-02, -2.6258e-01, -9.4662e-02,\n",
       "             2.8169e-01, -4.6166e-02, -1.2108e-02,  1.4209e-01,  4.2272e-02,\n",
       "            -7.4459e-02,  3.7190e-01, -1.2886e-01, -3.0874e-02, -2.5348e-01,\n",
       "             2.6319e-01, -2.0925e-01, -4.3177e-01, -8.6992e-02,  6.6740e-03,\n",
       "             1.8571e-01, -2.0072e-02, -2.0744e-01, -6.8891e-03, -3.5001e-01,\n",
       "            -9.3256e-02, -3.2290e-02,  7.7384e-02, -1.2177e-01, -1.5230e-02,\n",
       "            -7.3072e-01, -2.2189e-01, -4.2418e-01, -4.8728e-02,  2.6913e-01,\n",
       "            -2.3768e-01,  1.3666e-01, -2.1791e-01,  3.3647e-02, -9.0448e-02,\n",
       "             4.5114e-01, -2.5816e-02,  1.5167e-01,  1.3628e-01, -1.1839e-01,\n",
       "            -1.9059e-01, -1.3117e-02,  1.8963e-02,  1.4755e-01, -3.2294e-01,\n",
       "            -1.1729e-01,  6.6370e-02,  6.8025e-02, -6.3846e-02, -2.9912e-01,\n",
       "            -4.2185e-01, -5.5293e-02,  9.9964e-02, -2.4244e-02, -2.5152e-01,\n",
       "             3.3485e-01,  2.0356e-01, -1.7609e-02,  9.0225e-02,  1.9462e-01,\n",
       "             2.8282e-02, -4.7096e-02, -1.9185e-01, -1.7495e-01, -5.9802e-02,\n",
       "             6.8972e-02,  2.9637e-01,  4.3077e-01,  1.9330e-01,  2.5913e-01,\n",
       "            -3.9082e-02, -1.5980e-01,  2.2595e-01, -3.1009e-01, -1.0023e-01,\n",
       "            -7.2192e-02,  9.0603e-02,  3.0734e-01,  3.6185e-02, -1.3940e-01,\n",
       "            -4.4669e-02,  4.1987e-01, -1.2592e-01, -6.2298e-01, -1.9056e-01,\n",
       "            -1.5472e-01, -2.2640e-01,  3.4881e-01, -2.3235e-01, -4.9957e-01,\n",
       "            -3.3105e-01, -9.1083e-02,  2.5721e-01, -8.0016e-02, -1.7965e-01,\n",
       "             4.7808e-01,  8.6682e-02,  1.4714e-01, -2.8884e-01, -2.2586e-01,\n",
       "            -2.2298e-01, -5.1566e-01,  5.9057e-01, -2.4000e-01,  9.6398e-01,\n",
       "            -1.5387e-01,  3.3733e-02, -8.0708e-02, -6.3613e-02,  1.4916e-01,\n",
       "             2.6050e-01, -1.8489e-01,  1.5307e-01,  5.4299e-02,  3.2295e-01,\n",
       "             1.3776e-01,  1.8407e-01, -1.9074e-01, -3.4984e-01, -9.2278e-02,\n",
       "             7.5729e-01, -2.1437e-01,  1.9061e-01,  3.5078e-01,  2.3671e-01,\n",
       "            -2.4690e-01,  2.1695e-02, -7.8652e-02, -2.1267e-01, -3.3826e-01,\n",
       "             3.5494e-01, -6.1464e-02,  5.8978e-02, -3.9336e-02,  1.1386e-01,\n",
       "             7.3660e-02, -3.6948e-02,  5.8723e-02, -1.0431e-01,  1.4773e-01,\n",
       "            -1.2686e-02,  1.3075e-01,  2.1008e-01,  3.1822e-02, -1.1902e-01,\n",
       "            -2.3037e-01, -3.8743e-02, -6.6644e-01, -5.0074e-02, -6.5424e-02,\n",
       "            -5.1525e-01, -8.7240e-02, -2.7656e-02, -1.7249e-01, -3.4867e-01,\n",
       "            -5.6910e-02, -4.6578e-01,  2.8694e-01, -4.9480e-02, -2.9484e-02,\n",
       "             2.3870e-02,  2.7620e-01, -1.9154e-01, -5.6072e-01,  2.7130e-01,\n",
       "             2.2816e-01, -2.9441e-02, -2.1486e-01,  1.6555e-01,  4.9364e-01,\n",
       "             8.6609e-02, -1.1253e-02,  8.4257e-02,  2.9262e-01, -1.5968e-01,\n",
       "            -1.0907e-01, -6.3806e-01,  6.0467e-02, -1.3478e-01,  1.4171e-01,\n",
       "            -1.1891e-01,  5.3364e-03,  1.3171e-01, -2.3522e-01, -2.1129e-01,\n",
       "            -2.5799e-01, -1.9862e-01, -1.1489e-01,  2.6545e-01, -4.2368e-02,\n",
       "            -1.7999e-01, -1.1499e-02, -2.5301e-01, -3.2406e-01, -5.8799e-03,\n",
       "            -2.1017e-01,  6.7543e-02, -1.0134e-01,  4.0534e-01,  1.9419e-02,\n",
       "            -2.0376e-03,  4.7116e-01, -2.8669e-01,  3.7755e-01, -7.3704e-03,\n",
       "             1.1744e-01,  1.3952e-01, -1.8510e-01,  4.4122e-01,  1.8249e-01,\n",
       "             1.1240e-03, -1.3905e-01,  1.8664e-02, -2.1969e-01,  7.8594e-02,\n",
       "             1.5938e-01, -2.0529e-01, -7.9032e-04, -4.1621e-01, -2.3394e-01,\n",
       "            -1.0808e-01, -2.6527e-01, -1.3088e-01, -1.1004e-01, -1.7720e-01,\n",
       "             8.5128e-02, -2.2163e-01,  6.6964e-01,  2.1603e-01, -1.6912e-01,\n",
       "             1.0272e-01,  6.6627e-02, -1.2773e-01, -3.4510e-01,  2.2000e-01,\n",
       "             1.0950e-01, -2.8916e-01, -4.7626e-02,  2.2014e-01, -4.1860e-02,\n",
       "            -1.2163e-01,  3.6735e-01, -3.2030e-01, -3.8327e-01, -4.7477e-02,\n",
       "             4.3948e-01, -7.0664e-02, -6.8191e-01,  3.6655e-01,  4.8565e-02,\n",
       "            -1.6921e-01,  6.3991e-02,  4.1277e-01,  4.8237e-01, -3.2342e-02,\n",
       "             2.1981e-01,  1.9684e-01, -3.2130e-01, -3.7689e-01, -2.4426e-01,\n",
       "            -2.1507e-01,  7.0250e-01,  2.8799e-01, -4.8176e-01, -2.3676e-02,\n",
       "             2.9697e-01,  6.0207e-02, -3.7099e-02, -1.1553e-02, -6.1527e-02,\n",
       "             3.7405e-02,  4.6810e-01, -2.5745e-01, -5.9175e-02, -3.4385e-02,\n",
       "             2.3865e-02,  1.5661e-02, -1.9112e-02,  5.1607e-01, -1.8564e-01,\n",
       "             1.5889e-01,  3.7614e-01, -4.9633e-02, -7.2976e-02, -3.9483e-01,\n",
       "             3.7497e-01, -2.6430e-01, -1.4870e+00,  2.7232e-02, -8.8354e-02,\n",
       "            -8.1487e-02,  5.6217e-01,  9.9710e-02, -1.5082e-02,  1.1408e-01,\n",
       "             3.2267e-01, -5.4175e-01, -1.7118e-01, -5.2209e-02, -2.9712e-01,\n",
       "             1.9014e-01,  2.0639e-01,  1.8168e-02,  1.0918e-01,  1.7623e-01,\n",
       "             1.1021e-01, -2.2102e-01, -4.6020e-02,  1.3762e-01, -5.2267e-01,\n",
       "             1.4442e-01, -2.8263e-01,  3.2670e-02,  2.4106e-01, -2.4944e-01,\n",
       "             2.8638e-01, -3.1251e-01,  3.6859e-01,  8.3582e-02,  2.1967e-01,\n",
       "            -1.3468e-01, -1.3873e-01, -7.8029e-02, -4.4940e-02, -4.1969e-01,\n",
       "             6.1304e-01, -6.8470e-02, -4.2455e-02, -2.4705e-01,  4.8014e-02,\n",
       "            -1.4050e-01, -1.1638e-01,  2.3577e-01,  3.1987e-01,  3.7693e-02,\n",
       "            -6.4695e-02, -2.2063e-01, -2.7628e-03, -7.8921e-02, -1.4683e-01,\n",
       "             1.1788e-01,  1.4537e-01, -5.7427e-01, -2.3093e-01, -1.9475e-01,\n",
       "             1.1985e-01,  3.2989e-01, -9.8547e-02,  1.5879e-01, -4.1053e-01,\n",
       "             1.3870e-02, -2.5137e-01,  7.0340e-02, -6.8867e-03, -6.5256e-01,\n",
       "            -2.2740e-01,  1.6808e-01, -2.3321e-02,  2.5055e-01,  7.7346e-02,\n",
       "             4.7238e-01,  1.8983e-01, -3.7097e-01, -7.2802e-02, -3.5569e-01,\n",
       "             8.0240e-02, -4.8987e-02, -3.0933e-01, -2.4184e-01, -1.1043e-01,\n",
       "             6.6721e-02,  3.7632e-01, -1.1431e-01,  1.1349e-01, -1.6664e-01,\n",
       "            -7.6144e-02, -3.1293e-01, -2.3534e-01, -3.8478e-01,  3.5899e-01,\n",
       "             8.4163e-02,  1.7926e-01,  1.3738e-01,  1.5138e-01, -1.6724e-01,\n",
       "            -1.8686e-01, -4.1411e-01,  1.0823e-01, -2.0444e-01, -1.6457e-01,\n",
       "            -1.7991e-01,  2.7404e-01,  2.3815e-01,  1.2279e-02, -7.8426e-02,\n",
       "            -3.6048e-01, -1.0370e+00, -4.6942e-01, -1.2539e-01,  7.5846e-02,\n",
       "            -5.1040e-01, -1.6334e-02, -2.3246e-02,  2.1509e-01,  2.9442e-02,\n",
       "             2.8013e-02,  5.7444e-01,  1.5484e-01,  2.3345e-01, -2.5396e-01,\n",
       "             2.9203e-01, -2.0240e-01,  2.1735e-01,  2.2628e-01, -1.7856e-01,\n",
       "             1.3839e-01,  1.7939e-01, -2.0714e-01, -2.0409e-01, -3.2030e-03,\n",
       "            -2.9249e-01,  6.2612e-02,  8.4874e-02, -3.3211e-01,  4.2764e-02,\n",
       "             1.4121e-01, -1.4613e-01, -4.8791e-01, -8.4528e-02, -1.6951e-01,\n",
       "             7.6038e-02,  1.4795e-01, -2.9911e-01,  7.6208e-01, -1.4536e-01,\n",
       "             2.8180e-01,  3.9043e-02, -3.2810e-01,  4.6852e-02, -5.8590e-01,\n",
       "            -4.8213e-01,  1.2687e-01,  1.3239e-01, -3.1599e-01,  7.8787e-01,\n",
       "            -1.9900e-01,  2.1470e-01,  3.2976e-02,  1.7535e-01, -2.6854e-01,\n",
       "            -1.7776e-01,  4.2346e-01, -4.9658e-02,  2.6584e-01, -1.3420e-02,\n",
       "             3.9528e-01, -3.6330e-01, -2.6794e-01,  7.2063e-01, -2.6924e-02,\n",
       "             5.3027e-02,  1.1376e-01,  1.7936e-01,  3.4780e-01, -1.2819e-01,\n",
       "            -9.7410e-02, -1.4829e-02,  3.8375e-01, -2.4570e-01,  2.9191e-01,\n",
       "             3.7322e-01, -2.2273e-01,  1.3384e-02, -3.0707e-01, -4.4777e-01,\n",
       "            -6.9309e-01, -6.3718e-02, -3.9204e-01, -3.0062e-01, -4.9076e-02,\n",
       "             6.5315e-01, -2.0179e-01, -1.8195e-02, -3.1895e-01,  2.8201e-01,\n",
       "            -9.8153e-02,  4.8846e-01, -5.2533e-02, -1.1845e-01,  1.1056e-01,\n",
       "             1.7928e-01,  1.2508e-02, -1.1287e-01, -4.6492e-01, -3.5043e-01,\n",
       "             3.3832e-01,  2.1967e-01, -4.5147e-02,  2.9510e-01, -1.1474e-01,\n",
       "             1.8080e-02, -1.3825e-01, -2.7524e-02,  4.5988e-01, -4.8283e-02,\n",
       "            -4.1268e-02,  3.1351e-01,  3.1035e-01, -3.2399e-01,  3.8921e-01,\n",
       "            -3.0438e-01,  1.1039e-01, -2.5931e-01, -1.0696e-01,  1.0283e-02,\n",
       "             3.6775e-01,  1.3356e-01, -4.1394e-01, -2.4758e-02, -3.1349e-01,\n",
       "            -2.1034e-01,  3.8455e-01,  1.6018e-01, -2.6087e-01,  2.2451e-01,\n",
       "             7.0131e-02,  2.5188e-01,  8.7525e-02, -4.1965e-01,  3.4773e-01,\n",
       "            -2.5718e-01, -1.1996e-02,  1.0341e-01, -1.0460e-01,  2.4544e-01,\n",
       "            -8.5895e-03,  1.2318e-01,  1.0890e-01,  2.9441e-01, -5.8828e-01,\n",
       "             1.5446e-01,  5.0003e-01, -9.3641e-02, -1.2791e-01, -3.8073e-02,\n",
       "             3.0840e-01,  2.6956e-02, -4.1900e-01, -4.0892e-01, -6.2024e-02,\n",
       "             2.3195e-02, -1.3570e-01,  1.9289e-01,  4.4456e-01, -1.1737e-01,\n",
       "             2.9186e-01, -9.4053e-02,  2.2128e-01,  1.7319e-01,  1.3544e-01,\n",
       "            -1.1831e-01,  1.0712e-01, -2.8123e-01,  1.6155e-01,  3.0312e-01,\n",
       "            -1.7556e-01, -3.1223e-01,  1.9171e-01, -7.2104e-01, -4.7257e-01,\n",
       "            -2.0236e-01,  3.1015e-02,  2.4382e-01,  2.3716e-01, -7.5576e-01,\n",
       "            -1.9940e-01,  5.5411e-02, -4.7929e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  5703, 15764,  3423, 18088, 10123,   432,\n",
       "              634,  7583, 18273,  3909,  2278,  2603,     0]])),\n",
       "  (tensor([[-0.5535, -0.0208, -0.0223, -0.0366,  0.2338, -0.1066,  0.1572, -0.0219,\n",
       "            -0.5915, -0.0828,  0.2210, -0.0726,  0.0726, -0.3230,  0.1551,  0.2363,\n",
       "            -0.1173,  0.2316,  0.3159, -0.0773, -0.1871, -0.0507, -0.2464,  0.5650,\n",
       "             0.1437,  0.4996, -0.1851, -0.1773, -0.2623,  0.0658,  0.3644,  0.0615,\n",
       "            -0.2943,  0.3652,  0.1411, -0.1549, -0.3349, -0.4160, -0.1690, -0.4182,\n",
       "             0.1427, -0.0015,  0.4245, -0.0500, -0.4330,  0.0981, -0.0413, -0.1172,\n",
       "             0.0087, -0.5807, -0.0132,  0.4657,  0.0213, -0.2399, -0.2151, -0.5170,\n",
       "             0.4513, -0.0493,  0.1270,  0.1582, -0.3670,  0.3114, -0.1168, -0.1125,\n",
       "             0.3693,  0.0346, -0.0617,  0.3321, -0.1402, -0.1489, -0.4175,  0.1538,\n",
       "            -0.2271,  0.3098,  0.1854, -0.1161,  0.2150, -0.1621, -0.0695,  0.1538,\n",
       "            -0.1463, -0.1183,  0.1018,  0.1716,  0.0122, -0.0254,  0.3841, -0.1025,\n",
       "             0.3390, -0.1402,  0.1314, -0.1330, -0.1803, -0.2570,  0.0595,  0.1440,\n",
       "             0.1522, -0.2388,  0.0140,  0.1441, -0.3346, -0.0358, -0.2804, -0.1297,\n",
       "             0.0472,  0.0206, -0.0867,  0.1503,  0.1083, -0.0987, -0.0112, -0.1257,\n",
       "            -0.1004, -0.2018, -0.0530, -0.1993, -0.0331,  0.2386,  0.0431, -0.0903,\n",
       "             0.2076,  0.0794, -0.0868,  0.0604,  0.1060,  0.1347,  0.4954, -0.2797,\n",
       "             0.1874,  0.1690, -0.1274, -0.1500,  0.1502, -0.0881, -0.2521, -0.1921,\n",
       "            -1.0536, -0.0218, -0.1635,  0.2897, -0.1674,  0.1241,  0.4696, -0.1052,\n",
       "             0.0097, -0.1409, -0.0708,  0.0365, -0.1956, -0.0364,  0.0380,  0.1730,\n",
       "             0.3586, -0.1055,  0.0326, -0.0459,  0.2326,  0.0736,  0.1700,  0.0924,\n",
       "             0.0996,  0.2304, -0.0221,  0.0244,  0.0453, -0.4166,  0.5176,  0.3125,\n",
       "            -0.4616,  0.1950,  0.2529,  0.0562,  0.0844,  0.1162,  0.1562, -0.0284,\n",
       "             0.1252, -0.1650,  0.0359, -0.1491, -0.1457,  0.0477,  0.1249, -0.3676,\n",
       "             0.2747, -0.1636, -0.0895, -0.0347,  0.1331,  0.2053, -0.1220, -0.0611,\n",
       "            -0.2548,  0.1305, -0.2803,  0.1748,  0.0625, -0.3410,  0.2652, -0.1765,\n",
       "             0.4388,  0.0542,  0.1699, -0.0168, -0.1534,  0.2363, -0.2635, -0.0155,\n",
       "             0.1576,  0.0773,  0.0938,  0.2314,  0.0228, -0.0192, -0.1311, -0.4035,\n",
       "            -0.4216, -0.0730, -0.1465, -0.0916,  0.2091, -0.1152,  0.1459,  0.3451,\n",
       "            -0.0171,  0.0113, -0.0733, -0.2755, -0.0741,  0.2096,  0.3546,  0.0565,\n",
       "            -0.3407, -0.0354, -0.2008,  0.0077,  0.1183,  0.1638, -0.0237, -0.0519,\n",
       "            -0.0032,  0.0538,  0.2807, -0.2622, -0.1142, -0.0215,  0.2335,  0.0754,\n",
       "            -0.1794,  0.0670,  0.1698,  0.1222, -0.3609, -0.2531, -0.4291, -0.0179,\n",
       "             0.1020,  0.3977,  0.1828, -0.2916, -0.0064, -0.2840, -0.1778, -0.3471,\n",
       "            -0.0988,  0.0337, -0.3691,  0.1964, -0.0292, -0.2671, -0.3197, -0.0411,\n",
       "            -0.0150, -0.2508, -0.0343, -0.1030, -0.0104,  0.2774, -0.1323, -0.1064,\n",
       "            -0.0104, -0.3057,  0.1136, -0.4425, -0.2945,  0.3648, -0.0612, -0.2651,\n",
       "             0.0778, -0.1097,  0.0511, -0.2664,  0.4079,  0.0291,  0.9062, -0.2138,\n",
       "             0.1413, -0.0576, -0.2856,  0.0804,  0.1779, -0.0618, -0.0037, -0.2925,\n",
       "             0.1670, -0.0321, -0.1321, -0.0145, -0.3037, -0.0712,  0.9056,  0.3811,\n",
       "             0.1201,  0.1504,  0.1263, -0.3900, -0.1386, -0.1526,  0.0432, -0.0595,\n",
       "             0.4199, -0.1442, -0.0991, -0.0024, -0.0234,  0.0501, -0.1366,  0.0458,\n",
       "            -0.0322, -0.0587, -0.0542,  0.0695,  0.2045,  0.1783, -0.0596, -0.3824,\n",
       "             0.0374,  0.0896, -0.1452, -0.1122, -0.2950, -0.0144, -0.1656, -0.0357,\n",
       "            -0.2735,  0.1004,  0.0353, -0.1212, -0.2707, -0.0944, -0.0168,  0.2446,\n",
       "             0.0230, -0.4579, -0.1224,  0.5480, -0.1127, -0.1726,  0.2646,  0.4233,\n",
       "             0.1005,  0.0934,  0.0184, -0.0404, -0.1468, -0.3080,  0.0535, -0.0291,\n",
       "            -0.0903,  0.2036, -0.0666, -0.1117, -0.0536,  0.0104, -0.1492,  0.1035,\n",
       "             0.0886, -0.1101, -0.0289, -0.1345, -0.3483, -0.1132, -0.1153, -0.1432,\n",
       "            -0.2186, -0.3959,  0.1002, -0.0965,  0.2967,  0.1725, -0.1175,  0.5330,\n",
       "            -0.0719, -0.2179,  0.0785,  0.1517,  0.1258, -0.0279, -0.1021,  0.3805,\n",
       "             0.1493, -0.4521, -0.1306,  0.0786,  0.7117,  0.2089, -0.0861,  0.2781,\n",
       "             0.1486, -0.0315,  0.1957, -0.1505, -0.2645, -0.1106, -0.4084,  0.2021,\n",
       "            -0.0250,  0.1738,  0.2459, -0.1109, -0.1056, -0.0696, -0.3111,  0.0122,\n",
       "             0.0174,  0.0500,  0.2039,  0.3132,  0.3414,  0.2098, -0.1935,  0.1356,\n",
       "             0.0133, -0.4942,  0.2820,  0.1505,  0.0161, -0.4346,  0.4748, -0.1415,\n",
       "            -0.2429,  0.0205,  0.0912,  0.4789, -0.1269,  0.1048,  0.1866, -0.4697,\n",
       "            -0.2366, -0.2539,  0.0311, -0.0279,  0.7978, -0.4470,  0.0651,  0.2419,\n",
       "             0.1780, -0.6535, -0.2100,  0.2385,  0.2128,  0.1903, -0.1648,  0.0464,\n",
       "            -0.1755,  0.0946,  0.0525,  0.2802,  0.1111,  0.0176, -0.2430,  0.0432,\n",
       "             0.1261, -0.1495,  0.2823,  0.3438, -0.1289, -1.1264,  0.2678,  0.0735,\n",
       "            -0.2920,  0.1159, -0.3312, -0.2868,  0.4069,  0.4561, -0.4039, -0.3381,\n",
       "             0.0369, -0.0250, -0.1432, -0.0068, -0.0557,  0.3590,  0.2637, -0.0599,\n",
       "             0.1747,  0.1649,  0.2489, -0.4138, -0.1446, -0.0189,  0.2686,  0.2685,\n",
       "            -0.5981, -0.2688,  0.1348, -0.0681, -0.3408,  0.0644, -0.1286, -0.0260,\n",
       "            -0.4507,  0.0053, -0.6182,  0.1556, -0.2964,  0.2219, -0.2029,  0.0161,\n",
       "            -0.1521, -0.1605,  0.1167,  0.1787, -0.2604, -0.1653, -0.0987,  0.0749,\n",
       "            -0.1219, -0.5369, -0.0730, -0.1465, -0.4215, -0.3380, -0.4590,  0.2452,\n",
       "             0.3630, -0.1318,  0.2327,  0.0472,  0.2303, -0.1632, -0.2253, -0.0826,\n",
       "            -0.3162, -0.0407,  0.3425,  0.4765,  0.0368,  0.0172,  0.1931,  0.1878,\n",
       "            -0.4593, -0.1251,  0.0902,  0.0237,  0.0500, -0.6705, -0.0827, -0.4916,\n",
       "             0.1522,  0.3281, -0.0132, -0.0176,  0.0889, -0.0853, -0.2819,  0.0884,\n",
       "            -0.2714,  0.0259,  0.2820,  0.3713, -0.0395,  0.3558,  0.1712, -0.2922,\n",
       "            -0.0257, -0.1085,  0.2964,  0.4116, -0.0732, -0.4299, -0.0961, -0.3990,\n",
       "             0.2458, -0.2640, -0.1865, -0.1780,  0.3583,  0.4689, -0.2886,  0.4370,\n",
       "            -0.1059, -0.1077, -0.0904, -0.6079,  0.4557, -0.0241,  0.2291, -0.1722,\n",
       "             0.0674,  0.0663,  0.3076, -0.2013, -0.1039,  0.1953,  0.4340,  0.3532,\n",
       "             0.2371, -0.1774, -0.0097,  0.5524, -0.0854, -0.1036,  0.0164, -0.2299,\n",
       "            -0.1741, -0.4954,  0.2802, -0.0234, -0.0977,  0.2123,  0.1909,  0.1390,\n",
       "            -0.2365, -0.2886,  0.0921, -0.1864, -0.3967, -0.2665,  0.1911,  0.2785,\n",
       "             0.2353, -0.0551,  0.4467,  0.0674,  0.2871, -0.5415,  0.2270,  0.0613,\n",
       "             0.4506,  0.1740, -0.2591, -0.2023, -0.4104, -0.1187,  0.1386, -0.0147,\n",
       "             0.0953,  0.0390, -0.2098, -0.3147,  0.2726, -0.0695,  0.1232,  0.0710,\n",
       "             0.2188,  0.4096,  0.1743,  0.1753,  0.3350, -0.2180, -0.1347, -0.4254,\n",
       "            -0.2134, -0.1965,  0.0531, -0.6346,  0.3069, -0.1532, -0.0020,  0.5130,\n",
       "             0.2661, -0.1201, -0.2200, -0.1526,  0.0826,  0.3649,  0.0317, -0.3136,\n",
       "             0.3182,  0.0103, -0.2391, -0.2696, -0.1339, -0.2329, -0.1470, -0.4400,\n",
       "             0.5349,  0.0024, -0.0632,  0.2915, -0.5562,  0.0957,  0.4210,  0.0032,\n",
       "             0.0075,  0.0053, -0.0473,  0.3149, -0.5009,  0.0400, -0.1014, -0.0948,\n",
       "            -0.1769,  0.0327,  0.0674,  0.1962,  0.2794, -0.1384, -0.2695, -0.0820,\n",
       "            -0.0282,  0.2203,  0.2827, -0.2056,  0.0399,  0.1710, -0.0941,  0.0887,\n",
       "            -0.4700,  0.1222, -0.1325, -0.0215,  0.2536, -0.0936, -0.4384, -0.2871,\n",
       "             0.1229, -0.1199,  0.0914,  0.4252, -0.2753, -0.0837, -0.0943,  0.2127,\n",
       "             0.1203, -0.1716, -0.0581,  0.1718,  0.5835, -0.1988,  0.1085,  0.2093,\n",
       "             0.0688,  0.1661,  0.1817, -0.0348, -0.1272,  0.2576,  0.1583,  0.5861,\n",
       "            -0.4715,  0.4073,  0.2450,  0.1681,  0.1738, -0.3781, -0.3382, -0.1936,\n",
       "            -0.0497, -0.0590,  0.2511, -0.0992, -0.1621, -0.1089, -0.1615,  0.0762]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 45032, 18088,   378,  2865, 11381,   285,\n",
       "             7462,    90, 25271,   337,    15,   473,  1405,  1059,  3995,    15,\n",
       "              313, 32168,   481,  7489,  3954,    15,  2448,  1890,   428,   370,\n",
       "             1890, 25271,   374,    15,  2305,    15,   353, 33122,    15,   313,\n",
       "               19,    13, 22359,   481,  7489,  3954, 25271,   495,    15,   500,\n",
       "             3681,   434, 37119,    15,     0]])),\n",
       "  (tensor([[-5.8407e-01,  2.1528e-01, -3.0932e-01,  1.6281e-01,  4.1413e-01,\n",
       "             3.0161e-01, -1.1928e-01,  9.2831e-02, -3.0252e-01, -2.3589e-01,\n",
       "             6.0564e-01,  8.4601e-02,  5.0351e-02,  1.8309e-02, -1.6304e-01,\n",
       "            -1.5692e-01, -4.9671e-02, -2.8717e-02,  5.1446e-02, -1.5782e-01,\n",
       "             2.4338e-01,  2.7539e-02, -5.0408e-01,  5.4269e-01, -3.8908e-02,\n",
       "             2.8022e-01, -1.7876e-01,  4.5912e-02, -1.3334e-01,  7.6302e-02,\n",
       "             6.3081e-01,  1.3240e-01, -1.6534e-01,  2.7074e-02,  7.8945e-04,\n",
       "            -3.9716e-01, -1.8656e-01, -7.4832e-01, -1.8224e-02, -2.3697e-01,\n",
       "            -9.2816e-02, -1.9956e-01,  3.0694e-01, -4.7893e-02, -2.5034e-01,\n",
       "             6.6335e-02, -1.9076e-01, -5.6333e-02,  9.6449e-03, -5.0993e-01,\n",
       "             1.3291e-01,  1.2829e-01,  2.0208e-02,  3.6896e-01, -3.5787e-02,\n",
       "            -2.0743e-01, -1.6674e-01,  1.3730e-01,  3.7553e-01,  1.6187e-02,\n",
       "            -6.1403e-01, -1.4945e-01,  3.3336e-02,  1.5339e-01,  2.2203e-01,\n",
       "             2.8364e-01,  1.9383e-01, -8.5495e-02,  9.4632e-02, -3.6031e-01,\n",
       "            -1.7422e-02, -1.4891e-01, -1.7915e-01,  2.3382e-01,  2.2041e-02,\n",
       "            -2.6283e-02,  2.1069e-01, -8.7041e-02,  3.9942e-01,  1.5559e-01,\n",
       "            -2.5449e-01, -2.8482e-01,  1.7825e-02,  1.5922e-01,  1.0409e-01,\n",
       "            -2.2795e-01,  1.1403e-01, -1.1466e-02,  2.7284e-01, -5.0619e-02,\n",
       "            -1.3068e-01, -7.2693e-02, -3.8937e-01, -4.0776e-01, -1.3943e-01,\n",
       "             6.3343e-02, -1.1532e-01, -5.3106e-01, -2.8062e-03,  2.3334e-01,\n",
       "             3.0378e-02, -2.9618e-01, -8.1852e-02,  1.4879e-01,  7.8251e-02,\n",
       "            -1.7360e-01,  6.9738e-02,  1.3935e-01, -1.6868e-01,  4.9379e-02,\n",
       "             2.0636e-01, -2.3768e-01, -1.7898e-01,  9.7838e-02, -1.4844e-01,\n",
       "            -7.2343e-02,  5.6716e-02,  5.0879e-02,  1.2661e-02, -6.6816e-03,\n",
       "             1.4407e-01, -9.5060e-02,  9.0043e-02, -1.8685e-01,  1.4972e-01,\n",
       "             5.0933e-01,  2.1779e-01,  1.8406e-01,  6.2172e-02,  5.0269e-02,\n",
       "             5.6051e-02, -1.1330e-01,  2.4878e-01,  2.6750e-01, -8.8030e-02,\n",
       "            -6.3535e-02, -9.4388e-01,  2.0249e-01,  3.3815e-03, -7.2959e-02,\n",
       "            -4.3305e-01,  2.1860e-01,  2.2374e-01, -1.3889e-01,  1.2397e-01,\n",
       "            -1.4610e-01, -1.3137e-01,  2.4782e-01, -5.6535e-02,  2.3937e-01,\n",
       "             3.1745e-01,  2.1226e-04, -3.2016e-01, -2.8924e-01,  1.4102e-01,\n",
       "            -6.7372e-02, -1.3746e-01,  2.4720e-01, -2.8813e-01, -9.3662e-02,\n",
       "            -4.3218e-01,  1.1383e-01, -4.4472e-03, -1.7702e-01,  2.6741e-01,\n",
       "             3.0941e-02,  5.1163e-01, -2.5595e-01, -3.2329e-01, -1.9214e-02,\n",
       "             1.3054e-01,  1.1878e-01,  1.2167e-01,  6.9822e-02,  2.8210e-01,\n",
       "            -1.2262e-01,  3.3496e-01, -7.4078e-02,  6.1660e-02, -1.2142e-01,\n",
       "            -1.3335e-01,  1.3449e-01, -1.4233e-01, -1.0232e-01,  6.8670e-02,\n",
       "            -8.1999e-02,  3.1970e-02, -2.6288e-01, -8.6299e-02, -1.0643e-01,\n",
       "            -1.3775e-01, -9.7180e-02,  2.1370e-01, -2.3452e-01, -2.1541e-02,\n",
       "            -2.1148e-01,  9.8329e-02, -2.1669e-01,  3.9058e-01, -2.1723e-01,\n",
       "             3.4880e-01, -9.0003e-02, -2.6025e-01,  1.3102e-01,  1.5607e-03,\n",
       "             1.6922e-01, -2.8320e-01,  2.0214e-01,  1.9640e-01,  7.5069e-02,\n",
       "            -4.9276e-02,  8.8096e-02, -3.2091e-02, -1.2241e-01, -2.7621e-02,\n",
       "            -3.8980e-01,  7.7180e-03, -8.7352e-02, -1.1717e-01,  2.9037e-01,\n",
       "            -3.5483e-02,  4.7150e-02, -8.5157e-02,  2.5165e-01, -8.2987e-02,\n",
       "             1.6953e-01,  2.0415e-01,  1.5110e-02,  1.1350e-01,  2.2944e-01,\n",
       "            -1.6370e-01, -4.4020e-02, -4.2827e-01, -1.5016e-01, -9.1763e-02,\n",
       "             5.7512e-03,  1.3031e-01, -6.3244e-02,  9.9368e-02,  1.1131e-01,\n",
       "             2.5215e-01,  1.6021e-01,  3.9317e-01, -1.6928e-01, -8.7663e-02,\n",
       "             2.7622e-01,  1.0162e-01, -5.4403e-03, -2.8740e-02,  2.5321e-01,\n",
       "             7.7703e-02, -1.7228e-01, -3.8759e-01,  2.5069e-02, -2.6770e-01,\n",
       "             3.2676e-01, -1.0838e-01,  2.6452e-01,  6.9211e-02,  1.9636e-01,\n",
       "             1.1640e-01, -5.5612e-02,  1.8882e-02, -3.3466e-01, -1.4891e-01,\n",
       "            -1.1344e-01,  5.9352e-02,  1.1374e-01, -1.6977e-01, -1.7297e-02,\n",
       "            -8.1594e-02,  1.0708e-01, -1.6406e-02, -3.1441e-01, -2.5802e-01,\n",
       "            -2.2225e-01,  2.9399e-01, -2.3967e-02, -6.1710e-02, -1.9129e-01,\n",
       "            -2.4080e-01, -2.0147e-01,  3.5854e-01, -6.6540e-02,  1.4719e-01,\n",
       "             2.7258e-01,  8.8300e-02,  1.0665e-01, -1.8504e-01, -1.2416e-01,\n",
       "            -1.5580e-02, -2.4286e-01,  5.1245e-01,  2.9153e-01,  1.1257e+00,\n",
       "            -1.2420e-01,  1.0029e-01, -1.8485e-01, -1.1567e-01, -3.3824e-01,\n",
       "             5.8701e-01, -2.0447e-01,  1.3994e-02,  1.3990e-01,  6.0064e-02,\n",
       "            -1.4763e-01, -2.1483e-01,  1.8633e-01, -2.2371e-01, -1.5718e-01,\n",
       "             2.0444e-01, -1.4840e-01, -3.1402e-02,  2.0090e-01,  9.1976e-02,\n",
       "            -2.7040e-01, -8.0946e-02, -1.3928e-01,  6.2822e-02,  3.7909e-01,\n",
       "             5.5086e-02,  1.1879e-01,  1.3405e-01,  1.0864e-02,  4.0484e-01,\n",
       "             6.0242e-02, -5.5044e-02, -1.9326e-01,  2.8165e-01, -1.5320e-01,\n",
       "            -1.2740e-01,  1.6057e-01,  1.3663e-02, -3.6985e-02, -4.4547e-01,\n",
       "             2.8283e-01,  4.2424e-01,  7.6576e-02, -4.0226e-02,  1.0799e-01,\n",
       "            -3.0911e-01, -3.6473e-01, -3.8022e-01,  2.9943e-02, -2.0999e-01,\n",
       "             9.6673e-02,  6.0290e-02, -5.0839e-02, -3.1991e-01,  3.5599e-02,\n",
       "            -2.0322e-01,  4.3858e-02,  2.5176e-01, -2.4139e-01, -4.0700e-01,\n",
       "             2.8429e-01,  2.2619e-01, -1.4491e-01,  2.8706e-01,  4.0801e-01,\n",
       "             1.4286e-01,  5.9248e-02, -3.5262e-01,  9.1910e-02,  1.8208e-01,\n",
       "            -2.0568e-02, -1.4569e-01, -3.3234e-01,  6.4770e-02, -5.6347e-01,\n",
       "             2.1672e-01,  3.7578e-01,  2.0555e-01, -3.5658e-01, -1.3463e-01,\n",
       "             3.6347e-02,  4.5881e-02, -1.3985e-01,  1.8380e-01, -2.9502e-01,\n",
       "            -1.1788e-01, -2.1707e-01, -2.5324e-01, -1.9341e-01, -1.7136e-02,\n",
       "             1.7105e-01, -3.8451e-02, -3.9041e-01,  2.4851e-01,  2.1538e-01,\n",
       "             1.8431e-01,  1.9294e-02, -1.2805e-01, -7.1946e-02,  3.0004e-01,\n",
       "             5.9604e-02, -2.6378e-01, -4.7004e-02, -8.1872e-02,  5.7677e-01,\n",
       "             1.7601e-01, -3.5093e-01,  4.8220e-01, -4.0669e-02,  3.6806e-01,\n",
       "             2.1584e-03, -1.6669e-02,  2.0034e-01,  3.1689e-01, -5.3421e-01,\n",
       "             1.7829e-01, -4.6608e-02, -4.6258e-01, -6.6527e-02, -2.5586e-01,\n",
       "            -3.0110e-01,  3.5430e-02,  2.5177e-01, -1.3957e-01,  2.4426e-02,\n",
       "             8.6169e-02, -1.4566e-01,  1.4435e-02, -6.3949e-02,  3.5331e-01,\n",
       "            -1.0770e-01, -7.0220e-02,  1.6221e-02,  3.7827e-01,  1.8734e-01,\n",
       "            -9.9681e-02,  6.7948e-02, -2.5627e-01, -2.8714e-01,  7.9454e-02,\n",
       "            -1.1200e-01,  2.4989e-01, -3.8092e-01,  3.7455e-01, -3.4079e-01,\n",
       "             2.9570e-02, -2.8253e-02, -3.9114e-01,  2.5397e-01,  1.1003e-01,\n",
       "            -1.3863e-01, -1.4004e-01, -7.5626e-02, -1.7674e-01, -1.4857e-01,\n",
       "             1.5648e-01,  3.0448e-01,  5.1667e-01, -2.1350e-01,  4.8728e-01,\n",
       "             4.0704e-01,  4.9380e-02, -6.4837e-01,  2.9557e-01,  4.1000e-02,\n",
       "             2.0398e-01, -4.1657e-02, -1.4163e-01,  6.7432e-02, -7.0114e-02,\n",
       "            -2.4940e-01, -1.8957e-01,  3.3112e-02,  2.9056e-01,  1.4379e-01,\n",
       "             4.3666e-01,  1.2369e-03,  2.4282e-01, -3.0658e-01,  4.3096e-01,\n",
       "             9.2727e-02, -1.7901e-01, -4.1260e-01,  3.3999e-01,  2.7945e-01,\n",
       "             3.2295e-02, -4.7079e-03, -3.6180e-01, -3.6227e-01,  1.8288e-01,\n",
       "             3.1222e-01, -2.1197e-01, -5.6897e-02,  2.8605e-01, -9.0357e-02,\n",
       "             1.1923e-01, -1.8213e-01,  1.9703e-01,  2.3393e-01,  3.0716e-01,\n",
       "            -1.1125e-01, -8.4015e-02, -2.1205e-01,  3.1102e-01, -5.9851e-01,\n",
       "            -2.1748e-01, -1.5829e-01,  3.2965e-03, -4.6062e-02, -2.7514e-01,\n",
       "             3.5511e-01, -1.7522e-01,  2.5019e-01, -2.3103e-01, -1.7606e-01,\n",
       "            -4.2772e-01,  9.4986e-02, -2.9561e-01,  3.6663e-02, -3.2373e-01,\n",
       "            -7.4443e-02, -2.3252e-01, -1.3813e-01, -3.5520e-01, -2.0473e-02,\n",
       "            -4.2031e-01,  7.9686e-02,  3.4211e-01,  9.8090e-02,  9.3379e-02,\n",
       "             2.4874e-01, -4.0183e-02,  3.3530e-01, -8.1694e-02, -4.8923e-01,\n",
       "             2.3665e-02, -1.4247e-01, -1.6307e-02, -4.6237e-01, -1.8455e-01,\n",
       "             4.1045e-02,  1.3693e-01, -2.9292e-01,  1.7362e-01,  1.6742e-01,\n",
       "             2.7743e-01, -3.6266e-01,  1.0330e-01,  3.8966e-01, -7.2051e-01,\n",
       "            -9.0340e-02, -3.2650e-01,  1.7605e-01, -1.6504e-01, -2.0535e-01,\n",
       "             1.0330e-01,  4.5363e-01, -2.5785e-01,  2.1146e-02, -7.6087e-02,\n",
       "             9.2753e-03, -2.1718e-01, -6.9416e-02,  4.4933e-01,  2.4774e-01,\n",
       "             3.7484e-01,  4.6681e-01,  1.4677e-02,  2.2195e-01,  3.6215e-01,\n",
       "            -3.3883e-01, -2.2627e-01, -2.6455e-01, -2.4796e-01, -9.7859e-02,\n",
       "             1.3168e-02, -1.6572e-01, -3.9811e-01,  8.2675e-02,  1.1086e-01,\n",
       "            -1.2597e-01,  4.9217e-02,  1.5858e-01, -1.7734e-01,  6.8646e-02,\n",
       "             1.6308e-02,  1.6097e-01,  2.5132e-01, -2.5309e-01, -1.9345e-01,\n",
       "            -3.9045e-02, -4.6585e-01, -4.4045e-01,  4.5444e-01,  3.5258e-01,\n",
       "            -1.4664e-01,  1.9479e-01,  5.6584e-02, -4.3729e-01,  2.0958e-01,\n",
       "            -3.4948e-01, -9.6083e-02,  1.3561e-01,  2.5761e-01, -1.7978e-01,\n",
       "             5.2882e-01, -4.2264e-01,  1.7617e-01, -1.3765e-01, -3.6098e-01,\n",
       "             4.1523e-02,  5.2922e-02,  3.4866e-01,  3.4244e-01,  3.4228e-02,\n",
       "            -3.7872e-01,  2.1938e-01, -1.6890e-01, -3.7580e-01,  2.8937e-01,\n",
       "            -4.1508e-01, -3.3336e-01, -1.6663e-01,  4.1006e-01, -3.1821e-01,\n",
       "             2.0601e-01,  1.9699e-01, -4.7081e-01, -5.7434e-02,  5.9630e-02,\n",
       "             7.1080e-02,  3.4561e-01, -2.2434e-01,  4.1188e-01, -2.1742e-01,\n",
       "            -7.3437e-02,  4.0616e-01,  1.8316e-01, -3.1064e-02, -1.3032e-01,\n",
       "            -1.9246e-01,  3.2018e-01, -7.8456e-02, -3.0605e-01,  2.0832e-01,\n",
       "             1.9724e-01,  2.5767e-01, -9.1850e-02,  8.3267e-02,  7.7175e-02,\n",
       "            -2.0944e-01,  9.6606e-02,  3.8886e-02, -5.7106e-02,  2.6198e-01,\n",
       "            -2.5230e-01, -4.5461e-01,  1.7983e-01,  1.0264e-01,  8.0553e-02,\n",
       "             5.9424e-02,  3.1599e-01, -1.5712e-01,  2.7434e-01, -3.7204e-01,\n",
       "             5.6222e-01, -6.6413e-03,  1.4679e-01, -2.0679e-01,  2.2531e-01,\n",
       "            -4.4005e-01,  7.3129e-03, -1.5214e-01, -3.1150e-01, -1.3391e-01,\n",
       "             4.0078e-01,  4.3486e-02,  1.0345e-01,  2.4493e-01, -1.8601e-01,\n",
       "             4.7259e-02, -4.5721e-01, -2.0301e-01,  2.5778e-01, -1.4317e-01,\n",
       "            -1.4558e-01, -2.1160e-02,  2.7010e-01, -7.5785e-02, -1.7309e-01,\n",
       "             9.2344e-02,  6.5754e-02, -3.9101e-01,  2.9910e-01,  3.4726e-02,\n",
       "             3.5138e-04, -1.2142e-01, -6.1359e-01,  5.5349e-01,  7.7229e-01,\n",
       "             4.0677e-02, -2.9904e-01, -4.6826e-01, -8.0610e-02, -1.9038e-02,\n",
       "            -5.2366e-01,  6.9679e-02, -8.5480e-02, -4.5388e-01, -4.5423e-01,\n",
       "             5.8126e-02, -3.6239e-01, -2.2189e-02, -8.5072e-02,  4.9462e-01,\n",
       "            -1.4497e-01,  1.8605e-01,  3.5147e-01, -4.2894e-02, -1.0807e-01,\n",
       "            -1.1124e-01, -4.2484e-01, -1.0141e-01, -1.2226e-01,  3.5190e-01,\n",
       "            -2.1018e-01, -4.9191e-01,  3.2335e-01, -8.9967e-03,  1.8448e-01,\n",
       "            -7.5478e-02, -5.3947e-02, -1.6462e-01,  3.2909e-01, -2.8464e-01,\n",
       "             2.0319e-01,  3.5378e-01,  1.8666e-03, -1.6553e-01, -2.2137e-01,\n",
       "             2.4431e-01, -3.5100e-01, -3.1488e-02, -1.1884e-01,  3.2171e-01,\n",
       "            -8.3966e-02, -1.5776e-01,  1.9084e-01,  4.0932e-01, -3.4418e-01,\n",
       "            -3.3944e-01,  1.4765e-01, -2.6419e-01, -2.0063e-01, -3.0776e-01,\n",
       "             5.2826e-03,  4.7639e-01, -4.8028e-01,  5.5727e-01,  1.4458e-01,\n",
       "             1.7992e-01, -3.8444e-01,  2.7138e-01, -2.1487e-01, -4.3744e-02,\n",
       "            -7.5657e-03,  4.0249e-02,  1.1963e-01, -2.7011e-01, -6.1699e-02,\n",
       "            -1.5927e-01,  4.5808e-02,  2.7013e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,   510, 15878, 18088, 34982,   310,   247,\n",
       "            13726,   273,  3684, 15878, 18088, 38715,   275, 15319,  3928,    13,\n",
       "            23050,   326,   310,  1929,   323,   697,  4719,   273, 17942, 21440,\n",
       "              285,  6483, 15777,    15,   380, 34982,    13,   347,   352,   310,\n",
       "             1929,    13,   310,   670,   577,    15,    19,  6574,   313,    23,\n",
       "               15,    25, 10771,    10,  1048,    13,   285, 17954,  4745,  6420,\n",
       "              273,   253, 15878, 18088,  2846,  7787,   275,   253,   440, 39558,\n",
       "            15918,   273, 40577,   285,   411, 47724,  2971,   533,   310,  2223,\n",
       "             6289,   281,  3365,   347, 15878, 18088,    15,     0]])),\n",
       "  (tensor([[-1.4738e-01, -3.9036e-01, -9.3487e-02, -4.4237e-02, -2.2822e-01,\n",
       "             6.8411e-02,  6.5440e-02, -2.0953e-02, -5.5948e-01, -6.4941e-02,\n",
       "             3.7647e-01,  5.9956e-02, -1.3234e-03, -2.9700e-01,  6.8466e-02,\n",
       "            -9.1562e-02, -4.7121e-02,  2.2002e-01,  3.4121e-01, -8.5209e-02,\n",
       "            -4.0119e-01, -1.3979e-01, -1.3841e-01,  2.8865e-01,  1.4623e-01,\n",
       "             6.0517e-01, -1.3198e-01, -9.2062e-02, -1.7993e-01,  1.4242e-01,\n",
       "             1.9927e-01, -1.2571e-03, -2.2415e-01,  2.5273e-01, -2.0337e-02,\n",
       "            -2.4260e-01, -2.8522e-01, -6.7182e-01, -1.2285e-02, -3.9987e-01,\n",
       "            -3.9793e-02, -3.6530e-01,  9.1977e-02,  3.5241e-01, -1.6565e-01,\n",
       "             6.3924e-02,  5.2319e-02, -1.5372e-01,  5.7011e-02, -2.9622e-01,\n",
       "             2.2863e-01, -1.4442e-02, -3.9375e-01,  6.1498e-02, -3.2512e-01,\n",
       "            -2.0799e-01,  5.5358e-01,  6.7557e-02,  1.7441e-01, -1.2926e-02,\n",
       "            -1.7388e-01,  1.8334e-01, -9.5916e-02, -2.4011e-01,  4.4298e-01,\n",
       "             7.7211e-02,  1.9906e-02,  1.3231e-01,  9.0763e-02, -2.8476e-02,\n",
       "             7.0048e-03, -8.8513e-02, -1.8634e-01,  1.4047e-01,  9.3721e-02,\n",
       "            -3.2181e-01,  1.3197e-01, -3.4749e-01, -5.6568e-02, -1.3041e-02,\n",
       "            -3.4465e-01, -9.7361e-02, -5.1204e-02,  3.9854e-01,  1.3019e-01,\n",
       "             2.3656e-02,  8.3000e-02, -1.8541e-01, -8.4888e-02, -1.7390e-01,\n",
       "            -2.7146e-02, -2.6721e-01, -2.2928e-01, -1.3270e-01,  2.7518e-01,\n",
       "             6.7239e-02,  1.4657e-01, -2.7148e-01,  4.9435e-02,  1.2192e-01,\n",
       "             3.9506e-02,  1.2424e-01, -3.5106e-01, -1.7153e-01,  8.6495e-03,\n",
       "             1.2531e-01, -1.4035e-01,  8.8032e-02, -1.2881e-01, -7.9248e-02,\n",
       "             2.3769e-01, -2.6021e-01, -1.3196e-01, -3.3329e-01,  5.7325e-02,\n",
       "            -4.3349e-01, -1.3721e-01,  4.7323e-01, -1.3880e-01,  3.6048e-02,\n",
       "             6.5765e-02,  1.1366e-01,  2.8320e-02,  2.8745e-01,  1.4785e-01,\n",
       "            -2.6939e-02,  7.1120e-02, -2.2354e-01, -7.3835e-02,  2.1779e-01,\n",
       "             2.3060e-02, -9.3691e-02,  1.1563e-01,  2.7523e-01,  1.0093e-01,\n",
       "             1.4425e-01, -7.4982e-01, -9.8254e-03, -1.3427e-01,  3.0454e-01,\n",
       "            -2.6705e-01,  3.2394e-02,  3.2200e-01, -1.2958e-01, -6.8183e-04,\n",
       "            -3.9048e-01, -6.3045e-02, -1.4554e-01, -5.8224e-02, -3.0585e-01,\n",
       "             1.2041e-01,  7.0631e-02,  3.6236e-01, -1.5877e-03,  4.6280e-02,\n",
       "            -5.7209e-03,  8.1670e-02, -3.2120e-01,  9.9124e-02, -7.5737e-02,\n",
       "            -1.9688e-01,  4.4361e-01, -9.2490e-02,  1.6716e-02, -8.9629e-02,\n",
       "            -4.0151e-01,  5.4794e-01,  2.3605e-01, -9.5856e-02,  1.7420e-01,\n",
       "             1.6093e-01,  7.5422e-02, -9.1867e-02,  1.2696e-01,  5.1969e-02,\n",
       "            -4.1209e-01, -1.8031e-01, -3.7986e-01, -3.1503e-02, -1.7763e-01,\n",
       "            -2.1256e-01,  7.6006e-02,  1.4972e-01, -9.9268e-02,  2.2834e-01,\n",
       "            -2.9430e-01,  4.7943e-02, -1.3120e-01, -1.3772e-02,  1.5747e-02,\n",
       "            -3.2222e-01,  1.2129e-01, -3.5478e-01,  6.1993e-02, -1.0226e-01,\n",
       "            -1.9178e-01, -2.6942e-01, -4.7934e-01,  4.6653e-01, -2.4323e-01,\n",
       "             4.5705e-01, -2.1500e-01,  2.4392e-01, -2.5767e-01, -8.8270e-02,\n",
       "            -1.1684e-01, -2.9293e-01, -2.2051e-02,  2.7680e-02,  2.7276e-02,\n",
       "            -4.9620e-02,  1.4012e-01,  4.3292e-02, -5.7257e-02, -4.5638e-02,\n",
       "            -2.8677e-01, -1.1990e-01, -7.6257e-02, -1.2154e-01,  1.0761e-01,\n",
       "             3.3985e-01, -1.8451e-01,  3.2590e-02,  2.4545e-01,  2.2312e-01,\n",
       "            -2.6450e-04,  8.3483e-02, -3.4019e-01, -1.8149e-01,  2.7700e-01,\n",
       "             6.4988e-01,  6.1172e-03, -1.0719e-01, -4.4842e-01,  2.3182e-01,\n",
       "            -2.9887e-01, -1.2197e-01, -4.8351e-02,  1.9616e-01, -7.1412e-02,\n",
       "            -7.6238e-02, -3.6736e-02,  2.7808e-01, -2.5066e-01, -1.7782e-01,\n",
       "             1.1406e-01,  2.6652e-01, -2.0935e-01, -2.4913e-01,  3.0777e-02,\n",
       "             4.1829e-02,  8.6956e-02, -3.4657e-01, -2.5828e-01, -4.7542e-01,\n",
       "            -9.5382e-02, -5.2073e-02, -8.6272e-02,  2.0094e-01, -1.4686e-01,\n",
       "             4.4610e-02, -1.1169e-01, -1.0432e-01, -3.4353e-01,  3.1068e-01,\n",
       "            -5.5562e-02, -3.1962e-01,  7.4409e-01, -1.7926e-01,  8.4041e-02,\n",
       "            -2.3922e-01, -2.7645e-01, -1.5529e-01, -1.0253e-01,  5.8373e-02,\n",
       "            -8.1084e-02,  1.2029e-01,  1.8305e-01, -8.6888e-02, -5.6277e-02,\n",
       "            -2.3429e-01, -4.5911e-02,  6.2641e-02, -2.9851e-01, -2.1256e-01,\n",
       "             3.9371e-01, -6.0202e-02,  1.1131e-01,  7.9397e-02,  1.5820e-01,\n",
       "            -6.9055e-02, -2.7965e-01,  2.0049e-02,  1.5846e-01,  8.3127e-01,\n",
       "             5.1937e-02,  5.7684e-02,  3.3905e-02, -3.4450e-01,  1.0325e-01,\n",
       "             2.5980e-01, -4.3223e-01,  3.4247e-01, -1.0754e-01,  1.0611e-01,\n",
       "             5.4450e-02, -2.7796e-02, -2.1344e-01, -1.3165e-02,  1.7629e-01,\n",
       "             8.9287e-01,  3.7034e-01, -6.8464e-02,  2.9999e-01,  3.6084e-01,\n",
       "            -2.0100e-01, -2.7381e-01, -1.5139e-01, -4.6668e-03,  2.1013e-01,\n",
       "            -1.8181e-01, -1.2219e-01, -1.8858e-01,  4.6817e-02,  7.7126e-02,\n",
       "            -3.3043e-02, -6.5351e-03,  2.3043e-01,  1.4405e-01,  4.0857e-02,\n",
       "            -1.0265e-01,  3.1533e-02,  7.4130e-02,  2.4330e-02, -1.2178e-01,\n",
       "             2.2258e-01, -1.2823e-01, -3.5158e-02,  8.2811e-02, -9.9906e-02,\n",
       "            -3.7503e-01,  9.4214e-02,  1.9989e-01,  2.6526e-01,  1.6799e-02,\n",
       "             3.4604e-01,  1.4993e-01, -6.2548e-02, -3.1412e-01, -7.9598e-02,\n",
       "            -8.2512e-02,  9.6419e-02,  2.7400e-01, -2.0055e-02,  1.5383e-01,\n",
       "             2.2026e-01, -2.8305e-01, -2.1916e-01,  1.1661e-01,  6.6893e-01,\n",
       "             8.8510e-03,  7.5056e-02,  1.7204e-01, -2.2846e-01, -2.4808e-02,\n",
       "            -5.0057e-01,  3.3335e-02, -6.9783e-02, -1.0969e-01,  2.4433e-02,\n",
       "             1.9436e-01, -1.5983e-03,  3.0265e-01,  1.4115e-01, -8.8287e-02,\n",
       "             2.2925e-02,  2.5524e-01, -2.2801e-01,  3.5183e-02, -1.7046e-01,\n",
       "             1.3096e-03,  5.2609e-02, -9.7103e-02, -4.7572e-02, -2.7626e-01,\n",
       "            -1.6801e-01,  5.0412e-01,  5.9263e-02, -2.4299e-01,  1.0490e-01,\n",
       "            -1.1766e-01,  8.0013e-02,  2.4407e-01, -3.7612e-01,  2.8222e-02,\n",
       "             1.4887e-01, -3.1090e-01,  2.2293e-01,  9.3406e-02,  1.6346e-01,\n",
       "             2.3111e-01, -2.3376e-01, -3.0459e-01,  2.1548e-01,  2.1040e-01,\n",
       "             1.2448e-01, -2.0806e-04,  2.7817e-01,  3.2062e-01, -2.5654e-01,\n",
       "             6.2632e-01,  1.5290e-02, -3.2326e-01, -1.6641e-01, -1.4355e-01,\n",
       "            -1.7789e-01, -3.3574e-01,  1.7478e-01, -1.0399e-01, -1.0214e-01,\n",
       "             8.6841e-02,  2.0089e-01, -2.6701e-01,  2.5795e-01,  3.1363e-01,\n",
       "             3.7358e-01,  3.3052e-01,  2.0314e-01,  2.1285e-01,  2.1120e-01,\n",
       "             9.0782e-03,  4.3644e-01,  3.4039e-01, -3.7721e-01,  2.2214e-01,\n",
       "            -1.9402e-01, -2.5671e-01, -2.0601e-01,  1.4362e-01,  2.2012e-01,\n",
       "            -1.0031e-01, -1.7600e-01,  3.1982e-01,  3.3510e-01,  1.2244e-01,\n",
       "            -1.4739e-01,  1.1822e-01, -4.8075e-01,  9.1140e-02, -1.3985e-01,\n",
       "            -9.1229e-02,  9.0430e-02,  1.9686e-01, -5.1447e-01,  3.7978e-01,\n",
       "             1.7659e-01,  2.0077e-02, -4.9607e-01, -1.4585e-01,  3.5726e-01,\n",
       "             3.9235e-01,  7.5196e-02, -7.2002e-02,  1.9632e-01, -1.4863e-01,\n",
       "             2.6154e-01,  9.1214e-02,  2.5480e-01, -2.2351e-01, -3.4297e-02,\n",
       "             1.6749e-02,  1.7696e-01, -3.3877e-01, -4.8409e-01,  3.8802e-01,\n",
       "             5.6251e-01, -5.8100e-02, -1.2977e+00,  4.6376e-01, -1.0849e-01,\n",
       "            -3.7370e-01,  2.9297e-01, -2.5860e-01, -1.9825e-01,  3.0155e-01,\n",
       "             5.0024e-01, -3.9743e-01,  3.2273e-02, -4.2336e-01, -2.4861e-02,\n",
       "            -4.7255e-01, -2.8815e-01,  1.6030e-01,  1.6051e-01,  1.3894e-01,\n",
       "             4.1981e-02, -4.3699e-01,  1.6483e-01,  2.6462e-02, -7.5194e-01,\n",
       "             1.1262e-01,  1.9020e-01, -2.9189e-01,  2.5087e-02, -7.4071e-02,\n",
       "             1.4087e-02,  7.7507e-03,  3.4848e-02, -3.9942e-01, -7.1011e-02,\n",
       "             1.6743e-01, -3.7670e-01, -2.9478e-01,  2.6359e-01, -8.4194e-02,\n",
       "             3.9163e-01, -6.1401e-02, -6.1026e-02, -4.7244e-02,  2.3051e-01,\n",
       "            -2.0563e-01, -2.8561e-01, -1.6216e-01, -1.5330e-01, -4.7161e-01,\n",
       "            -1.7148e-01,  8.2960e-02, -1.0616e-01, -1.7195e-01, -4.7405e-01,\n",
       "            -3.6249e-01, -2.7046e-02, -2.6729e-01, -4.3420e-01, -2.1929e-01,\n",
       "             2.4447e-01,  2.0143e-01, -4.6381e-03,  1.9086e-01,  3.4464e-02,\n",
       "             3.6765e-01,  3.0016e-01, -2.6892e-01, -9.3740e-02, -6.5625e-01,\n",
       "            -1.5638e-01,  1.1197e-01,  1.0556e-01, -4.9301e-02,  1.9585e-01,\n",
       "             2.9007e-01,  3.9926e-01, -3.2624e-01, -4.0548e-01,  4.2354e-01,\n",
       "             1.4938e-01,  1.5543e-01, -2.0966e-01, -2.9542e-01, -3.6588e-01,\n",
       "             3.2619e-01,  2.9537e-01, -5.6790e-02, -6.1668e-01,  2.7221e-01,\n",
       "             1.7199e-01,  4.4387e-02,  4.4482e-02,  2.8761e-01, -1.1249e-02,\n",
       "             1.1319e-01,  3.1000e-02, -2.6445e-01,  3.9974e-01,  7.4798e-02,\n",
       "             1.4081e-01, -2.0581e-01, -1.0351e-02,  3.3138e-01,  8.8729e-01,\n",
       "            -3.4806e-02, -9.1827e-02, -2.6210e-01, -5.8606e-01,  4.9522e-01,\n",
       "             2.9765e-01, -4.8045e-01,  1.2912e-01,  3.7935e-01,  1.9406e-01,\n",
       "            -3.1092e-02,  2.2433e-01, -4.7492e-02, -1.3251e-01, -3.4994e-01,\n",
       "            -4.0386e-01,  1.9450e-01, -2.5349e-01,  3.3112e-01, -2.1744e-01,\n",
       "             2.2602e-01,  3.4623e-02,  5.4361e-01, -8.2607e-02, -2.3602e-02,\n",
       "             4.8993e-02,  2.6662e-01,  1.0559e-01, -1.7877e-02,  7.2217e-02,\n",
       "             5.2990e-02,  3.6520e-01,  8.8721e-02,  3.0017e-01,  2.0739e-01,\n",
       "            -1.9837e-01, -2.7420e-01, -8.0544e-01,  1.8925e-01, -3.2123e-01,\n",
       "             1.0875e-01,  1.6122e-01, -3.2084e-02, -2.0483e-01, -3.0050e-01,\n",
       "            -8.7800e-02,  2.0145e-01,  2.5562e-01, -3.4511e-01, -4.3654e-02,\n",
       "             1.1061e-01,  2.5651e-01,  4.4793e-02,  1.5642e-01,  2.0942e-01,\n",
       "            -1.8065e-01,  3.6884e-02, -2.2883e-01, -4.1177e-02, -1.4789e-01,\n",
       "             2.2432e-01,  3.1241e-01, -4.9090e-01, -2.3995e-03, -1.0166e-01,\n",
       "            -7.0806e-02,  3.6698e-01,  2.1639e-01, -1.0465e-01,  1.2973e-01,\n",
       "            -2.9751e-01, -1.9774e-01,  2.2259e-01,  1.2379e-01,  2.7636e-02,\n",
       "            -3.6994e-01,  2.6431e-01, -3.2233e-01, -3.9383e-01,  2.1858e-02,\n",
       "             3.4306e-01, -2.6500e-01, -1.6693e-01, -2.4102e-01, -2.0628e-01,\n",
       "            -1.4141e-01, -6.2474e-02, -3.1733e-01,  2.3550e-01, -4.2318e-01,\n",
       "            -2.4708e-01,  3.8447e-01,  2.6059e-01,  1.0810e-01, -5.7628e-02,\n",
       "             9.8105e-02, -4.2431e-02,  2.9079e-01,  2.2217e-01, -5.9232e-01,\n",
       "             3.0368e-01,  1.4317e-02, -8.7636e-02, -3.8188e-01,  2.5442e-01,\n",
       "            -2.5183e-01,  8.8014e-02, -3.3184e-01,  5.8938e-01, -2.6047e-03,\n",
       "             7.7213e-03,  8.8362e-02, -4.0593e-01, -7.2466e-02,  2.2305e-01,\n",
       "            -2.5014e-01,  3.7017e-01, -8.6935e-02, -1.3999e-01,  2.7615e-02,\n",
       "            -4.4430e-01, -2.3341e-01, -6.2780e-02, -4.1835e-01,  3.0663e-01,\n",
       "             2.5651e-02,  1.3307e-01,  4.5140e-01, -1.5546e-01, -3.2372e-01,\n",
       "            -2.6147e-01,  1.2017e-01,  3.3344e-01,  8.3175e-02,  5.0865e-01,\n",
       "            -4.1996e-02, -2.1347e-01,  8.3011e-02,  1.3640e-01,  1.1191e-01,\n",
       "            -4.3915e-01,  1.7814e-01, -3.2449e-01,  5.7796e-02,  5.8910e-01,\n",
       "            -4.5819e-02, -2.3180e-01, -6.7392e-02, -4.9082e-02,  1.4628e-01,\n",
       "            -3.2124e-01,  3.9146e-02,  2.8285e-02, -2.0427e-01, -2.9611e-01,\n",
       "             9.3792e-02,  2.7814e-02,  1.1436e-01, -9.7033e-03,  2.5606e-01,\n",
       "             4.9266e-01,  6.6892e-02, -2.8403e-01,  1.9852e-02, -1.9521e-01,\n",
       "             1.3159e-01,  1.7579e-02, -3.1479e-01,  2.0582e-02,  1.2694e-01,\n",
       "             1.7822e-01,  5.5307e-01, -6.2862e-01,  1.8258e-01,  6.4174e-02,\n",
       "             2.4980e-02, -3.5814e-01, -9.2904e-02, -3.1970e-01,  7.4895e-02,\n",
       "            -2.6420e-01,  1.7611e-01,  2.2954e-01, -1.5340e-01,  1.6781e-01,\n",
       "             1.7782e-01, -2.7637e-02,  2.2902e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 11688,   621,   403,  5699,   594,   604,\n",
       "              368,  1472, 18254,   436,   310,   253,  1659,    15,   380, 39438,\n",
       "            11381,   403,  8644,   342,   253, 36018, 25308,    15, 10338,  2119,\n",
       "              281,  1611,   581,   281,  3894, 10159,   752,   673,   368,   403,\n",
       "              627,     0]])),\n",
       "  (tensor([[ 3.2039e-01, -2.8997e-01, -3.0658e-02,  1.3021e-01, -6.8710e-02,\n",
       "            -2.7525e-01, -1.8795e-01,  7.2678e-02, -2.0876e-01, -7.4082e-03,\n",
       "             3.9972e-01,  3.9204e-01,  4.3070e-02, -2.3399e-01,  1.8942e-01,\n",
       "            -7.8825e-02, -1.2391e-01,  1.1731e-01,  3.8898e-01,  5.8383e-02,\n",
       "            -2.3038e-01, -1.4231e-02, -4.7768e-01, -6.2067e-02,  1.8707e-01,\n",
       "             1.2995e-01,  1.4857e-01, -1.1236e-01, -1.0621e-01, -1.0301e-01,\n",
       "             3.2804e-01,  1.2946e-01, -7.7362e-02,  4.7749e-02, -2.8326e-02,\n",
       "             5.3436e-02,  2.6282e-01, -2.6406e-01, -4.1397e-01,  3.9849e-01,\n",
       "            -6.2949e-02, -3.7454e-02,  4.7973e-01,  2.4336e-01, -3.4063e-01,\n",
       "             8.8988e-03, -1.1616e-01, -6.6574e-02,  1.4424e-01, -2.7371e-02,\n",
       "             2.4579e-01, -2.9436e-02,  2.1961e-01, -2.3867e-01, -1.9116e-01,\n",
       "            -1.7730e-01, -1.1198e-01, -2.8422e-01,  1.3321e-01,  3.4881e-02,\n",
       "            -1.5431e-01,  2.3305e-01, -1.1980e-01, -3.0117e-01,  5.1213e-01,\n",
       "             3.6253e-01, -2.4089e-03,  1.5674e-01,  1.7959e-01,  3.9013e-02,\n",
       "             5.4332e-01, -3.1846e-01,  8.5723e-02,  1.9802e-02, -8.0098e-02,\n",
       "            -2.9117e-01, -9.9500e-02,  1.3434e-01,  5.0254e-02, -1.5663e-01,\n",
       "             3.0917e-01, -1.2053e-01, -2.1082e-01,  8.2082e-02,  8.3092e-02,\n",
       "            -1.1305e-01, -5.6900e-02, -3.3216e-01,  1.9952e-01, -1.7439e-01,\n",
       "             1.7805e-01, -1.5555e-01, -2.8385e-01,  6.2979e-01, -1.1341e-02,\n",
       "            -1.0584e-01, -5.3284e-02, -5.7486e-01, -2.9697e-02,  1.8263e-01,\n",
       "            -5.3263e-01,  1.3161e-01, -3.2836e-01, -3.2364e-01,  6.8378e-02,\n",
       "             6.4520e-02, -1.1741e-01, -2.5700e-01, -1.9392e-01, -1.6737e-01,\n",
       "             2.0790e-01, -4.2529e-02,  1.9805e-01, -1.7709e-01, -1.8820e-01,\n",
       "             4.0500e-02, -4.3004e-02,  1.5946e-02, -1.1296e-01, -4.1721e-01,\n",
       "            -2.5022e-01,  4.2899e-01,  1.9546e-01,  3.0760e-01, -1.2691e-01,\n",
       "             8.9566e-02,  2.5392e-02,  1.9674e-01,  1.7266e-01,  4.8630e-01,\n",
       "            -1.7667e-01, -8.8453e-01, -2.4485e-02,  6.2398e-01,  4.1880e-01,\n",
       "            -5.2057e-02, -1.3254e-01,  1.6120e-01, -2.6859e-01,  1.0238e-01,\n",
       "            -6.6068e-02, -7.9467e-02, -5.0010e-03, -1.5265e-01, -1.2310e-01,\n",
       "            -2.6105e-01,  2.3034e-01, -4.7502e-02, -3.7045e-01,  1.1789e-01,\n",
       "             2.9750e-01,  1.6774e-01,  2.3067e-01, -3.6864e-01, -3.4954e-01,\n",
       "             3.1869e-01, -1.7046e-01,  1.9311e-01, -6.1512e-02,  2.3068e-01,\n",
       "            -4.6787e-01, -1.8182e-02, -3.0594e-01, -3.8110e-01,  2.3934e-01,\n",
       "             6.7244e-02,  1.1456e-01,  1.6665e-01, -8.5473e-02,  3.2145e-01,\n",
       "             2.7219e-02,  2.6847e-01, -3.7420e-01,  3.5939e-01, -1.0848e-01,\n",
       "            -1.6332e-01, -8.6616e-02, -3.8248e-01,  1.3709e-01, -1.9398e-01,\n",
       "             1.2386e-01,  1.2459e-01, -1.6080e-01, -1.0179e-01, -2.9762e-01,\n",
       "            -3.3720e-01,  7.5449e-03, -1.2182e-01, -4.0477e-01,  2.1317e-01,\n",
       "            -1.8379e-01,  4.4753e-02,  3.5810e-01, -7.3696e-03,  1.5790e-01,\n",
       "            -2.1667e-01, -4.2545e-01,  1.0135e-01,  4.4462e-01,  3.6927e-01,\n",
       "             2.1872e-01,  8.5364e-03, -3.5160e-01, -2.1464e-01, -2.7469e-01,\n",
       "            -2.5173e-02,  1.3106e-02, -4.7005e-03,  3.6736e-02, -2.9992e-02,\n",
       "             1.1122e-01,  1.8996e-01,  2.2731e-01,  2.2525e-01, -2.2945e-01,\n",
       "             2.5898e-02,  1.2590e-01, -6.8362e-01,  1.2587e-01,  2.7041e-01,\n",
       "            -1.3888e-01,  3.2168e-02, -1.4159e-02,  3.2743e-01,  3.1841e-01,\n",
       "             1.4755e-01, -2.2984e-01,  3.6490e-01,  6.8863e-04, -2.9827e-01,\n",
       "             1.9164e-01, -2.6756e-02, -7.6327e-02, -4.3139e-01, -1.8894e-01,\n",
       "            -8.5491e-04, -7.5468e-02,  1.9396e-01,  3.3617e-01, -1.1277e-01,\n",
       "            -3.8230e-01,  4.3115e-01,  2.4503e-01,  6.6760e-02, -6.8945e-02,\n",
       "            -3.1751e-01, -7.9957e-02,  1.9163e-01, -1.1762e-01,  2.2976e-01,\n",
       "             3.6256e-01, -5.4611e-02, -1.0911e-01, -3.1166e-01, -4.2888e-01,\n",
       "             1.1506e-01, -2.9291e-01, -3.2235e-01, -1.4615e-02,  3.0549e-01,\n",
       "            -4.4384e-02,  1.1906e-01,  2.3423e-01, -6.8844e-02,  6.4165e-01,\n",
       "             2.1977e-01,  2.1165e-01, -1.8625e-01,  1.9999e-01, -3.4454e-01,\n",
       "             1.8136e-01, -2.9337e-01, -2.0180e-01, -4.3798e-01, -2.6639e-02,\n",
       "            -3.9002e-03, -1.4631e-01,  2.0140e-02,  3.7286e-02, -4.2412e-01,\n",
       "            -4.0557e-01,  1.9208e-01, -8.8240e-02, -2.8519e-01, -4.4785e-02,\n",
       "             3.8077e-02, -2.7227e-01,  3.4533e-01,  1.1660e-01, -2.0942e-01,\n",
       "             2.6206e-02, -2.2593e-01,  4.1685e-02, -2.3180e-01,  2.3960e-01,\n",
       "             6.7274e-02,  8.9493e-02, -5.3401e-03, -2.6396e-03,  7.2497e-03,\n",
       "            -1.3896e-01, -2.9955e-01,  3.7445e-01, -1.8338e-02,  2.4798e-04,\n",
       "            -3.5801e-02,  5.0352e-02, -1.8375e-01, -2.8527e-01,  3.6440e-01,\n",
       "             1.3304e-01, -1.4082e-01,  3.5657e-03,  5.9659e-01,  2.7118e-01,\n",
       "            -1.3013e-01, -1.9750e-01, -2.7404e-01, -3.4400e-01,  3.9144e-01,\n",
       "             2.5925e-01, -4.8347e-03, -2.2557e-01, -3.0957e-02,  1.1523e-01,\n",
       "            -1.1646e-01, -7.1780e-02,  2.0201e-01, -7.6779e-02, -6.7287e-02,\n",
       "            -1.4412e-01,  2.1769e-01, -1.0892e-01,  2.9430e-01, -1.2242e-01,\n",
       "             2.6633e-01, -1.6477e-01, -6.0650e-02,  2.5582e-01,  4.9214e-02,\n",
       "            -5.7869e-01,  2.2551e-01,  2.6432e-01, -2.4816e-01,  1.8384e-01,\n",
       "             2.5780e-01,  1.0789e-02,  5.3121e-02,  1.0981e-01,  5.1646e-01,\n",
       "            -2.3475e-01,  7.1330e-02, -4.5362e-02, -2.7175e-01,  5.3944e-02,\n",
       "             1.9410e-02, -3.8186e-01,  2.0824e-02,  4.0725e-01, -4.5496e-02,\n",
       "             1.0796e-01,  9.4246e-02,  4.4927e-01,  2.3041e-01, -1.0314e-01,\n",
       "            -6.3250e-01, -1.0135e-01,  9.2817e-02,  1.5811e-01, -2.7843e-01,\n",
       "             1.3998e-01,  3.6939e-03,  4.3863e-01,  1.9448e-01,  2.3647e-02,\n",
       "            -1.4766e-01,  3.6315e-02, -7.3545e-02,  2.2316e-01,  2.8131e-01,\n",
       "             1.3432e-01, -1.5474e-01, -6.2636e-02,  1.0758e-01,  1.2805e-01,\n",
       "             3.7600e-02,  4.3059e-01, -7.3946e-01,  2.2458e-01,  1.2550e-01,\n",
       "             1.8467e-01,  2.2629e-01,  4.1448e-01,  1.8036e-01, -1.6724e-01,\n",
       "            -5.8193e-02,  3.2749e-01,  2.2562e-01,  4.9635e-01,  4.4684e-03,\n",
       "             2.8961e-01,  4.6298e-02,  1.7573e-01, -3.8925e-01, -1.1882e-01,\n",
       "             1.0781e-02,  2.2587e-01,  3.9567e-01, -2.2075e-01,  2.1468e-01,\n",
       "            -8.4940e-02,  6.3007e-01, -3.2016e-01, -2.6307e-01, -1.0099e-01,\n",
       "            -4.0293e-01, -1.6242e-01,  1.2004e-01, -1.8033e-02, -2.0948e-01,\n",
       "            -1.9808e-01, -1.2542e-01,  2.9359e-01,  2.7606e-01,  3.1846e-01,\n",
       "            -1.1344e-01,  2.2958e-01,  2.3333e-01, -1.0902e-01, -5.4925e-02,\n",
       "             1.8471e-01, -2.5662e-02,  5.1820e-01, -1.2357e-01,  3.4859e-01,\n",
       "             2.4434e-01, -2.9767e-01,  1.0343e-01,  1.3372e-01,  2.6070e-01,\n",
       "            -3.3070e-01, -1.9197e-01,  3.9061e-01, -1.3117e-01,  1.8834e-01,\n",
       "             3.9183e-02,  8.2214e-02, -1.3330e-01, -4.4111e-01, -3.3030e-01,\n",
       "            -6.0040e-01,  1.0827e-01,  2.6359e-01,  3.1614e-01,  1.4641e-01,\n",
       "             9.8692e-03, -4.3348e-01, -7.8143e-03,  1.0238e-01,  1.6152e-01,\n",
       "             6.3313e-02, -3.8138e-02, -3.0098e-01,  1.2658e-01, -3.7367e-01,\n",
       "             3.3969e-01, -6.5782e-02,  3.4280e-01, -4.0113e-02,  4.4064e-02,\n",
       "            -1.1880e-01, -2.6667e-02, -3.2739e-01, -4.4467e-01, -3.7408e-01,\n",
       "             5.8683e-01, -4.2758e-02, -9.7903e-01,  4.4842e-02, -3.0905e-01,\n",
       "            -1.0527e-01,  5.7906e-01, -1.1071e-01, -3.4041e-01,  2.6554e-01,\n",
       "             2.3564e-02, -6.5412e-01, -9.9114e-02, -1.6324e-01, -7.3367e-02,\n",
       "            -8.7973e-02, -3.8723e-01,  2.6029e-02, -3.0967e-02, -1.2736e-01,\n",
       "            -1.6512e-01, -2.0973e-01, -2.0190e-01,  3.5069e-02, -3.1398e-01,\n",
       "             1.4144e-01,  1.5150e-01,  3.2583e-01, -2.1579e-01,  3.6387e-01,\n",
       "             5.5983e-01, -8.0075e-02, -4.5947e-02, -1.0809e-01,  2.0053e-01,\n",
       "            -4.8313e-02, -4.9879e-01, -1.9781e-01, -1.1918e-01, -1.5330e-01,\n",
       "            -2.2854e-01,  2.3660e-01,  4.4978e-01, -3.7680e-01,  5.1788e-01,\n",
       "            -2.0642e-01, -6.5376e-01, -4.4024e-02,  2.2806e-01, -2.3555e-01,\n",
       "            -7.4701e-03,  1.0085e-02, -1.3562e-01, -4.3615e-02,  3.6410e-01,\n",
       "            -4.8292e-01, -1.4776e-02, -3.0249e-01, -3.4235e-01, -2.7445e-01,\n",
       "             1.0874e-01, -3.1628e-01, -3.8789e-01,  2.0122e-01,  4.1801e-02,\n",
       "            -4.5321e-01, -4.5446e-01, -1.8567e-01, -2.1550e-01, -1.4203e-01,\n",
       "            -6.1161e-01, -2.6768e-01, -2.9685e-01,  1.8367e-01,  4.5673e-01,\n",
       "            -8.5672e-02,  3.6294e-01, -2.0096e-01, -5.8602e-01,  3.4372e-01,\n",
       "            -1.0805e-01,  4.6312e-01, -1.2968e-01, -2.1120e-02, -6.0816e-01,\n",
       "             1.2854e-01,  3.2244e-01, -1.7104e-01, -6.4373e-02, -3.2401e-01,\n",
       "            -7.1615e-03,  1.2030e-01,  2.0349e-01,  4.7689e-01, -4.8726e-02,\n",
       "            -2.7093e-01,  5.9692e-02,  3.7795e-02,  2.6828e-01, -1.5680e-01,\n",
       "             2.3315e-01, -2.1788e-01,  3.2756e-02, -1.1455e-02, -3.5001e-02,\n",
       "             1.5847e-01, -1.3267e-01,  1.5686e-01, -1.1204e-01,  7.9250e-02,\n",
       "             9.1442e-02, -1.4584e-01, -2.4921e-01, -2.0550e-01,  3.4627e-01,\n",
       "             1.5964e-01,  3.2883e-01,  2.1243e-01,  1.6983e-01,  2.9955e-01,\n",
       "            -1.6061e-01, -7.8475e-02, -2.6647e-01,  1.3153e-01,  2.1936e-01,\n",
       "             2.1481e-01, -2.3838e-01,  1.4253e-01, -2.9846e-01, -6.1541e-03,\n",
       "             4.0040e-02,  1.3544e-01, -1.0817e-01, -2.6390e-01, -4.6653e-02,\n",
       "             2.6993e-01, -1.0628e-01,  3.2242e-02, -1.5623e-01,  7.0412e-02,\n",
       "             1.2106e-01, -1.5882e-01, -4.6724e-02, -1.6306e-01, -2.6295e-01,\n",
       "            -1.0101e-01,  1.0937e-01, -9.4438e-02, -6.3060e-01, -6.2390e-01,\n",
       "            -1.8033e-01, -8.2461e-02, -2.5912e-01, -2.8972e-01, -8.3195e-02,\n",
       "            -9.1642e-02,  4.1465e-01,  1.2607e-01,  3.5242e-01,  4.1727e-01,\n",
       "            -2.1204e-01, -1.1658e-02,  1.7241e-01,  4.1627e-01, -4.9783e-01,\n",
       "            -5.0829e-02,  3.8466e-01, -6.3384e-02, -4.8210e-02,  2.9267e-01,\n",
       "            -1.4817e-01,  2.2081e-02, -1.5173e-01,  4.0474e-01, -1.3203e-01,\n",
       "            -4.8286e-01,  1.9788e-01, -1.0929e-01,  6.4048e-02,  4.5125e-01,\n",
       "            -4.9123e-01,  1.8629e-01, -5.2826e-01, -6.8570e-01,  1.4811e-01,\n",
       "             8.2236e-01, -1.6783e-01, -3.1367e-01, -5.6723e-01, -1.3515e-01,\n",
       "             4.5284e-02, -5.9880e-02,  5.3359e-02,  1.9827e-01, -2.8730e-01,\n",
       "            -9.5065e-02, -1.6766e-01, -5.7486e-02,  6.4268e-02,  3.2192e-01,\n",
       "            -1.6934e-01,  4.1066e-01, -1.0170e-01,  1.5139e-01, -9.6177e-02,\n",
       "             3.6197e-01,  2.0624e-01,  1.5555e-01, -9.9715e-02,  5.4261e-01,\n",
       "             6.0753e-03, -4.4086e-02,  6.6496e-01,  4.8043e-01, -1.1548e-01,\n",
       "            -1.3870e-01, -1.4907e-01, -7.8033e-02, -7.3552e-02,  3.3214e-01,\n",
       "            -1.0381e-01,  2.0635e-01, -1.8862e-01,  1.3009e-01,  4.6730e-01,\n",
       "            -6.4883e-02, -7.6843e-01,  4.3322e-02, -4.1916e-01,  6.9201e-01,\n",
       "             1.7550e-01, -6.6466e-01, -1.9030e-01,  1.7940e-01, -2.5809e-01,\n",
       "             1.7859e-01, -3.8810e-01, -9.2771e-02, -1.3369e-01,  1.8632e-01,\n",
       "            -5.2354e-03, -1.1157e-01,  2.2167e-02,  9.6804e-02,  2.0878e-01,\n",
       "            -3.8177e-01, -5.0455e-01,  1.2939e-01,  1.4943e-01,  4.3951e-01,\n",
       "             7.9104e-02,  2.3861e-01,  3.5923e-01,  8.9436e-02,  3.4922e-01,\n",
       "             1.0154e-02, -1.5734e-01, -1.3380e-01, -1.3790e-02, -2.4204e-02,\n",
       "             2.9718e-01,  2.5774e-01, -1.4861e-01,  8.0318e-02, -6.8489e-02,\n",
       "             3.2230e-01,  7.1316e-02, -4.2791e-02,  3.5803e-01, -4.3702e-01,\n",
       "            -8.7344e-03,  3.1600e-02, -4.7439e-01, -1.6106e-01,  1.9008e-01,\n",
       "            -2.7424e-01,  2.5140e-01, -3.0266e-01,  4.2487e-02, -1.7580e-01,\n",
       "            -1.6862e-01, -3.1330e-01,  2.6720e-01, -1.1450e-01,  2.1986e-01,\n",
       "             4.6246e-01, -2.5724e-01,  1.0534e-01, -4.0552e-01, -2.4255e-01,\n",
       "            -4.8153e-04, -2.0109e-01, -3.9956e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,   510,  1385,   273, 46809,  8892,  4566,\n",
       "              598, 10793,   271,  5382,   310,  2879,   281,   253, 15154,    15,\n",
       "                0]])),\n",
       "  (tensor([[-8.0771e-02,  2.7666e-02, -6.7620e-01,  1.6321e-01,  2.0517e-01,\n",
       "            -2.6729e-01,  1.2856e-02,  2.6405e-01,  1.7891e-01,  4.4017e-01,\n",
       "             2.9847e-01,  5.4353e-01, -3.2462e-02,  1.9018e-01,  6.4705e-02,\n",
       "             1.9690e-01, -6.7924e-02,  4.8292e-01, -1.6309e-01,  1.8655e-01,\n",
       "            -4.0955e-02, -8.2191e-02, -3.5120e-01, -1.0521e-01,  1.3709e-01,\n",
       "             3.6089e-01, -1.8809e-01, -1.4678e-01,  4.7047e-02,  1.4971e-02,\n",
       "             2.6051e-01,  2.0236e-01, -1.3931e-02, -3.8147e-02, -1.3622e-01,\n",
       "            -6.5221e-02,  1.3440e-01,  1.3209e-01, -6.4813e-01,  1.4104e-01,\n",
       "             1.7695e-01, -9.0678e-02,  1.6015e-01,  9.9440e-02,  1.3137e-02,\n",
       "            -1.0742e-01,  3.8092e-01, -1.4339e-01, -1.2928e-01,  2.5022e-02,\n",
       "             2.7278e-01, -1.8666e-01, -1.9420e-01, -1.3326e-01,  5.4044e-02,\n",
       "             4.0692e-03, -1.5496e-01, -2.7083e-01,  2.4374e-01, -3.9670e-01,\n",
       "            -1.5190e-01,  2.9347e-01, -1.3236e-01,  7.3543e-02,  5.6822e-01,\n",
       "             2.7831e-01, -7.8728e-02,  6.7886e-02,  2.9361e-01, -1.9203e-01,\n",
       "             5.4169e-01, -8.3404e-02,  1.1143e-01, -5.1715e-01, -8.6568e-02,\n",
       "            -1.8240e-01, -1.1578e-01,  2.7226e-01, -1.6994e-01, -6.0416e-02,\n",
       "            -4.2804e-02,  3.0245e-01, -4.8054e-02, -4.3437e-01,  2.5648e-01,\n",
       "             1.0493e-01,  3.9060e-01,  5.6677e-02, -1.1053e-01,  3.5091e-02,\n",
       "             4.4246e-01,  2.8059e-02,  2.3351e-01, -2.1383e-01,  1.9863e-01,\n",
       "            -6.8656e-02, -3.8596e-02, -2.1352e-01,  8.3774e-02, -6.2403e-02,\n",
       "            -1.7017e-01,  1.4810e-01,  2.9144e-01, -1.0801e-01, -1.9669e-01,\n",
       "            -3.3240e-02, -1.3383e-01, -1.1225e-02,  1.5690e-01, -2.7825e-01,\n",
       "             5.1215e-03,  4.4855e-01,  1.0588e-01, -1.2666e-01, -3.6807e-01,\n",
       "             3.8067e-01,  2.5771e-02,  7.3008e-01,  2.3607e-01, -3.4582e-02,\n",
       "             3.1685e-01,  2.8347e-01,  2.9768e-01,  1.1980e-01, -1.7117e-01,\n",
       "            -1.3921e-01, -6.4866e-02, -3.0536e-02, -1.5785e-02,  8.8027e-02,\n",
       "             4.1650e-02, -2.7452e-01, -6.7660e-02,  2.8882e-02,  2.2994e-01,\n",
       "            -3.4168e-02, -1.3429e-01, -1.0264e-02,  6.9862e-02, -7.1431e-02,\n",
       "            -2.0246e-01, -3.9337e-02, -2.4295e-01,  7.7427e-02, -3.2606e-01,\n",
       "            -1.9706e-01,  9.1453e-02,  5.6174e-02,  7.9598e-02,  6.4319e-02,\n",
       "            -2.6781e-01,  1.6527e-01, -1.0658e-01, -1.5242e-02,  1.6624e-01,\n",
       "             1.1505e-01,  2.1343e-01,  1.0495e-01, -2.9682e-01,  2.0973e-01,\n",
       "            -3.7447e-01, -4.1510e-02, -7.6818e-02, -2.3861e-01,  5.0189e-02,\n",
       "             3.0369e-01,  2.9458e-01, -5.9815e-02,  3.4563e-01, -5.3741e-02,\n",
       "            -1.3339e-01,  2.2085e-01, -3.0314e-01, -9.0425e-02, -2.2773e-01,\n",
       "            -1.1247e-01, -1.1801e-01,  4.8727e-03,  8.0194e-02,  1.6446e-01,\n",
       "             1.2943e-01, -1.4037e-01,  1.6743e-02, -1.1764e-01, -1.6301e-01,\n",
       "            -4.5623e-01, -4.6418e-01,  3.8587e-01, -1.5868e-01, -9.5237e-02,\n",
       "            -2.3400e-01, -1.4673e-01, -3.4424e-01, -1.4080e-01,  1.5168e-01,\n",
       "            -3.8131e-02,  7.3924e-03,  2.8263e-01, -4.9822e-02,  2.0857e-02,\n",
       "            -5.0655e-02, -3.6187e-01,  7.5421e-02,  4.1701e-02,  5.0014e-02,\n",
       "            -3.6599e-01, -8.5753e-02,  2.2629e-02,  2.0696e-01, -9.4995e-02,\n",
       "             2.6937e-01,  1.7273e-02,  3.5359e-01, -1.4416e-01, -2.3833e-01,\n",
       "             2.3702e-03,  3.1645e-02, -5.2901e-01,  1.7910e-01,  1.4662e-01,\n",
       "            -5.2931e-02,  1.9087e-01,  1.3028e-01,  2.9329e-02, -5.4392e-02,\n",
       "             1.6296e-01, -2.2897e-01,  2.5283e-01, -2.2318e-01, -3.4330e-01,\n",
       "             3.6325e-01, -2.1931e-01, -3.5097e-02,  2.3769e-01, -1.3330e-01,\n",
       "             1.8878e-02,  2.0820e-02,  2.0660e-01, -3.6607e-01, -3.4545e-01,\n",
       "            -3.4949e-01,  3.2252e-01,  5.2195e-01, -3.8825e-02, -4.1285e-02,\n",
       "            -2.7859e-01,  3.6901e-01, -3.5015e-01,  8.5357e-02,  3.9057e-01,\n",
       "             8.5427e-03, -2.1419e-01,  2.7619e-02,  1.2024e-01, -1.9654e-01,\n",
       "            -2.5403e-01,  2.5621e-01, -2.4775e-01,  7.6538e-02,  1.8929e-01,\n",
       "             1.5283e-03,  2.8970e-01,  2.8669e-01,  1.9157e-01,  4.6720e-01,\n",
       "             1.3277e-01,  1.2792e-01,  2.0155e-01,  7.4261e-02,  6.3219e-02,\n",
       "             7.2462e-02, -2.0271e-01, -8.8248e-02, -3.1639e-01, -7.2826e-02,\n",
       "            -1.0460e-01, -5.1719e-03,  8.1149e-04, -5.4363e-02,  4.1684e-02,\n",
       "            -3.3003e-01, -2.7682e-01, -2.0359e-01, -2.4463e-01, -6.7340e-02,\n",
       "             1.5943e-02,  1.6827e-01,  2.4449e-01,  1.0138e-01,  1.4622e-01,\n",
       "            -1.6645e-01, -3.5862e-01,  1.4361e-01, -1.0938e-01,  4.6196e-01,\n",
       "             4.5646e-02,  3.7314e-01, -8.7448e-02,  2.6556e-02, -3.3248e-01,\n",
       "             3.8513e-02, -3.9674e-01,  7.2776e-02,  7.2309e-02,  3.5033e-02,\n",
       "            -1.3831e-01,  7.9481e-01, -6.6721e-02,  7.2720e-02,  4.4843e-01,\n",
       "             8.1865e-02, -6.6237e-02, -9.2193e-02,  3.0815e-02,  5.2805e-03,\n",
       "             2.1061e-02, -1.2591e-02, -6.9552e-02, -2.8371e-01, -3.8302e-02,\n",
       "            -1.5597e-01,  2.1568e-01,  1.5150e-02,  3.0486e-02, -1.6660e-01,\n",
       "            -4.0443e-01,  8.5209e-02,  1.6781e-01, -3.1073e-01,  3.3827e-01,\n",
       "            -2.1106e-02, -2.6534e-02,  1.3818e-01, -2.0587e-01, -2.5500e-02,\n",
       "             4.0252e-01,  1.4184e-01, -5.5097e-02,  6.6800e-02,  1.1200e-02,\n",
       "             3.6333e-01,  1.2120e-01,  3.1992e-01, -6.2939e-02,  2.5322e-02,\n",
       "            -2.8053e-02,  7.2605e-02, -1.0203e-01,  6.4410e-02, -1.6024e-02,\n",
       "            -5.5694e-03, -1.7786e-01, -7.6294e-02,  6.7910e-02,  3.1588e-01,\n",
       "            -8.7034e-02, -2.4738e-02, -1.4410e-01,  4.5469e-03,  2.0932e-01,\n",
       "             2.3139e-01, -2.8496e-01,  2.2281e-02,  1.1399e-01,  1.0563e-01,\n",
       "            -1.4930e-01, -5.7729e-01, -1.6534e-01,  1.6195e-01, -8.5346e-02,\n",
       "            -3.4489e-01, -1.6490e-02,  5.8844e-01,  2.3383e-01,  5.3661e-01,\n",
       "             2.4579e-01,  6.4330e-01, -9.0529e-02,  2.0632e-01,  2.2509e-01,\n",
       "            -2.7512e-01, -3.9986e-01, -1.7347e-01, -3.7463e-01, -4.3786e-02,\n",
       "             2.8025e-01,  5.2629e-01, -4.2367e-01, -6.3432e-02,  2.3181e-01,\n",
       "            -6.9678e-02,  1.9376e-01, -2.9366e-01,  1.4255e-01,  1.1266e-01,\n",
       "            -6.4415e-02,  7.4231e-02, -2.9335e-01,  4.3163e-01,  2.8365e-01,\n",
       "             3.1304e-01,  3.5645e-01, -3.4050e-02,  2.8512e-03,  3.8269e-01,\n",
       "            -4.8587e-01,  3.5653e-01, -5.5496e-02, -8.5778e-01, -2.6564e-01,\n",
       "             2.0307e-01,  3.6606e-01,  2.8439e-01, -3.5281e-01, -3.7907e-01,\n",
       "             1.9912e-01,  1.0609e-01, -2.6005e-01, -4.0787e-02,  3.5560e-02,\n",
       "            -2.8210e-01, -3.9410e-02,  5.3201e-02,  8.6800e-01,  2.1725e-01,\n",
       "             1.4374e-01, -1.5338e-01,  2.8746e-01, -6.2764e-02, -3.8382e-01,\n",
       "            -8.8148e-02,  1.7606e-01, -2.2762e-01,  2.2857e-01,  2.6745e-01,\n",
       "             9.1522e-02,  1.5651e-01, -1.7645e-01, -3.6415e-02,  2.8604e-02,\n",
       "            -1.8341e-01, -1.7904e-01, -7.7594e-02,  1.4531e-02, -2.9300e-03,\n",
       "            -3.6851e-01, -2.4546e-01,  1.2554e-01,  5.1827e-02, -7.9086e-01,\n",
       "            -2.3817e-01,  2.1262e-01, -9.4066e-02, -6.4515e-01,  1.1767e-02,\n",
       "            -1.8762e-01, -1.1894e-01, -5.0386e-02, -1.0751e-01, -8.9244e-02,\n",
       "             1.8789e-01,  6.8919e-02,  3.2289e-01, -5.4278e-02,  1.9237e-02,\n",
       "            -2.1730e-01, -1.8214e-01,  3.2027e-01, -4.4863e-01, -2.8274e-01,\n",
       "            -7.2245e-02,  6.5536e-03, -7.3183e-01, -2.8431e-01, -5.6054e-01,\n",
       "             3.9387e-01, -5.0139e-02, -8.6961e-01,  2.3394e-01, -1.9188e-01,\n",
       "            -4.1709e-02,  5.5444e-01,  1.9987e-01,  4.9128e-01,  7.2378e-02,\n",
       "            -1.2134e-01, -5.2279e-02,  3.9052e-01,  4.9053e-01, -6.5254e-01,\n",
       "             7.6826e-02, -2.9868e-01, -9.2166e-02,  1.3208e-01,  7.0185e-02,\n",
       "             9.6248e-02,  9.2086e-02,  5.9954e-01, -3.8636e-02, -3.2858e-01,\n",
       "            -1.4773e-02,  1.0828e-03, -1.8845e-01,  3.2515e-01,  1.9006e-01,\n",
       "             6.7206e-01, -3.2233e-02,  3.7736e-01, -5.1118e-02,  1.0919e-01,\n",
       "            -8.1853e-02, -1.4393e-01, -1.6881e-01,  7.4735e-02,  5.5909e-01,\n",
       "            -2.8734e-01, -2.0957e-01, -1.1062e-01, -5.4120e-02,  5.8603e-02,\n",
       "             1.1294e-01, -6.6897e-01,  1.0307e-01,  2.1843e-01, -2.3153e-01,\n",
       "            -4.1757e-01,  1.0177e-01, -6.5040e-01, -5.6519e-02,  2.9868e-01,\n",
       "            -4.9716e-02, -1.9116e-01, -3.2072e-02,  5.1230e-01, -5.7849e-01,\n",
       "            -5.9219e-02, -1.2221e-01,  3.8588e-01,  3.1436e-02, -1.5013e-01,\n",
       "            -5.4789e-02, -3.4187e-01,  5.8667e-01,  1.9173e-01,  1.6737e-01,\n",
       "             8.1905e-02,  5.4228e-02, -4.0107e-01,  2.2314e-01,  2.6718e-01,\n",
       "            -2.1742e-01,  2.8328e-02,  1.3630e-01, -1.2795e-01, -3.3826e-01,\n",
       "            -9.6935e-02,  2.3403e-01,  4.1918e-01, -2.5498e-02, -2.2821e-01,\n",
       "            -1.8558e-01,  2.9920e-01, -3.1479e-01, -6.6018e-01, -5.5290e-01,\n",
       "             7.6202e-02,  3.3781e-01,  1.8015e-01, -7.6653e-02,  2.3681e-01,\n",
       "             1.5258e-01,  3.0957e-01, -1.8612e-03, -1.5346e-01, -9.9070e-02,\n",
       "            -1.3900e-01, -4.3134e-01, -3.8248e-02,  2.0663e-01, -1.0528e-01,\n",
       "            -2.2252e-01, -2.8254e-01,  5.0540e-01,  7.9328e-02, -1.3692e-01,\n",
       "            -1.6552e-01, -2.3408e-01, -1.5769e-02, -4.7048e-02, -1.4643e-01,\n",
       "             5.1878e-02, -1.8415e-01,  2.7322e-01,  1.5905e-01, -7.1325e-03,\n",
       "             2.4465e-01, -1.1766e-01, -4.7802e-01,  2.6651e-01, -1.7822e-01,\n",
       "             5.6917e-02, -6.9203e-02,  4.0912e-01,  1.9220e-01, -1.8202e-01,\n",
       "             2.7206e-02,  4.9121e-02, -2.6542e-01, -2.8357e-01, -1.8906e-01,\n",
       "             1.9547e-01, -4.7323e-01, -3.4127e-01, -1.1729e-01, -7.3517e-02,\n",
       "             5.6621e-01,  3.2301e-01, -3.1149e-01, -9.5948e-03, -5.4176e-01,\n",
       "             1.0107e-01,  1.7872e-01,  4.3782e-02, -9.6126e-02, -2.4829e-01,\n",
       "            -2.1191e-01, -1.7568e-01, -6.4026e-02,  2.6208e-01, -1.6221e-01,\n",
       "            -9.8747e-02,  3.5574e-01, -2.8509e-01,  1.5123e-01,  5.2392e-01,\n",
       "             1.4813e-01, -5.2448e-03,  8.2352e-02, -6.4958e-01, -3.5639e-01,\n",
       "             2.3687e-02, -1.5613e-01, -3.5065e-01, -2.1348e-01, -2.3774e-01,\n",
       "            -1.0533e-01, -1.6835e-01,  3.5988e-02, -5.7855e-01,  1.0621e-02,\n",
       "            -2.2559e-01,  1.2034e-01, -1.8028e-02,  1.9769e-01,  8.5752e-01,\n",
       "            -9.3840e-02, -4.7264e-01,  3.1418e-03, -6.4230e-01,  6.9368e-01,\n",
       "            -1.7788e-01,  2.5195e-01, -2.7194e-01, -3.0187e-01, -5.6512e-02,\n",
       "            -2.3676e-06,  2.2425e-01, -7.4579e-01, -8.0302e-02,  2.0810e-01,\n",
       "            -1.1969e-01,  3.6684e-02, -1.9966e-01,  1.8672e-01,  9.0138e-02,\n",
       "             3.3146e-01,  3.6601e-01, -5.7972e-01,  8.5239e-02, -5.8221e-01,\n",
       "             4.1210e-01, -4.6547e-02,  2.0144e-01, -1.7798e-01,  1.6034e-01,\n",
       "            -5.9728e-02, -1.2695e-01, -1.0211e-01,  6.6560e-01, -1.0838e-01,\n",
       "            -2.9036e-01, -5.3611e-01,  2.0324e-01, -9.3674e-02, -3.8595e-02,\n",
       "            -1.7275e-01, -4.6357e-01,  5.1244e-01,  3.8288e-01,  2.0293e-01,\n",
       "             8.7032e-02, -7.2136e-02,  2.6319e-01, -2.4148e-01,  3.2102e-01,\n",
       "             1.5977e-01, -3.4491e-02, -1.7419e-01, -7.9231e-02, -4.6816e-01,\n",
       "             1.6681e-01,  3.4111e-02, -2.6593e-01, -2.8065e-01, -6.0141e-02,\n",
       "            -2.7772e-01, -3.7049e-01, -3.5956e-01,  9.3286e-02, -1.2139e-01,\n",
       "            -1.6641e-01, -5.8890e-01,  4.2039e-01, -4.4904e-01,  1.1995e-01,\n",
       "            -1.1611e-01,  2.5687e-01, -1.0982e-01,  1.0466e-01,  3.4870e-01,\n",
       "            -1.5901e-01,  9.1922e-02, -6.3602e-02, -1.3185e-01,  1.2558e-01,\n",
       "            -5.6236e-02,  2.4515e-01, -3.6719e-01, -3.6840e-03, -1.7474e-01,\n",
       "            -2.5425e-02, -1.6108e-01, -2.8163e-01, -6.7002e-03, -4.8965e-01,\n",
       "             1.0946e-01,  1.0414e-01, -1.0559e-01, -3.3156e-01,  2.0424e-01,\n",
       "             3.4189e-03, -1.6985e-01, -4.2719e-01,  1.8507e-01, -2.5865e-01,\n",
       "            -3.3173e-01, -3.7687e-02,  3.7348e-01, -3.1588e-01,  3.8990e-01,\n",
       "             2.7503e-01, -1.6502e-01,  3.7776e-01, -5.5018e-01, -2.5798e-01,\n",
       "             3.8242e-02,  9.1011e-02, -2.0072e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,    42,   452,  1071,  5447,   273,  7177,\n",
       "              342,  3388,  3389,  1979,   310, 35453,  2945,   378, 12742,   760,\n",
       "               15,     0]])),\n",
       "  (tensor([[-1.1876e-01,  9.8550e-02, -5.5522e-01, -8.9686e-02,  1.3146e-01,\n",
       "            -4.1783e-01, -2.2195e-01,  2.1838e-01, -1.3406e-03,  5.9366e-01,\n",
       "             4.1343e-01,  2.8070e-01, -9.9110e-02, -5.3019e-02, -2.7489e-01,\n",
       "             2.6114e-01,  1.7224e-01,  4.4410e-01, -2.8776e-01, -2.0017e-01,\n",
       "            -1.6467e-01,  4.7301e-02, -1.8678e-01,  5.0010e-03, -7.7681e-02,\n",
       "            -4.4063e-02, -8.0276e-02, -1.1673e-01,  1.8301e-01,  8.2298e-03,\n",
       "             2.4511e-01,  5.8113e-02,  5.3612e-02,  9.2769e-03, -5.9180e-01,\n",
       "            -7.5504e-02,  1.8323e-01, -2.0837e-01, -7.4841e-01,  2.5105e-01,\n",
       "             5.3106e-02, -4.4953e-01,  2.9622e-01,  1.4674e-01, -1.4969e-01,\n",
       "             2.2538e-01,  4.1699e-01, -7.8790e-02, -2.1861e-03,  4.0892e-01,\n",
       "            -1.5120e-01,  4.2799e-02, -1.0409e-01, -1.1785e-01, -3.3640e-02,\n",
       "             3.3740e-01, -2.8613e-01, -3.2164e-01,  1.6970e-01, -3.1081e-01,\n",
       "            -9.3975e-02,  4.1596e-02, -1.3012e-01, -2.6554e-02,  3.4627e-01,\n",
       "             6.5920e-01,  4.0478e-01,  1.2884e-01,  3.7586e-02, -2.0748e-01,\n",
       "             4.2635e-02,  1.6354e-03, -3.5846e-01, -3.8017e-01,  7.0004e-02,\n",
       "             8.1151e-02, -8.3528e-02,  3.5520e-01, -7.5799e-02, -2.4101e-01,\n",
       "            -1.2681e-01,  7.7264e-02,  2.3248e-02, -2.6817e-01,  2.5526e-01,\n",
       "            -1.2497e-01,  6.1702e-02, -3.7050e-02, -1.2312e-01,  4.6005e-02,\n",
       "             1.5258e-01, -9.2830e-02,  2.7187e-01, -1.9361e-01,  8.6027e-02,\n",
       "            -1.5112e-01, -1.8724e-01, -2.3397e-02,  1.8605e-01, -1.7847e-01,\n",
       "             1.3926e-02,  1.6052e-01,  4.7834e-01, -1.7669e-01, -6.2204e-01,\n",
       "             9.2668e-02, -2.4766e-02, -3.1266e-01, -1.4736e-01, -2.3155e-01,\n",
       "             3.2169e-01,  3.6571e-01, -5.1177e-02, -1.5668e-01, -3.5544e-01,\n",
       "             1.5421e-01, -6.5995e-02,  5.0083e-01, -9.9797e-02, -4.3442e-01,\n",
       "             2.4184e-01,  1.5493e-02,  2.0807e-01,  6.0851e-02,  4.9896e-02,\n",
       "             1.5632e-01, -5.3128e-02, -9.1422e-02,  1.8499e-01,  9.5164e-02,\n",
       "            -2.4528e-01, -3.1641e-01, -8.2803e-02, -1.3035e-01,  3.3162e-01,\n",
       "             2.2728e-01,  1.4653e-01, -7.5109e-02,  1.8525e-01, -1.4649e-01,\n",
       "            -1.0187e-01, -3.8110e-02, -3.6413e-01,  9.3574e-02, -3.4924e-01,\n",
       "            -1.8187e-01,  4.7263e-01,  1.2861e-01, -1.3463e-01,  3.3039e-03,\n",
       "            -5.4071e-01, -1.5408e-01, -2.4008e-01, -5.2783e-02, -1.3052e-01,\n",
       "            -8.6079e-02,  5.7606e-02,  1.7069e-01, -5.2997e-01,  1.3771e-01,\n",
       "            -4.2030e-01, -7.8000e-02,  8.8058e-02, -1.0720e-01,  1.4480e-01,\n",
       "             1.8952e-01, -5.0339e-02, -1.2087e-01,  9.9623e-02,  4.4754e-02,\n",
       "            -4.9784e-02,  2.7771e-01, -1.0331e-01,  1.6423e-02,  1.4857e-01,\n",
       "             5.6086e-02, -1.7846e-01,  5.4263e-02,  1.2961e-01,  1.6083e-01,\n",
       "             9.5821e-02, -6.3753e-02, -6.1717e-02,  8.6507e-02, -4.5610e-01,\n",
       "            -2.5265e-01, -3.3428e-01,  5.9791e-01, -3.7096e-01,  1.8349e-01,\n",
       "            -3.1337e-01, -2.6474e-01, -2.0241e-01, -3.2765e-01, -3.7573e-02,\n",
       "             3.8150e-02, -1.9381e-01,  2.6831e-01, -6.7329e-02,  1.1075e-01,\n",
       "             2.1524e-01, -2.4859e-01,  2.2169e-01,  9.3854e-02, -3.3504e-02,\n",
       "            -4.6000e-01, -1.3053e-01,  2.8161e-02,  2.2597e-01,  2.2952e-01,\n",
       "             1.5489e-01, -2.9356e-02,  1.6934e-01, -2.7777e-01,  6.5987e-02,\n",
       "             2.0997e-01,  2.2414e-01, -3.1193e-01,  4.1314e-02, -4.3639e-02,\n",
       "            -6.9865e-02,  6.6562e-02,  9.2476e-02, -2.4734e-02,  7.5206e-02,\n",
       "             4.0888e-03, -9.9990e-02,  6.8643e-01, -1.4253e-01, -3.7953e-01,\n",
       "             1.9131e-01,  3.1907e-02, -2.8415e-01,  4.0229e-01,  2.4122e-01,\n",
       "            -1.1496e-01, -1.3255e-02,  2.5004e-01, -3.3134e-02, -1.6085e-01,\n",
       "            -4.9325e-01,  1.7410e-01,  5.9164e-01, -8.4028e-02,  1.8771e-01,\n",
       "            -3.8620e-01,  2.4099e-01, -4.6851e-01, -2.5941e-01,  2.7859e-01,\n",
       "             2.7782e-01, -3.7582e-02, -7.5530e-02,  4.9432e-01,  4.5052e-02,\n",
       "            -2.0394e-01,  1.1013e-01, -3.6985e-02,  2.0230e-01,  1.5118e-01,\n",
       "            -5.2890e-02, -5.4747e-02,  4.4788e-01,  1.1650e-01,  3.5383e-01,\n",
       "             3.0032e-02,  2.7108e-01, -2.7786e-02, -1.0085e-02, -1.6199e-01,\n",
       "             3.4174e-01, -3.4837e-01,  1.0493e-02, -2.5707e-01, -5.1448e-01,\n",
       "            -2.2051e-01, -1.1290e-01, -4.8744e-02, -6.4638e-02,  1.6756e-01,\n",
       "            -1.1691e-01, -4.6347e-02, -1.3436e-01,  1.8271e-03,  6.8214e-02,\n",
       "            -1.8212e-01,  9.1357e-02,  4.3176e-01,  1.0275e-01,  1.1482e-01,\n",
       "            -1.2681e-01, -2.5504e-01, -6.6703e-02, -1.4149e-01,  3.9541e-01,\n",
       "             1.2736e-01, -7.1697e-02, -2.1730e-01,  2.2790e-03, -3.2438e-01,\n",
       "            -1.1055e-01, -5.5612e-03, -1.5902e-01,  4.5078e-01, -4.3916e-02,\n",
       "            -1.5239e-01,  2.8828e-01,  1.1344e-01,  8.2889e-03,  5.3454e-01,\n",
       "            -4.4230e-02, -1.6976e-01,  1.4995e-01,  3.8992e-02,  5.4039e-02,\n",
       "             1.8086e-01,  4.9865e-02, -1.8292e-02, -3.0016e-01,  7.6421e-02,\n",
       "             3.4571e-01,  3.2203e-01, -1.4769e-01,  5.7210e-02,  1.4430e-03,\n",
       "            -2.7885e-01,  2.5627e-02,  2.0593e-01,  3.1974e-01,  2.6509e-01,\n",
       "            -1.7751e-01, -1.8079e-01,  2.1860e-01, -2.6279e-01, -2.2888e-01,\n",
       "             1.5222e-01,  1.3857e-01, -5.9376e-02,  2.5659e-01, -1.3215e-01,\n",
       "             1.7958e-01,  1.4234e-02,  3.8183e-01, -1.4402e-01,  1.6861e-01,\n",
       "             2.1770e-01,  1.5664e-01, -3.7854e-02,  2.2734e-01,  1.8478e-01,\n",
       "            -2.3046e-01, -2.1431e-01, -1.0007e-01, -1.9351e-03,  1.8513e-01,\n",
       "            -4.6715e-01,  1.0016e-01,  8.3066e-03,  1.2947e-01, -6.4718e-02,\n",
       "             2.3912e-01,  1.9962e-01,  1.0907e-01,  1.3327e-01,  7.9812e-02,\n",
       "            -2.5541e-01, -4.5782e-01, -2.6850e-01,  1.9310e-01,  7.7705e-02,\n",
       "            -6.0798e-02,  1.7280e-01,  5.5050e-01,  2.2004e-01,  5.4065e-01,\n",
       "            -3.5908e-02,  3.1067e-01, -1.9714e-01, -2.6521e-01,  2.9331e-01,\n",
       "            -1.4916e-01, -3.5294e-01, -6.9461e-02, -3.0047e-01, -1.2843e-01,\n",
       "             9.1127e-01,  3.3910e-01, -3.1965e-01,  3.6851e-01,  3.3840e-01,\n",
       "             1.2937e-01, -3.9954e-01,  2.9079e-01,  1.0258e-01,  2.0975e-01,\n",
       "            -2.8814e-02, -2.6339e-02,  5.1047e-02,  5.0131e-01,  4.2696e-01,\n",
       "             2.4666e-01,  3.5634e-01, -3.1978e-01,  1.8941e-01,  1.7372e-01,\n",
       "            -5.7910e-01,  1.5439e-01, -2.5383e-01, -5.0934e-01,  1.7746e-01,\n",
       "             3.2522e-01,  4.8843e-01,  4.3695e-01, -2.2116e-01, -2.5011e-01,\n",
       "            -4.7265e-01,  9.0830e-02,  1.8572e-01,  6.0489e-02,  4.2752e-01,\n",
       "            -3.2348e-01, -5.1038e-02,  1.2519e-01,  6.3992e-01,  2.4508e-02,\n",
       "             2.0856e-01, -3.2327e-01,  4.3626e-01, -1.1674e-01, -1.7848e-01,\n",
       "             1.1252e-01,  4.6816e-02,  2.3640e-01,  7.9086e-02,  4.1151e-01,\n",
       "             2.9692e-01,  1.1452e-01, -1.3081e-01, -1.8704e-01, -3.6581e-01,\n",
       "             1.1485e-02,  9.6473e-03, -2.3724e-01,  1.2660e-01,  7.6313e-02,\n",
       "             8.2555e-02, -9.2698e-04,  2.1305e-01,  7.0999e-02, -5.3799e-01,\n",
       "            -5.9157e-01, -2.8264e-01,  2.3089e-01, -2.5889e-01, -4.0769e-03,\n",
       "             2.8705e-01, -1.0574e-01, -2.9203e-01,  2.8293e-02, -6.9706e-02,\n",
       "            -5.7844e-03, -8.1314e-02,  2.7023e-01, -1.2580e-03,  2.2934e-02,\n",
       "            -2.5303e-01, -4.4816e-01,  3.2835e-01, -2.5055e-01, -3.1371e-01,\n",
       "            -2.6400e-01, -1.5347e-01, -7.1104e-01, -5.3283e-01, -3.1766e-01,\n",
       "            -1.2110e-01,  8.2179e-02, -2.0333e-01,  2.6027e-01, -3.4380e-01,\n",
       "             4.4254e-02,  5.5245e-01,  5.3771e-02,  1.4817e-01,  2.1201e-01,\n",
       "            -8.9796e-02, -1.8230e-01,  3.6800e-01,  5.0418e-01, -2.5938e-01,\n",
       "             1.5198e-01, -1.3987e-01, -3.0790e-01,  7.5425e-02, -2.4223e-01,\n",
       "             1.4711e-01,  1.9971e-01,  2.8205e-01, -1.4470e-01, -1.5812e-01,\n",
       "             4.0659e-01, -3.1620e-01, -3.2173e-01,  1.7143e-01,  6.9955e-01,\n",
       "             6.0433e-01, -4.1555e-02, -9.8026e-02, -2.2340e-02,  5.0761e-02,\n",
       "             1.5093e-01,  6.6405e-02,  1.2020e-01,  2.1618e-01,  4.0354e-01,\n",
       "            -6.5632e-01, -1.2805e-01,  1.0949e-01, -9.3540e-02,  3.2506e-01,\n",
       "             4.6278e-02, -6.6948e-01, -1.4650e-01,  1.2200e-02,  1.8903e-01,\n",
       "             9.0634e-03,  1.7497e-01, -2.8709e-01,  8.9363e-02,  1.6969e-01,\n",
       "             2.0263e-01, -1.4590e-01,  1.5771e-01, -9.7416e-02, -4.6288e-01,\n",
       "            -3.8639e-01, -3.2790e-01,  2.1866e-01,  2.6250e-02, -9.5434e-03,\n",
       "            -1.5017e-01, -3.3878e-01,  3.2360e-01,  7.8224e-02, -8.9464e-02,\n",
       "             2.0023e-01,  1.6998e-01, -4.1608e-01,  3.5667e-01,  3.0871e-01,\n",
       "            -4.0959e-01, -7.4460e-03, -7.9854e-02, -2.3625e-02,  7.0496e-02,\n",
       "            -2.9849e-01,  4.5390e-01,  7.4289e-02, -4.4196e-02, -7.4207e-02,\n",
       "            -3.6425e-01,  2.8632e-01, -1.2415e-01, -1.1278e-01, -6.8422e-01,\n",
       "             5.2244e-02,  1.1516e-01,  2.0937e-01,  8.9238e-02,  8.0461e-02,\n",
       "             3.5046e-01,  5.7993e-02,  2.8388e-01, -9.7097e-02,  1.7055e-02,\n",
       "            -9.8271e-02, -3.9396e-01,  6.7085e-02, -4.9018e-02, -2.1691e-01,\n",
       "            -2.8140e-01, -2.4291e-01,  4.5385e-01, -2.4738e-01, -2.9837e-01,\n",
       "            -1.3385e-01,  1.4017e-02, -3.9841e-01,  1.1136e-01, -2.3013e-01,\n",
       "             3.2402e-01, -1.2999e-01,  3.3349e-01, -1.9618e-01, -5.7857e-02,\n",
       "            -1.4431e-01, -1.4268e-01, -1.2197e-01, -1.6434e-02,  3.2593e-01,\n",
       "             2.7278e-01, -1.1743e-01, -5.1237e-02,  9.7341e-02, -2.8496e-01,\n",
       "             1.7968e-01, -1.7217e-03, -1.5649e-01, -1.7176e-01, -8.7734e-02,\n",
       "             3.4416e-01, -2.2891e-01, -5.6133e-01, -1.9535e-01,  1.7417e-01,\n",
       "             4.9282e-01,  1.9723e-01,  2.4064e-01, -5.1345e-02, -4.6029e-01,\n",
       "             7.5121e-02,  4.4262e-02, -3.2922e-01,  4.2654e-02,  3.1971e-02,\n",
       "            -2.0911e-01, -1.4240e-01,  2.2610e-01,  2.4302e-01, -2.9469e-01,\n",
       "            -1.2300e-01,  1.1745e-01, -2.6376e-01,  2.0224e-01,  2.0392e-01,\n",
       "            -8.4375e-02, -8.4073e-02,  2.3262e-01, -4.7191e-01, -2.4740e-01,\n",
       "             1.5750e-01,  1.7675e-01, -2.7933e-01, -4.6388e-01, -2.7474e-01,\n",
       "            -5.5883e-02, -3.3559e-01,  1.2537e-01, -2.9191e-01,  9.9080e-02,\n",
       "             2.2579e-02, -4.5185e-03, -1.5969e-01,  4.1842e-02,  9.9095e-01,\n",
       "             8.6329e-02, -3.9154e-01,  6.5809e-02, -4.6423e-01,  3.8840e-01,\n",
       "            -1.2278e-01, -3.2527e-02,  1.7327e-01, -1.1572e-01,  2.1285e-01,\n",
       "            -3.1020e-01,  7.6518e-02, -3.9857e-01, -1.1607e-01,  3.8056e-02,\n",
       "            -7.6459e-02,  3.8424e-01, -9.1212e-02,  2.2198e-01, -2.6190e-02,\n",
       "            -8.0291e-02,  1.6066e-01, -6.1858e-01,  1.5117e-01, -3.6258e-01,\n",
       "             2.1339e-01, -2.7319e-01,  4.4835e-01, -2.3326e-02,  5.3493e-01,\n",
       "            -3.1429e-02, -8.2456e-02,  1.5940e-01,  1.1586e-01,  6.8044e-02,\n",
       "            -2.9678e-01, -1.6635e-01,  1.0162e-01, -3.2811e-01,  4.0628e-01,\n",
       "            -1.0482e-01, -6.0803e-01,  3.0108e-01,  7.2788e-02, -5.1980e-02,\n",
       "            -2.9380e-01, -2.2275e-01,  1.0081e-01, -5.8706e-03,  4.3156e-01,\n",
       "            -1.0564e-02, -5.7578e-01,  1.1984e-01, -2.2890e-01, -3.7212e-01,\n",
       "            -5.3860e-03, -4.4002e-02, -4.3373e-02, -2.3641e-01,  1.2758e-01,\n",
       "             2.2673e-01, -3.7115e-01, -6.7125e-01, -1.3639e-01,  7.6917e-02,\n",
       "            -2.6394e-01, -6.4321e-01,  2.1986e-01, -3.2573e-01, -1.1420e-01,\n",
       "            -1.1822e-01,  5.2014e-01, -4.2124e-01,  4.1071e-02,  5.7748e-01,\n",
       "            -3.0468e-01, -2.7067e-01,  1.0328e-02, -4.8146e-02, -5.9819e-02,\n",
       "            -3.3156e-01,  1.8069e-01, -4.5427e-01,  4.4740e-02,  3.9918e-02,\n",
       "            -2.2628e-01, -4.5368e-02, -4.4369e-03, -9.1853e-02, -1.7186e-02,\n",
       "             1.5445e-01, -5.4524e-02, -1.3928e-01, -5.8042e-01,  5.6063e-01,\n",
       "            -2.7383e-01, -1.6388e-01, -1.5192e-01,  1.8837e-02, -3.0914e-01,\n",
       "            -3.1771e-01,  1.2032e-01,  2.9162e-02, -7.4388e-02,  5.3431e-01,\n",
       "             6.2305e-01, -1.1260e-01, -1.2668e-01, -4.8143e-01, -7.7079e-02,\n",
       "            -1.6499e-01, -6.3885e-02, -5.3925e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,   688,  8624,    13,   760,  1355,  2217,\n",
       "             7177,   403,  7141,    15,     0]])),\n",
       "  (tensor([[ 1.1697e-01, -1.2536e-01, -4.6570e-01, -5.6803e-02,  9.4541e-02,\n",
       "            -2.1514e-01, -9.7020e-02,  2.1997e-01, -1.0985e-01,  5.2980e-01,\n",
       "             2.4692e-01,  4.4597e-01,  5.5142e-02, -8.3841e-02,  2.5317e-02,\n",
       "             1.8564e-01,  6.8003e-02,  3.8180e-01, -1.7671e-01, -1.3152e-01,\n",
       "             3.2032e-02, -1.1654e-01, -5.9623e-01,  1.7427e-02,  5.2463e-02,\n",
       "            -3.1544e-02, -6.9016e-02,  2.6166e-02,  2.2697e-01, -1.4407e-01,\n",
       "             8.5510e-02,  2.3869e-01,  2.5480e-01, -6.0698e-02, -2.2951e-01,\n",
       "            -9.1547e-02,  5.5933e-02, -4.2967e-01, -8.0664e-01,  1.4429e-01,\n",
       "             4.7419e-02, -4.5061e-01,  3.8128e-01,  1.6574e-01,  8.0282e-02,\n",
       "             3.3182e-02,  2.3395e-01, -2.5684e-02,  7.4069e-02,  1.6002e-01,\n",
       "            -1.1424e-01,  3.6660e-01, -6.8462e-02,  1.2369e-01, -1.3224e-01,\n",
       "             2.0346e-01, -1.2204e-01, -3.1307e-01,  5.7330e-02, -1.7221e-01,\n",
       "            -1.0161e-01,  2.0213e-01, -6.6081e-02, -2.7056e-01,  2.2570e-01,\n",
       "             5.0959e-01,  3.6100e-01,  1.3831e-01,  6.9571e-02, -3.0249e-01,\n",
       "             2.5959e-01,  6.9768e-02, -7.7808e-02, -4.5777e-01,  1.3502e-01,\n",
       "            -5.7734e-03, -7.9664e-02,  2.3943e-01, -1.5200e-01, -1.0484e-01,\n",
       "            -1.5234e-01,  5.2357e-02, -2.3254e-01, -1.6629e-01,  7.2605e-02,\n",
       "            -1.0766e-01,  9.7118e-02,  5.1361e-03,  8.7275e-03,  7.1368e-02,\n",
       "             3.7688e-01, -2.3217e-01,  2.5738e-02, -1.2183e-01,  2.5042e-01,\n",
       "            -8.9715e-02,  1.8549e-01, -1.2171e-01,  3.2202e-01, -1.9351e-01,\n",
       "            -1.0684e-01, -2.5661e-01,  1.4502e-01, -2.1977e-01, -3.6872e-01,\n",
       "            -3.0186e-02, -1.5477e-01, -1.5005e-01, -2.4147e-01, -1.6094e-01,\n",
       "             2.2250e-01,  3.7041e-01, -2.3396e-01,  6.5577e-03, -4.2166e-01,\n",
       "             8.0781e-03,  3.6959e-02,  5.7686e-01,  6.0923e-02, -2.9327e-01,\n",
       "             3.6726e-01,  1.1797e-01,  2.2757e-01,  2.1650e-01,  4.4507e-02,\n",
       "             9.4237e-02, -2.0480e-01, -1.5258e-01,  6.1085e-02, -6.2640e-02,\n",
       "            -2.6154e-03, -3.8581e-01, -7.9567e-02, -2.1279e-01,  2.9235e-01,\n",
       "             4.1670e-01,  1.2738e-01, -2.3455e-01, -5.5292e-02, -1.4816e-01,\n",
       "             2.9037e-02,  1.1269e-01, -1.7754e-01,  3.0333e-01, -3.8355e-01,\n",
       "            -2.8808e-01,  3.6373e-01,  4.3416e-02, -2.6778e-01,  2.4100e-01,\n",
       "            -3.5417e-01, -1.3744e-01, -9.1685e-02, -8.3797e-02, -4.9649e-02,\n",
       "             1.0469e-01, -8.1869e-02,  5.2851e-01, -4.0468e-01,  6.0739e-02,\n",
       "            -3.9877e-01,  2.3188e-01,  1.0971e-01,  7.3401e-02,  8.9725e-02,\n",
       "             3.1874e-01,  3.1767e-01,  7.4955e-02,  2.6954e-01,  1.1341e-01,\n",
       "            -1.0056e-01,  3.7103e-01, -3.9240e-01,  1.0586e-01,  1.9781e-01,\n",
       "            -1.2067e-01,  1.3015e-01,  4.0098e-02,  1.3356e-02,  2.8250e-01,\n",
       "            -1.6003e-02, -1.4132e-02, -5.4787e-02, -6.5749e-02, -2.4714e-01,\n",
       "            -2.5234e-01, -2.9940e-01,  5.2263e-01, -2.5273e-01,  1.7943e-01,\n",
       "            -2.7011e-01, -1.2125e-01, -2.6974e-01, -2.6518e-01,  1.7473e-03,\n",
       "             1.8879e-01, -1.0937e-02,  1.5809e-01,  8.0459e-03,  8.1576e-02,\n",
       "             1.6378e-01, -4.7483e-01,  1.6328e-01, -1.2256e-01,  6.6832e-02,\n",
       "            -1.8346e-01, -9.1543e-02,  1.4517e-01,  3.6474e-01, -3.9279e-02,\n",
       "             2.7654e-01, -1.3682e-01,  2.2078e-01, -1.9402e-01,  2.3546e-01,\n",
       "            -2.4551e-02,  1.8812e-01, -4.6458e-01,  8.1624e-02,  1.5433e-01,\n",
       "            -1.2633e-01,  4.2702e-02, -6.0154e-02,  9.3716e-03,  5.3179e-02,\n",
       "             6.8021e-02, -2.5540e-02,  6.6868e-01, -1.6159e-01, -4.4637e-01,\n",
       "             2.7066e-01,  1.6731e-01, -1.3021e-01,  2.1434e-01,  3.4471e-01,\n",
       "            -3.3357e-01,  8.1075e-02,  2.6899e-01,  2.5952e-01, -2.7363e-03,\n",
       "            -5.7873e-01,  4.0143e-01,  5.7145e-01, -8.8980e-02,  2.6432e-02,\n",
       "            -3.7534e-01,  2.4828e-01, -3.5835e-01, -1.5591e-01,  2.6418e-01,\n",
       "            -6.0694e-02, -1.8049e-01,  1.6663e-02,  2.8763e-01,  3.6945e-02,\n",
       "             2.2831e-01,  3.3976e-01,  3.0140e-03,  1.7403e-01,  2.5415e-01,\n",
       "            -6.2373e-02,  9.6658e-02,  4.4065e-01, -6.7211e-02,  2.1433e-01,\n",
       "             1.3381e-01,  1.7973e-01, -7.2370e-02, -2.2422e-01,  4.7300e-02,\n",
       "             2.8225e-01, -3.3700e-01, -2.2240e-02, -2.3188e-01, -1.5341e-01,\n",
       "            -1.5139e-01,  8.7313e-02, -1.7203e-01,  3.0112e-02,  7.7167e-02,\n",
       "            -3.3398e-01, -8.3147e-02, -3.1536e-01, -4.9529e-02,  2.3054e-02,\n",
       "            -4.5939e-02, -8.4973e-02,  5.4516e-01, -5.3096e-02, -3.4418e-02,\n",
       "            -9.2716e-02, -4.4230e-01,  4.2903e-01, -2.2551e-01,  4.5854e-01,\n",
       "             2.7473e-01, -6.1683e-02, -1.1527e-01, -7.8816e-02, -2.2663e-01,\n",
       "            -2.1577e-02, -4.1836e-01, -8.4846e-02,  2.1445e-01, -1.2465e-01,\n",
       "            -2.9894e-02,  5.1321e-01,  1.4409e-01, -1.9539e-02,  5.8831e-01,\n",
       "            -6.8378e-02, -1.7403e-01, -2.2711e-01,  2.3647e-01,  8.7760e-02,\n",
       "             3.0986e-02,  4.7121e-02, -8.9849e-02, -1.3490e-01, -2.6505e-02,\n",
       "             2.4861e-01,  9.3207e-02, -1.1810e-01,  1.3711e-01, -1.8442e-01,\n",
       "            -2.1981e-01, -6.2644e-02,  3.5170e-01,  1.3436e-01, -3.5260e-02,\n",
       "             6.1781e-02, -1.3470e-01,  1.8862e-01, -1.4425e-04,  2.2289e-02,\n",
       "            -1.1011e-01,  1.0177e-01, -1.4996e-01,  2.5552e-01, -2.0923e-01,\n",
       "             1.4275e-01, -1.6385e-01,  1.9822e-01, -3.1598e-01, -9.0830e-02,\n",
       "             1.4405e-01, -9.0845e-02, -4.7150e-02,  3.9555e-02, -7.2037e-02,\n",
       "            -2.3472e-01, -1.1304e-01, -1.6755e-01,  1.0077e-01,  3.4367e-01,\n",
       "            -1.9325e-01, -4.8069e-02,  1.0253e-02,  2.5976e-01,  2.2876e-02,\n",
       "             2.2506e-01,  6.6271e-02,  1.7183e-01,  6.5707e-02, -8.3707e-03,\n",
       "            -1.3184e-01, -5.3884e-01, -1.6319e-01,  3.3141e-01,  3.7782e-02,\n",
       "            -3.9652e-01,  1.6422e-01,  4.4780e-01,  3.7163e-01,  3.2796e-01,\n",
       "            -4.9766e-02,  4.0371e-01, -1.1603e-01,  1.8286e-02,  2.6136e-01,\n",
       "            -2.7932e-01, -2.1732e-01, -6.1212e-02, -6.2597e-01, -9.1795e-02,\n",
       "             6.6250e-01,  1.7706e-01, -6.9405e-01,  1.4140e-01,  2.2141e-01,\n",
       "            -2.2224e-01, -3.1769e-01,  1.0847e-01,  3.3365e-01,  1.0095e-01,\n",
       "            -6.9639e-02,  3.5493e-02, -3.4584e-01,  5.5949e-01,  1.1524e-01,\n",
       "             1.6189e-01,  2.3953e-01, -5.2552e-01,  3.7017e-02,  4.0930e-03,\n",
       "            -6.4748e-01,  1.9013e-01,  5.1629e-02, -9.5122e-02,  5.4284e-02,\n",
       "             5.7042e-01,  9.3688e-02,  4.3288e-01, -3.8532e-01, -3.4952e-01,\n",
       "            -2.6035e-01,  5.0522e-02,  6.7943e-03,  7.0772e-02,  1.2773e-01,\n",
       "            -6.2715e-01, -1.7910e-01,  3.7855e-01,  4.8216e-01, -1.5268e-01,\n",
       "             1.9417e-02, -3.0273e-01,  3.5350e-01,  4.5179e-02, -1.8926e-01,\n",
       "            -2.3531e-01,  1.6386e-01, -7.1548e-02, -2.2202e-01,  5.2410e-01,\n",
       "             3.3347e-01, -2.1749e-01, -1.1410e-01, -2.6213e-01, -3.5689e-01,\n",
       "            -1.3220e-01, -7.2074e-03, -5.7761e-02,  9.7048e-02,  1.9900e-01,\n",
       "            -1.1187e-01,  9.2020e-02,  2.8967e-01,  2.8392e-01, -7.9392e-01,\n",
       "            -7.6029e-01,  4.9845e-01,  1.0562e-01, -2.9142e-01,  1.0192e-01,\n",
       "             5.2813e-01,  1.8085e-01, -2.4376e-01,  2.4368e-01,  1.5629e-01,\n",
       "             1.7033e-01, -6.3464e-02,  1.5353e-01, -4.1894e-04,  2.3729e-01,\n",
       "             1.0438e-01, -3.2151e-01,  2.6673e-01, -1.9916e-01, -4.5214e-01,\n",
       "            -2.4568e-01,  4.1322e-02, -4.2168e-01, -7.2412e-01, -5.6231e-01,\n",
       "             1.8740e-01,  1.9197e-01, -6.6511e-01,  9.3536e-02, -2.7460e-01,\n",
       "            -1.7281e-01,  4.9645e-01, -2.0505e-01,  4.6160e-01,  4.7984e-02,\n",
       "             1.0996e-01, -3.5983e-01,  3.7832e-01, -6.7468e-03, -2.1998e-01,\n",
       "             1.0464e-01, -7.3985e-02, -1.4353e-01,  1.9447e-01, -2.4328e-01,\n",
       "             4.4267e-01, -2.8953e-02,  4.6933e-01, -8.7657e-02, -2.2927e-01,\n",
       "             2.6123e-01, -1.6681e-01, -6.9822e-02, -8.4742e-02,  1.9258e-01,\n",
       "             7.8835e-01, -4.0478e-01,  2.6190e-01,  1.1939e-01,  7.9993e-02,\n",
       "             6.5098e-02,  2.3517e-02, -1.7639e-01,  8.2735e-02,  4.4176e-01,\n",
       "            -6.2579e-01, -1.0108e-02,  3.6849e-02, -7.5623e-02,  3.2122e-01,\n",
       "            -1.7760e-01, -5.5534e-01, -1.7720e-01,  8.9884e-02,  1.1246e-01,\n",
       "            -2.2792e-01, -5.1159e-02, -1.8776e-01, -9.6040e-02,  1.7930e-01,\n",
       "            -1.8031e-01, -1.3624e-01, -1.2776e-01, -8.4488e-02, -4.6987e-01,\n",
       "            -4.9386e-01,  1.0271e-02,  2.3281e-01, -6.3427e-02, -2.5642e-01,\n",
       "            -1.8032e-01, -2.5064e-01,  1.0574e-01,  7.2748e-02,  4.7895e-01,\n",
       "            -7.4209e-03,  3.2245e-01, -3.5576e-01,  9.6030e-02,  5.0984e-01,\n",
       "            -3.2109e-01,  1.0601e-01, -1.8215e-01, -2.3304e-01, -9.6092e-02,\n",
       "            -5.6750e-01,  2.0060e-01,  2.5184e-01, -2.3965e-01,  5.8675e-02,\n",
       "            -3.4053e-01,  4.0683e-01, -1.0076e-01, -3.8881e-01, -5.6959e-01,\n",
       "             6.1339e-02, -1.2941e-01,  2.0381e-01,  1.8181e-01,  2.9439e-01,\n",
       "             2.9874e-01, -3.3604e-02, -3.3876e-02, -1.6105e-01,  4.5297e-02,\n",
       "            -2.9453e-02, -3.8307e-01,  3.2796e-01,  4.4654e-04,  3.5531e-02,\n",
       "            -2.6309e-03,  2.1724e-01,  4.1722e-01, -4.4641e-02, -6.1377e-01,\n",
       "            -1.3600e-01,  1.3124e-01, -1.0061e-01,  3.7076e-01, -2.2726e-01,\n",
       "             5.5518e-02, -7.3702e-02,  8.4404e-02, -4.2997e-02,  1.9049e-01,\n",
       "            -7.7222e-02, -1.4415e-02, -4.1421e-01,  4.2587e-01,  3.0924e-01,\n",
       "             2.0791e-01, -1.3667e-01,  1.2867e-01, -4.4474e-02, -1.3025e-01,\n",
       "            -1.8560e-02, -9.3445e-02, -8.8651e-02, -2.1053e-01, -8.4234e-02,\n",
       "             4.5338e-02, -3.1340e-01, -5.1877e-01, -3.6141e-01,  2.2010e-01,\n",
       "             7.4590e-01,  9.0772e-02, -2.7040e-01,  1.6831e-02, -8.2770e-02,\n",
       "             1.0996e-01, -1.5036e-01, -1.4824e-01,  4.0305e-01,  1.6634e-01,\n",
       "            -2.1498e-01, -1.8556e-01,  8.5700e-02, -4.8489e-02, -3.3723e-01,\n",
       "            -3.1906e-02,  2.8058e-01, -1.6089e-01, -1.5814e-01,  5.0402e-01,\n",
       "            -5.4499e-02,  9.5852e-03,  4.1884e-01, -5.2690e-01, -1.1977e-01,\n",
       "            -7.7320e-02,  1.2533e-01, -4.4111e-01, -4.8682e-01, -1.1408e-02,\n",
       "            -2.2922e-01, -2.7795e-02, -1.4177e-01, -1.0154e-01, -1.2381e-01,\n",
       "            -1.1579e-01,  1.4422e-02, -2.7863e-01,  2.4000e-01,  8.1420e-01,\n",
       "            -1.3736e-01, -3.6088e-01, -3.3156e-01, -7.3368e-01,  5.0019e-01,\n",
       "            -9.4550e-02, -1.1889e-02,  7.4079e-02, -2.3321e-01, -1.4220e-01,\n",
       "            -1.5867e-01,  2.0875e-01, -2.5962e-01, -8.7697e-02,  2.3586e-02,\n",
       "            -4.7658e-03,  1.9037e-01, -4.4142e-01,  3.8901e-01,  1.6311e-01,\n",
       "             1.4314e-01,  2.0394e-01, -7.7595e-01, -4.3936e-02, -6.6184e-01,\n",
       "             1.3080e-01, -4.8235e-01,  1.1986e-01, -1.2708e-01,  4.8941e-01,\n",
       "             2.8840e-01,  1.8239e-03,  8.2554e-02,  6.2510e-01,  3.5909e-01,\n",
       "            -1.0601e-01, -2.6954e-01,  4.8355e-01, -3.1500e-01, -6.8118e-02,\n",
       "             8.3102e-02, -4.3345e-01,  4.6628e-01,  5.5523e-02,  4.1577e-01,\n",
       "            -3.8595e-01, -5.1382e-01, -1.6913e-01, -1.6298e-01,  2.4615e-01,\n",
       "             1.3981e-01, -4.8452e-01,  1.1228e-01,  1.8390e-01, -4.0924e-01,\n",
       "            -1.1427e-02,  8.3902e-02,  2.2307e-02,  3.6778e-02,  9.4496e-03,\n",
       "            -1.9571e-01, -2.2408e-01, -3.4920e-01, -2.8096e-01,  3.1309e-01,\n",
       "            -5.2071e-01, -5.3478e-01,  2.0350e-01, -2.6881e-01, -9.3646e-02,\n",
       "            -7.7779e-03,  4.6959e-01, -1.8713e-02, -1.0441e-02,  3.2229e-01,\n",
       "            -2.3987e-01, -1.9645e-01, -5.5314e-02, -2.3168e-01,  8.0086e-02,\n",
       "            -1.1981e-01,  1.4764e-01, -5.1126e-01,  9.7666e-02, -3.0774e-01,\n",
       "            -1.0563e-01, -1.5046e-01, -7.1922e-03,  2.0186e-01, -1.4005e-01,\n",
       "             1.9860e-02, -9.2838e-02,  2.5323e-02, -1.6431e-01,  4.2476e-01,\n",
       "            -2.7945e-01,  5.3055e-02, -1.9998e-01,  2.8259e-01, -2.6596e-01,\n",
       "            -4.3099e-02,  5.6562e-02,  4.4320e-03, -2.7236e-01,  4.9584e-01,\n",
       "             3.7645e-01,  6.0121e-02,  3.9620e-02, -9.2159e-02, -1.5104e-01,\n",
       "             1.3547e-01,  7.1367e-02, -7.4996e-01]]),\n",
       "   tensor([[   29,    93, 20704, 49651,   510,  7177,   403,  7141,   275,   247,\n",
       "             4849,  1925, 25290,    15, 11242,   285,   253, 30151,   326,  1056,\n",
       "              598,  1016,  3389,   403,  7141,   275,   247,  4849,  1925, 25290,\n",
       "               15,   348, 18357,    15,     0]])),\n",
       "  (tensor([[ 3.4561e-03, -3.2860e-01, -7.9001e-01,  2.4986e-01,  6.8249e-02,\n",
       "             6.3502e-02, -9.0733e-02, -9.0769e-02, -6.2673e-03,  4.7706e-01,\n",
       "             1.1943e-02,  3.9929e-01,  3.8603e-02,  4.3678e-02,  1.6228e-01,\n",
       "             6.1017e-02, -9.1081e-02,  1.2524e-01, -8.4170e-02, -1.9645e-02,\n",
       "            -4.8223e-03, -3.2912e-01, -5.7973e-01, -3.0281e-01,  5.1283e-02,\n",
       "             2.5320e-01, -1.7029e-01, -1.2787e-01,  6.2296e-02, -3.5433e-02,\n",
       "            -2.1476e-02,  7.4844e-02, -2.0009e-01,  2.8038e-01, -3.4298e-01,\n",
       "             3.8735e-02, -1.0891e-01,  3.1406e-01, -8.7331e-01,  8.4960e-02,\n",
       "             8.6070e-03, -8.2909e-02,  4.9615e-01,  5.3988e-02, -4.9297e-02,\n",
       "            -1.9787e-02,  3.8342e-01, -7.0500e-02, -2.4841e-01,  4.2187e-03,\n",
       "             1.8939e-01, -9.7119e-02, -2.5718e-01, -5.0709e-02, -1.5268e-01,\n",
       "             6.1073e-02, -5.3538e-02, -3.4986e-01,  1.3100e-01, -3.4667e-02,\n",
       "            -1.9502e-01,  7.9744e-02, -2.2169e-01, -6.9435e-02,  5.5625e-01,\n",
       "             5.4062e-01,  5.8121e-02,  8.8434e-02,  1.3871e-01, -4.4994e-01,\n",
       "             5.2970e-01,  1.3026e-01,  1.5278e-01, -2.1311e-01, -6.3941e-02,\n",
       "            -4.2566e-01,  7.8557e-03,  1.7060e-01, -5.5312e-02, -7.6372e-02,\n",
       "            -2.3794e-01, -1.2271e-01, -1.9183e-01, -3.8836e-01,  5.3949e-02,\n",
       "             1.1412e-01,  3.1222e-01, -3.4830e-02, -1.7718e-01, -1.5476e-01,\n",
       "             1.6358e-01,  4.0310e-02,  1.4284e-01, -1.4243e-01,  6.6346e-02,\n",
       "            -1.8402e-01, -1.7022e-01, -3.0281e-01,  2.6372e-01, -1.4995e-01,\n",
       "            -8.8859e-02, -4.6313e-02,  2.2823e-01, -1.7050e-01,  1.5921e-02,\n",
       "             7.7450e-02, -4.3856e-02, -1.4877e-01, -1.9116e-02, -2.0349e-01,\n",
       "             2.5756e-02,  3.2509e-01,  1.1516e-01,  1.2846e-01, -2.7015e-01,\n",
       "             2.5892e-01,  1.1306e-01,  4.9023e-01,  2.9138e-01,  1.0794e-01,\n",
       "             6.9688e-02,  2.4048e-01,  3.6971e-01,  1.1582e-01, -6.5047e-02,\n",
       "            -1.1520e-01,  2.1996e-01,  2.1840e-02, -2.6843e-01, -1.2352e-01,\n",
       "            -3.2112e-01,  1.2112e-01, -3.4942e-02, -1.4353e-01,  2.8552e-01,\n",
       "             2.4307e-01, -5.0502e-01,  3.9228e-02, -4.0900e-02,  2.1218e-01,\n",
       "            -8.9603e-02, -1.1755e-01, -2.8809e-01, -2.4314e-01, -2.6546e-04,\n",
       "            -4.0242e-01,  3.4477e-01, -7.5905e-02,  1.7290e-02, -1.3656e-01,\n",
       "             3.7903e-02,  2.9297e-01,  8.1868e-02, -1.4984e-01,  1.4897e-01,\n",
       "             1.5345e-01,  9.2612e-02,  1.9106e-01, -4.2940e-01,  1.2833e-01,\n",
       "            -6.6320e-01, -1.2617e-01, -8.0488e-02, -1.8899e-02,  1.5531e-01,\n",
       "             3.2764e-02,  5.0690e-01,  7.3674e-02, -1.3088e-01, -1.2203e-01,\n",
       "            -2.5186e-01, -9.3303e-02, -1.0065e-01, -1.5960e-02, -3.4896e-01,\n",
       "             1.4743e-01, -3.1917e-01, -2.0165e-01,  2.1752e-01,  2.4017e-01,\n",
       "             2.1633e-01, -4.7511e-02,  1.2172e-01, -2.2040e-01, -2.4041e-01,\n",
       "            -5.0313e-01, -3.9998e-01,  5.4851e-01, -1.8934e-01,  1.9805e-01,\n",
       "            -9.0408e-02, -7.9123e-02, -1.4995e-01, -9.3363e-02,  1.6520e-01,\n",
       "             1.9245e-01, -6.1914e-03,  1.3928e-01, -1.6626e-01,  5.9343e-02,\n",
       "            -1.0100e-01, -2.2297e-01,  1.5054e-01,  1.8959e-01,  5.7493e-03,\n",
       "            -2.4852e-01, -6.1666e-02,  8.2617e-02,  2.6348e-01, -8.3220e-02,\n",
       "             1.6371e-01,  5.4433e-02,  1.4850e-01,  3.1559e-01, -5.5489e-02,\n",
       "             1.2979e-02,  7.5780e-03, -3.7629e-01,  1.9372e-01,  2.0057e-01,\n",
       "            -1.7336e-01,  2.2197e-01,  6.1368e-02,  1.1289e-01, -2.7025e-02,\n",
       "             1.0594e-02, -2.1393e-01,  4.7604e-01, -1.1523e-01, -7.1217e-02,\n",
       "             3.6527e-01, -8.8216e-02, -3.1423e-01, -3.2917e-02,  1.9456e-03,\n",
       "            -1.4813e-01, -9.2281e-02, -1.9365e-02, -1.0259e-01, -3.3108e-01,\n",
       "            -2.9025e-01,  3.4210e-01,  4.2342e-01,  1.8366e-01,  3.7119e-02,\n",
       "            -2.6906e-01,  2.4536e-01, -2.3002e-01,  1.7792e-01,  9.5414e-02,\n",
       "            -1.3404e-02,  1.8904e-02, -1.9752e-01,  1.2521e-01, -1.4504e-01,\n",
       "            -1.1522e-01,  2.6946e-01, -2.8399e-01,  1.9838e-02,  3.1657e-01,\n",
       "             1.5159e-01,  1.2749e-01,  1.9503e-01,  2.6165e-01,  6.9721e-01,\n",
       "             1.4643e-01,  9.4919e-02,  2.5417e-01, -3.7478e-01, -5.8476e-03,\n",
       "            -1.0144e-01, -1.4517e-01, -1.5321e-01, -1.7210e-01, -1.9568e-01,\n",
       "            -6.6373e-04,  1.3200e-01, -4.7329e-04,  5.7416e-02, -1.0695e-01,\n",
       "            -4.9833e-01, -2.1178e-01,  1.8811e-02, -2.4878e-01, -1.9487e-01,\n",
       "             2.1275e-01,  1.4313e-01, -5.1956e-02,  1.2125e-01,  9.7256e-02,\n",
       "             2.8535e-02, -1.5568e-01,  2.5743e-01, -2.5794e-01,  8.9266e-01,\n",
       "             1.1860e-01,  6.3923e-02,  1.3712e-01, -1.0185e-01, -2.3009e-01,\n",
       "            -1.6885e-02, -1.5011e-01,  1.0405e-01,  2.1386e-01, -1.6477e-01,\n",
       "            -1.8192e-02,  7.1925e-01, -9.1906e-02,  8.2598e-02,  4.7683e-01,\n",
       "             8.8126e-03, -9.4398e-02,  9.2110e-03,  2.0525e-01, -7.7226e-04,\n",
       "            -1.0937e-01, -7.3118e-02,  1.8663e-01, -2.7803e-01, -4.7453e-02,\n",
       "             2.2860e-01, -5.1864e-02, -1.6226e-01,  6.9887e-02, -4.9996e-03,\n",
       "            -1.9668e-01,  1.3052e-01, -4.2850e-03, -2.7096e-01,  3.6376e-01,\n",
       "            -1.1881e-01,  1.4296e-01,  8.1556e-02, -2.2741e-01,  1.4367e-01,\n",
       "             2.7456e-01,  1.7368e-01, -1.4079e-01,  1.7569e-01, -1.7019e-01,\n",
       "             8.8758e-03,  1.9925e-01,  1.5526e-01, -3.3200e-01,  1.6699e-01,\n",
       "             2.3182e-01,  2.3944e-01, -3.4301e-02,  1.9966e-02,  2.5050e-01,\n",
       "            -1.0542e-01, -7.4511e-02,  9.2963e-02,  9.1681e-02,  1.0565e-01,\n",
       "             1.0086e-01, -1.0269e-01, -2.7164e-03, -5.4272e-02,  4.0323e-01,\n",
       "             3.8445e-01, -5.4910e-03,  1.1129e-01,  3.0980e-01,  1.0916e-01,\n",
       "            -3.0055e-01, -4.5462e-01, -2.9226e-01,  1.4639e-01,  1.1931e-01,\n",
       "             1.9552e-01, -9.7540e-02,  5.1366e-01,  1.9039e-01,  5.0596e-01,\n",
       "             2.5716e-01,  6.1007e-01,  5.0528e-02,  1.1323e-01,  3.9163e-02,\n",
       "            -2.3466e-01, -1.9541e-01, -1.2121e-01, -3.2652e-01, -4.4353e-02,\n",
       "             5.7997e-01,  3.4006e-01, -7.4229e-01,  3.4631e-01,  3.5831e-01,\n",
       "            -1.4844e-01, -1.3465e-01, -6.7987e-02,  3.4947e-01,  8.0230e-02,\n",
       "            -2.6667e-02,  2.2235e-01, -1.4975e-01,  4.7273e-01,  1.4093e-01,\n",
       "             1.7837e-01, -8.3714e-02, -2.6082e-01, -5.8449e-02,  2.0944e-01,\n",
       "            -3.4453e-01,  3.6913e-01,  1.5344e-01, -5.4724e-01,  7.2037e-02,\n",
       "            -1.8493e-01,  4.7903e-01,  3.3921e-01, -5.7231e-01, -4.3204e-01,\n",
       "             8.1064e-02,  1.5217e-01,  7.9879e-02,  1.1812e-01, -5.4330e-02,\n",
       "            -3.4466e-01, -7.6556e-03,  2.6103e-01,  4.3456e-01,  2.5899e-01,\n",
       "             2.3314e-01, -2.7611e-01,  3.4836e-01, -5.7676e-02, -3.4930e-01,\n",
       "             2.5774e-01,  3.0935e-02,  1.4105e-01,  4.7479e-01,  2.6080e-01,\n",
       "             2.1079e-01,  3.4819e-01, -2.8764e-01, -2.7798e-01, -3.1402e-01,\n",
       "            -3.6552e-01, -2.4731e-02,  6.9732e-02,  5.8033e-02,  6.3750e-02,\n",
       "            -5.9814e-01, -2.9627e-01,  6.2759e-03,  2.9946e-02, -4.9984e-01,\n",
       "            -1.7913e-01,  2.7047e-01,  8.8480e-03, -7.5135e-01, -6.8939e-02,\n",
       "            -1.5001e-03, -2.4826e-01,  9.9911e-02,  1.2658e-01, -1.6059e-01,\n",
       "             2.2193e-01, -2.9377e-01,  4.6085e-01,  1.1116e-01, -3.2221e-01,\n",
       "            -2.2027e-01, -2.1305e-01, -2.8291e-02,  1.2671e-01, -2.7971e-01,\n",
       "            -8.7468e-02,  3.3245e-01, -5.2832e-01, -4.5926e-01, -5.1291e-01,\n",
       "             1.2812e-01, -1.8998e-01, -1.1216e+00,  4.5354e-01, -2.4144e-01,\n",
       "             1.9712e-02,  2.9662e-01, -1.1556e-03,  2.5459e-02,  1.4889e-01,\n",
       "             1.9877e-01,  2.1085e-01,  2.0807e-01,  4.6572e-02, -5.1185e-01,\n",
       "            -1.0867e-01, -2.2380e-01,  1.1269e-01,  2.4552e-01,  2.0255e-01,\n",
       "             1.0531e-01,  4.5113e-02,  3.5605e-01, -4.6420e-01, -5.6483e-01,\n",
       "             1.1162e-01, -1.2307e-01, -8.5553e-02,  5.7422e-01,  1.8398e-02,\n",
       "             7.6807e-01, -4.0690e-02,  2.4556e-01, -3.9447e-01,  2.6035e-01,\n",
       "             3.2128e-02, -3.1039e-01,  7.1461e-02,  1.3569e-01,  5.1941e-03,\n",
       "            -2.1511e-01,  7.6695e-02, -1.3655e-01,  3.2955e-01,  2.8160e-01,\n",
       "            -3.0194e-02, -6.2649e-01,  1.7926e-01,  6.1487e-01, -1.1123e-01,\n",
       "            -5.7118e-01,  1.5484e-01, -5.2887e-01, -5.7055e-02,  2.0332e-01,\n",
       "            -1.7813e-02, -1.2249e-01, -6.7474e-02,  1.6892e-01, -3.8315e-01,\n",
       "             1.5966e-01, -2.8228e-02,  1.8181e-01,  2.6490e-01, -1.8193e-02,\n",
       "            -3.4101e-01, -3.0039e-01,  2.8363e-01, -1.5977e-01, -1.5125e-01,\n",
       "             2.3495e-01,  2.1219e-01, -3.0545e-01,  1.5564e-01,  2.3881e-01,\n",
       "            -2.8878e-01,  3.8447e-01,  2.0887e-02, -4.4872e-01, -4.1103e-01,\n",
       "             1.0567e-01,  1.9148e-01,  3.1620e-01, -1.4384e-01, -3.2209e-01,\n",
       "            -1.9833e-01,  2.3238e-01, -4.3373e-01, -9.5280e-01, -6.1518e-01,\n",
       "             3.0555e-01,  1.7543e-01,  2.5091e-01, -3.2005e-01,  2.3731e-01,\n",
       "             1.8801e-01,  1.9706e-01,  1.5706e-01, -2.3782e-01, -2.6911e-01,\n",
       "            -1.7451e-01, -4.1132e-01, -1.5377e-02,  2.7116e-01, -1.3325e-01,\n",
       "            -1.3083e-01, -3.5278e-01,  2.9981e-01, -7.2224e-02, -1.1636e-01,\n",
       "            -2.2792e-01, -2.3534e-02, -6.4359e-02,  3.0467e-01, -1.4831e-01,\n",
       "            -1.7213e-01, -2.6907e-01,  1.4899e-01,  2.6893e-01,  1.2014e-01,\n",
       "            -1.4620e-01, -5.6556e-02, -4.7698e-01,  2.3057e-01,  1.5535e-01,\n",
       "             2.1865e-01,  5.2181e-02,  5.2700e-01,  2.6572e-01,  7.6095e-02,\n",
       "            -4.2874e-03, -8.8076e-02, -1.3888e-01, -2.5304e-01, -5.4821e-02,\n",
       "            -1.5380e-01, -7.2953e-01, -5.4848e-03, -3.5267e-01,  3.1190e-03,\n",
       "             4.1655e-01, -3.4317e-01, -3.0535e-01,  6.8072e-02, -1.9597e-01,\n",
       "             2.1546e-01,  2.4537e-01, -2.5960e-01, -3.9553e-02, -1.9064e-01,\n",
       "            -2.1120e-01, -8.3191e-02,  6.6295e-02,  4.9065e-01,  1.5199e-01,\n",
       "            -1.6718e-01,  4.9857e-01, -3.5053e-01,  6.3899e-02,  2.4964e-01,\n",
       "            -2.0999e-01,  1.3232e-01, -3.7047e-02, -2.1471e-01, -1.1854e-01,\n",
       "             3.6328e-01, -3.4625e-01, -6.0160e-01, -1.8881e-01, -1.7306e-01,\n",
       "             1.6264e-03, -3.7655e-01,  3.0431e-01, -4.8105e-01,  6.1361e-02,\n",
       "            -2.6919e-01, -2.0698e-01,  8.7779e-02,  1.9636e-01,  7.2037e-01,\n",
       "            -1.1099e-01, -2.6582e-01,  2.7245e-01, -5.6287e-01,  6.5916e-01,\n",
       "             2.4445e-02,  9.3282e-02, -4.6360e-02, -3.6765e-01, -6.1114e-02,\n",
       "            -6.8587e-02, -3.5611e-01, -7.6067e-01, -2.9766e-03,  2.6855e-01,\n",
       "             9.4810e-02,  8.3489e-02, -6.3724e-02,  3.4352e-01,  3.2335e-02,\n",
       "             2.9863e-01,  3.3919e-01, -4.0446e-01, -6.4675e-02, -3.4672e-01,\n",
       "             4.6727e-01, -2.0401e-01,  2.2700e-02, -2.5243e-01, -2.1051e-02,\n",
       "             2.4539e-01, -1.1965e-01,  6.6149e-02,  5.4425e-01, -7.1268e-02,\n",
       "            -4.2548e-01, -2.8065e-01,  2.3204e-01, -3.7521e-01,  2.9045e-01,\n",
       "            -1.6226e-01, -2.1154e-01,  5.1611e-01,  2.6105e-01,  2.2113e-01,\n",
       "            -2.0966e-01, -8.1624e-02,  1.9098e-01,  3.2330e-03,  3.6166e-01,\n",
       "            -1.3523e-01, -7.2123e-02,  2.1596e-01,  9.3780e-02, -3.9187e-01,\n",
       "             1.6095e-01,  1.2761e-01, -1.0141e-01, -2.0858e-01, -1.3657e-01,\n",
       "            -6.1365e-02, -1.6576e-01, -2.0945e-01,  3.4075e-01, -1.4706e-01,\n",
       "            -3.1137e-01, -3.2469e-01,  3.1462e-01, -4.6710e-01,  3.3354e-02,\n",
       "            -6.8421e-01,  1.8216e-01, -2.6853e-01,  2.3922e-02,  4.4479e-01,\n",
       "            -6.5719e-01,  8.3915e-02,  1.8440e-01,  2.8537e-03,  5.8084e-02,\n",
       "            -2.0368e-02,  3.6703e-02, -1.6166e-01,  1.8383e-01,  3.2633e-01,\n",
       "            -1.3856e-01, -2.7985e-01, -3.0495e-01,  2.4146e-01, -2.0061e-01,\n",
       "             2.8393e-01,  9.4376e-02, -3.8463e-01, -2.1230e-01,  2.9819e-01,\n",
       "             6.8764e-02,  1.8627e-01, -6.9067e-01,  1.0871e-01, -4.0036e-01,\n",
       "            -2.1929e-01, -2.3465e-01,  1.9554e-01, -1.8575e-01, -8.2392e-02,\n",
       "             1.3939e-02,  4.5883e-03,  1.0845e-01, -5.2706e-01, -2.3378e-01,\n",
       "             1.1606e-01, -9.8015e-02, -8.9327e-02]]),\n",
       "   tensor([[   29,    93, 20704, 49651,  1394,   403,   987,    15, 30123,  3389,\n",
       "              778,  2489,  1781,   407,  1781,  1618,    15,     0]])),\n",
       "  (tensor([[-3.9489e-01,  1.6906e-01, -2.0000e-01, -2.3003e-01, -1.5566e-01,\n",
       "            -3.0396e-01, -2.5851e-01, -1.1333e-03, -3.5433e-01,  8.5907e-02,\n",
       "             2.2157e-01,  4.7293e-01,  2.0571e-01,  5.0607e-02,  8.9471e-03,\n",
       "             3.2004e-01,  1.2470e-01,  2.6971e-01,  2.0661e-01, -1.7868e-02,\n",
       "            -3.2570e-01, -2.1345e-01, -2.2732e-01, -3.4684e-02,  1.7359e-01,\n",
       "            -7.9600e-02, -2.1013e-01, -2.0869e-02,  2.0514e-01, -1.3027e-01,\n",
       "             2.0825e-01,  1.9152e-01, -2.7252e-01,  1.5677e-01,  4.5146e-01,\n",
       "             1.0056e-02, -2.9610e-01, -3.4518e-01,  3.2492e-02,  1.6084e-01,\n",
       "            -1.2629e-01,  1.9892e-03,  9.8585e-02,  4.3345e-02, -2.4116e-01,\n",
       "            -4.1396e-02,  3.2455e-01,  1.7954e-01,  1.3749e-02, -1.1593e-01,\n",
       "            -2.0819e-02, -1.9269e-02, -2.7818e-01, -3.7327e-01, -1.6064e-01,\n",
       "            -3.2151e-01,  1.1067e-01,  9.1436e-02,  2.2903e-01,  4.0189e-02,\n",
       "            -1.8343e-01,  1.4704e-01,  8.5116e-03, -2.4107e-01,  1.5393e-01,\n",
       "             2.1845e-01, -1.7839e-01, -6.1134e-02,  3.8125e-02, -8.2632e-02,\n",
       "             1.9639e-01, -1.1598e-01,  6.6263e-02,  2.6469e-01,  1.8336e-01,\n",
       "             1.9461e-02,  2.6150e-01, -1.6924e-01, -9.9777e-04, -5.8676e-02,\n",
       "            -1.8983e-01, -1.6174e-01,  2.2933e-01,  2.3513e-01, -6.6270e-01,\n",
       "             4.9264e-02,  2.4325e-02, -2.4209e-01,  3.6442e-01, -1.1979e-01,\n",
       "             2.7487e-01, -3.2372e-01,  3.4103e-02, -6.2272e-01,  1.1526e-01,\n",
       "             1.3205e-01,  1.8106e-01, -7.5042e-02, -8.2485e-02, -3.1960e-01,\n",
       "            -2.0514e-01, -2.5403e-01, -1.6550e-01, -1.7279e-01,  1.3928e-01,\n",
       "             3.9095e-02, -1.7979e-01, -2.6291e-01, -5.6924e-02,  1.2602e-02,\n",
       "             5.1693e-02,  6.7903e-02, -3.3995e-01,  1.3993e-01,  4.1699e-02,\n",
       "             4.4407e-02, -2.7815e-01,  4.6247e-01,  3.8131e-02,  2.8797e-01,\n",
       "             2.2785e-01,  2.1418e-01, -6.0610e-02,  2.4531e-01,  1.1605e-01,\n",
       "             5.5818e-02,  4.2732e-01, -3.2834e-01,  7.2297e-02,  4.9520e-02,\n",
       "             7.6374e-03, -9.2002e-02, -7.1757e-02, -2.0770e-02,  1.6360e-01,\n",
       "            -1.6839e-02, -7.1303e-01, -5.0069e-02, -1.1126e-01,  4.1077e-03,\n",
       "            -2.7011e-01,  1.9312e-01,  1.1319e-01, -1.9559e-01, -6.4490e-01,\n",
       "            -1.6372e-01, -7.0770e-02, -8.7864e-02,  1.1546e-03, -4.1647e-03,\n",
       "            -1.8745e-01, -2.6732e-02,  8.7910e-01,  6.4051e-02, -1.3304e-01,\n",
       "            -1.3206e-01,  2.7629e-01, -1.5948e-01,  2.0187e-02,  1.9158e-01,\n",
       "             3.5941e-01,  1.7816e-01, -4.5005e-01,  2.8841e-01,  1.8448e-02,\n",
       "             2.0933e-01,  3.6730e-01,  4.1626e-01, -5.8442e-02,  4.1842e-02,\n",
       "             1.2731e-01,  3.6157e-01, -2.7542e-02,  3.4200e-01,  3.1803e-02,\n",
       "            -4.9631e-01, -5.5185e-03,  1.4391e-01, -2.2824e-01, -3.5202e-01,\n",
       "            -2.5639e-01,  7.9762e-02, -2.6464e-02,  2.9098e-02,  2.0497e-01,\n",
       "             3.5648e-01, -2.1980e-01,  2.5325e-02,  2.6639e-01,  1.9859e-01,\n",
       "            -3.5947e-02,  2.9629e-01,  2.6237e-01, -9.9230e-03, -8.8171e-02,\n",
       "             2.1564e-03,  1.3190e-01,  2.5361e-01,  2.7395e-01,  3.5411e-02,\n",
       "             2.4369e-01, -2.1783e-01,  1.4410e-01, -8.9659e-02,  2.4564e-01,\n",
       "            -2.8573e-02, -3.7656e-01, -3.2369e-01,  1.9881e-01,  1.6750e-01,\n",
       "             9.5198e-02,  4.5101e-02,  4.0372e-04,  1.5459e-01,  3.8920e-02,\n",
       "            -6.8642e-01, -3.4561e-01, -1.7387e-01, -1.6582e-01,  1.1108e-01,\n",
       "             2.7028e-01,  7.4387e-02, -1.8253e-01,  3.2232e-01, -1.0157e-01,\n",
       "             1.8861e-01, -4.8210e-01, -5.4197e-01,  1.6368e-01,  2.3060e-01,\n",
       "             1.9459e-01,  1.1805e-01, -1.7196e-01, -2.5405e-02, -2.1037e-01,\n",
       "            -1.5973e-01,  7.0164e-02, -1.9608e-01, -8.9977e-02, -3.9066e-02,\n",
       "            -5.9274e-01, -1.8001e-02,  8.1093e-02, -2.8820e-01, -2.8802e-01,\n",
       "            -1.0763e-01,  1.0780e-01, -4.8988e-02,  1.2562e-01, -7.5254e-02,\n",
       "            -1.7731e-01, -2.7347e-01, -3.4385e-01, -2.4568e-02, -3.5398e-01,\n",
       "            -2.5346e-01,  2.8994e-01,  3.6480e-01,  1.6155e-01, -1.4145e-01,\n",
       "            -1.1269e-01,  1.0398e-01,  9.2618e-03, -2.7006e-01,  2.9468e-01,\n",
       "             2.4897e-01, -6.3574e-01,  1.6793e-01,  8.5785e-02,  2.7138e-02,\n",
       "            -2.9592e-01,  8.3794e-02, -1.8984e-01, -4.1335e-01,  1.4724e-01,\n",
       "            -1.9039e-01, -1.9004e-01, -1.8421e-01, -1.0664e-01,  3.2264e-01,\n",
       "            -4.9055e-02,  8.5317e-02,  1.2001e-01, -3.7364e-01,  1.3545e-01,\n",
       "             2.3192e-01, -4.5233e-01,  7.4713e-02, -7.8257e-02,  1.1556e-01,\n",
       "             3.0812e-01, -2.4021e-01,  3.1100e-01,  3.7354e-01,  6.5752e-01,\n",
       "            -2.6153e-01,  3.4881e-01,  2.3093e-01, -1.3960e-01, -1.9056e-01,\n",
       "            -9.1575e-02, -3.2716e-02, -6.7670e-02,  3.3416e-03, -1.0307e-01,\n",
       "             7.3203e-02,  1.6612e-01, -3.0413e-01, -2.8898e-01, -2.4981e-02,\n",
       "             5.7069e-01,  3.8012e-01,  3.2650e-01, -1.2157e-01,  1.6857e-01,\n",
       "            -1.8371e-02, -7.7083e-02, -1.2407e-01,  1.9671e-01, -2.0602e-01,\n",
       "            -1.4258e-01, -1.5499e-01, -1.0198e-02,  1.7256e-01, -7.7522e-02,\n",
       "            -1.7008e-01, -1.5953e-01,  3.0973e-01, -4.2852e-02,  4.9739e-02,\n",
       "             4.0875e-01,  1.9873e-02,  1.1714e-02, -5.9874e-03, -5.7529e-01,\n",
       "            -8.8737e-02,  2.6306e-01,  7.1515e-02, -1.2158e-01, -1.8370e-01,\n",
       "            -9.4597e-02,  2.0082e-01,  2.0325e-01,  2.4711e-01, -2.0849e-02,\n",
       "             1.4097e-01,  1.9468e-02,  1.8174e-01,  1.0593e-01, -1.5238e-01,\n",
       "             1.8307e-02, -3.2549e-01,  2.9160e-01, -3.3755e-01, -8.4311e-02,\n",
       "             1.8321e-01, -2.0234e-02,  5.9921e-02, -2.8546e-02,  3.2444e-01,\n",
       "             2.6974e-01, -4.4749e-02,  5.1784e-01, -2.0676e-01, -2.4076e-01,\n",
       "            -3.8989e-01, -3.1028e-01, -1.7181e-01,  4.7190e-02, -3.0258e-01,\n",
       "            -2.3540e-01,  3.1150e-01, -2.0517e-01,  2.9914e-01, -2.6846e-01,\n",
       "            -3.2353e-01, -2.9883e-01,  1.2162e-01, -2.5235e-01, -2.2668e-02,\n",
       "            -8.8757e-02, -4.1213e-02, -2.6146e-01, -2.6448e-02,  2.1644e-01,\n",
       "             1.0503e-02,  6.3383e-02, -3.2716e-01,  1.0925e-01,  8.1484e-02,\n",
       "            -1.3160e-01,  4.9991e-01, -1.1795e-01, -5.3090e-01, -4.4723e-01,\n",
       "            -2.4249e-01, -8.1568e-02,  3.8780e-01, -6.0131e-02, -1.6158e-02,\n",
       "            -4.8515e-02, -7.0596e-02, -3.2093e-01, -2.3304e-01,  2.3311e-01,\n",
       "            -3.5319e-01, -4.9825e-01,  3.9502e-02,  2.6181e-01, -1.1307e-01,\n",
       "            -1.4710e-02,  2.6364e-02, -2.1740e-01,  3.5793e-01,  2.3829e-02,\n",
       "            -7.9859e-02,  1.3696e-01,  7.5989e-01,  5.9375e-01,  1.0247e-01,\n",
       "             2.2750e-01,  1.8696e-01, -2.1119e-01, -2.9331e-03,  1.2062e-01,\n",
       "             3.0333e-01,  9.6198e-02,  3.8645e-01,  1.2160e-01,  1.8010e-01,\n",
       "             1.1762e-01,  1.8109e-01,  4.7071e-02, -7.3088e-02,  6.9894e-02,\n",
       "             1.6507e-01, -6.2498e-02, -2.1646e-01,  1.1851e-01,  6.9626e-02,\n",
       "            -2.8478e-01,  3.1709e-01,  2.6805e-01,  4.5441e-01, -1.8468e-02,\n",
       "            -2.1636e-01,  2.1921e-01, -5.6322e-01, -5.9870e-02, -6.1186e-01,\n",
       "            -5.4606e-02, -4.2888e-01,  1.7870e-01, -2.8493e-01,  2.6375e-01,\n",
       "             7.1807e-02,  2.1750e-01, -3.9047e-01, -3.6417e-02,  4.1975e-01,\n",
       "             1.8836e-01,  2.1081e-01, -1.0598e-01, -2.3522e-01, -1.0493e-01,\n",
       "             1.9635e-01,  3.1164e-01,  3.6399e-01, -2.1589e-01, -2.7586e-01,\n",
       "            -7.3464e-02,  1.1565e-01, -6.2667e-02, -2.8317e-02,  1.8005e-01,\n",
       "             8.3965e-02, -1.3287e-01, -6.9433e-01, -6.9194e-02, -7.8551e-02,\n",
       "            -8.8017e-01,  9.4092e-02, -8.4714e-02, -2.3659e-01,  1.7037e-01,\n",
       "            -1.2642e-01, -4.7668e-01, -1.2830e-01,  2.1730e-01, -2.8193e-01,\n",
       "             1.0625e-01, -2.1109e-02,  4.6180e-01,  3.1135e-01,  4.1397e-01,\n",
       "             1.8683e-01, -5.3913e-03,  3.9908e-01,  7.8043e-02, -5.5504e-01,\n",
       "            -1.3898e-01, -7.2588e-02,  3.6102e-01,  6.8125e-01, -7.1935e-02,\n",
       "             2.6093e-02, -9.2341e-02, -4.5233e-01, -5.2152e-02, -6.0129e-01,\n",
       "             2.5409e-01,  1.0940e-01, -6.3943e-02, -1.1819e-01, -1.6393e-02,\n",
       "             7.1337e-01, -1.9272e-01, -1.9174e-01,  2.2547e-01, -2.5750e-01,\n",
       "             4.3656e-01,  1.8898e-02,  8.8189e-02,  1.7620e-02,  3.8524e-02,\n",
       "            -1.3477e-01, -3.9742e-01,  1.3810e-02, -3.3398e-01, -3.6209e-01,\n",
       "             1.3248e-01,  1.6886e-01, -1.8531e-01, -3.8371e-01,  1.8801e-02,\n",
       "            -1.9994e-01, -3.0880e-01,  1.2517e-02, -2.0239e-01,  1.6230e-01,\n",
       "             2.4838e-01, -8.8705e-02, -3.1792e-01, -8.2844e-02,  1.8304e-01,\n",
       "             1.3627e-02,  3.9061e-01,  2.9479e-01,  3.3925e-01, -1.7306e-01,\n",
       "             2.3058e-01,  5.1725e-01,  1.3698e-01, -1.5453e-01, -2.0692e-01,\n",
       "            -1.9697e-01, -1.2137e-01, -3.8195e-01,  4.9124e-02, -4.1451e-01,\n",
       "             8.1679e-02,  2.8973e-01, -2.7261e-01, -4.4936e-01, -1.4335e-01,\n",
       "            -4.3070e-02, -2.5650e-01,  3.6662e-02, -6.2565e-01,  5.5217e-02,\n",
       "             1.8752e-01,  1.5900e-01, -1.1616e-01,  3.3616e-02,  5.6017e-02,\n",
       "            -4.7733e-01, -3.2379e-01, -1.1198e-01,  9.9712e-02,  5.2879e-01,\n",
       "            -2.1608e-01,  1.6101e-01,  1.4822e-01, -3.3416e-01,  9.3358e-02,\n",
       "            -4.2184e-01, -8.5695e-01, -2.0860e-02,  4.4098e-01, -1.7683e-01,\n",
       "            -1.8076e-01,  4.7945e-01, -9.6586e-02,  3.4814e-01, -2.7700e-01,\n",
       "            -5.9087e-01,  4.1163e-01, -2.1052e-01,  3.1448e-02, -1.7481e-01,\n",
       "            -1.7251e-01,  2.7418e-01,  3.2821e-01,  4.7287e-02, -7.2491e-02,\n",
       "             2.0691e-02, -4.3333e-01,  5.9616e-02,  2.3931e-01, -1.8660e-01,\n",
       "             1.6619e-01,  3.2986e-01,  1.3384e-01, -1.1732e-01,  1.6410e-02,\n",
       "            -1.2507e-01,  3.4207e-01, -7.4478e-02, -1.9581e-02, -1.5302e-01,\n",
       "             3.3603e-01,  1.8281e-01, -5.7764e-01,  3.0133e-01,  1.5173e-01,\n",
       "             8.8531e-02, -5.1518e-01,  3.3948e-02, -3.2355e-01, -3.4246e-01,\n",
       "             3.6016e-01, -8.1342e-02,  1.0357e-01, -2.1854e-01,  4.2213e-01,\n",
       "             2.1262e-02, -1.3941e-01, -3.3355e-01, -3.0538e-01,  1.4167e-01,\n",
       "             1.0371e-01,  1.1692e-01,  1.2377e-01,  3.2975e-02, -3.6699e-02,\n",
       "             1.9479e-01, -1.1515e-01,  8.2592e-02,  4.3772e-02,  3.3073e-02,\n",
       "            -2.2682e-01,  2.3082e-02, -1.3581e-01,  3.4164e-01,  6.7992e-02,\n",
       "             2.1290e-01,  3.4018e-01,  3.7579e-01, -2.9707e-01,  3.5810e-01,\n",
       "             2.7875e-01,  7.1702e-02, -5.7956e-02, -1.6667e-01, -2.6008e-01,\n",
       "            -1.5194e-01,  7.0855e-02, -4.6853e-01,  5.4977e-02, -6.3873e-02,\n",
       "            -8.3459e-02,  2.5418e-01,  6.5605e-02, -2.2217e-01,  1.2459e-01,\n",
       "             7.1092e-01,  4.5569e-02,  2.8837e-01,  3.5217e-01, -3.8898e-01,\n",
       "            -9.1138e-02,  4.1101e-02, -3.6727e-01, -4.7959e-01,  1.0719e-02,\n",
       "            -1.8100e-01, -4.1106e-01, -4.0952e-01,  4.0352e-01, -3.4615e-01,\n",
       "             8.9625e-02,  4.8660e-01, -3.7300e-01,  1.2029e-01,  4.0850e-02,\n",
       "             6.5412e-01,  6.6806e-02, -1.1242e-01,  2.4641e-01, -1.6098e-01,\n",
       "             1.6804e-01, -2.5699e-01,  2.4018e-02, -2.8271e-01,  2.3548e-01,\n",
       "            -2.6504e-01, -1.9797e-01,  2.9482e-01, -6.7457e-01, -4.6599e-01,\n",
       "            -6.0777e-02,  8.2327e-02, -3.1137e-01,  3.9554e-01,  2.0304e-01,\n",
       "            -5.8125e-01, -3.5452e-01,  8.5831e-02, -1.0966e-01,  1.5342e-01,\n",
       "            -5.6261e-01,  3.7194e-01,  4.1345e-02,  3.1215e-01,  4.7430e-01,\n",
       "            -2.7476e-02, -3.5594e-01,  1.4945e-01,  3.6730e-02, -1.7261e-01,\n",
       "             3.2355e-01, -2.3028e-02,  1.2107e-01,  2.8872e-01,  2.5547e-01,\n",
       "            -2.9111e-02,  1.1114e-01, -5.2607e-01, -1.6112e-01,  2.6544e-01,\n",
       "             1.0366e-01, -6.1805e-02, -1.6193e-02,  1.5562e-01, -6.1260e-02,\n",
       "            -6.4967e-03, -3.1385e-01, -1.3024e-01, -3.4308e-02, -3.8559e-01,\n",
       "             2.7390e-01,  2.4352e-01, -3.6727e-02,  1.2060e-01,  3.7719e-01,\n",
       "            -4.5343e-02,  3.6990e-01, -2.1848e-01,  3.6237e-02, -1.3444e-01,\n",
       "            -6.7873e-01, -1.5004e-01,  1.1026e-01, -4.7492e-01,  1.8280e-01,\n",
       "             8.9889e-02,  5.9845e-03,  8.7400e-02]]),\n",
       "   tensor([[   29,    93, 20704, 49651, 28440,   434,  7583,  3295,   310,  5418,\n",
       "                0]]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1885.42it/s]\n"
     ]
    }
   ],
   "source": [
    "toy_data_preprocessed = preprocess(toy_data, r_tokenizer, g_tokenizer, mama_template, 2048 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "          187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  3689,\n",
       "           73,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "         1812,     0,   187])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data_preprocessed[\"input_ids_g\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nHow old is Minh?<|endoftext|>\\n<|assistant|>\\n36<|endoftext|>\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(toy_data_preprocessed[\"input_ids_g\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mama = mama.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutput(logits=tensor([[[ 13.1250,  -1.3906,  15.3125,  ...,  -0.9492,  -1.1953,  -1.1484],\n",
       "         [  8.3750, -10.6250,  12.7500,  ..., -10.0625, -10.5000,  -9.9375],\n",
       "         [ 17.2500,   0.4922,  19.3750,  ...,   0.7383,   0.1504,   0.7891],\n",
       "         ...,\n",
       "         [ 28.3750,   3.0312,  26.2500,  ...,   3.2812,   2.9531,   3.2969],\n",
       "         [ 24.2500,   1.1875,  26.8750,  ...,   0.9375,   0.6328,   1.1250],\n",
       "         [  9.5625, -20.2500,  12.6875,  ..., -20.5000, -20.2500, -20.2500]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mama.generator.forward(toy_data_preprocessed[\"input_ids_g\"][0].unsqueeze(0).cuda())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'divT.\\n        : question question.The\\ndiv\\n_\\n\\ndy are your??\\nThe\\ndiv\\nignment_\\n\\n.The\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(out.logits[0].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move embedded corpus to GPU\n",
    "embedded_corpus = [(r_emb.cuda(), g_emb.cuda()) for r_emb, g_emb in embedded_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = mama.forward(\n",
    "  query_r=toy_data_preprocessed[\"input_ids_r\"][0].unsqueeze(0).cuda(),\n",
    "  query_g=toy_data_preprocessed[\"input_ids_g\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutput(logits=tensor([[[ 12.9375,  -1.4219,  15.1875,  ...,  -0.8984,  -1.1953,  -1.1641],\n",
       "         [  8.1250, -10.8125,  12.5625,  ..., -10.2500, -10.6875, -10.1250],\n",
       "         [ 16.1250,   0.7695,  20.8750,  ...,   1.5703,   0.9414,   1.5469],\n",
       "         ...,\n",
       "         [ 28.3750,   3.0000,  26.1250,  ...,   3.3438,   2.9688,   3.3438],\n",
       "         [ 24.3750,   1.3281,  26.8750,  ...,   1.0312,   0.6992,   1.2656],\n",
       "         [  9.5000, -20.7500,  12.6250,  ..., -21.0000, -20.7500, -20.6250]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'divT_\\nify< a years old.\\n is in a. Heonica is a English in theate.Thediv>|\\n a future of will us to build the behavior. the speed scale. a to understanding the nextizational Intelligence. to is is.\\nThehtml>|\\n, I name is <... I am a years old and I am in a, I am a artist in the.Thediv>.\\n<: following questions.The\\ndiv\\n_\\n\\ndy are yourerv?\\nThe\\ndiv\\nignment_\\n\\n.The\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(out2.logits[0].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'Answer the given question'},\n",
       "  {'role': 'user', 'content': 'How old is Minh?'},\n",
       "  {'role': 'assistant', 'content': '36'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = mama.retrieve(\n",
    "  query_r=toy_data_preprocessed[\"input_ids_r\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.4365], device='cuda:0', grad_fn=<SumBackward1>), 0),\n",
       " (tensor([0.3696], device='cuda:0', grad_fn=<SumBackward1>), 2),\n",
       " (tensor([0.3556], device='cuda:0', grad_fn=<SumBackward1>), 8)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Minh is 36 years old. He lives in Los Angeles. Minh is an expert in Karate'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mama(\n",
       "  (retriever): MonarchI2i(\n",
       "    (model): BasicModel(\n",
       "      (model): HuggingFaceModel(\n",
       "        (model): BertForMaskedLM(\n",
       "          (bert): BertModel(\n",
       "            (embeddings): BertEmbeddings(\n",
       "              (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "              (token_type_embeddings): Embedding(2, 768)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (encoder): BertEncoder(\n",
       "              (layer): ModuleList(\n",
       "                (0-11): 12 x BertLayer(\n",
       "                  (attention): MonarchMixerSequenceMixing(\n",
       "                    (filter_fn): HyenaFilter(\n",
       "                      (dropout): Dropout(p=0.2, inplace=False)\n",
       "                      (pos_emb): PositionalEmbedding()\n",
       "                      (implicit_filter): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (implicit_filter_rev): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (modulation): ExponentialModulation()\n",
       "                    )\n",
       "                    (filter_fn2): HyenaFilter(\n",
       "                      (dropout): Dropout(p=0.2, inplace=False)\n",
       "                      (pos_emb): PositionalEmbedding()\n",
       "                      (implicit_filter): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (implicit_filter_rev): Sequential(\n",
       "                        (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                        (1): Sin()\n",
       "                        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (3): Sin()\n",
       "                        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                        (5): Sin()\n",
       "                        (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (modulation): ExponentialModulation()\n",
       "                    )\n",
       "                    (in_linear): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (act): Identity()\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (short_filter): Conv1d(2304, 2304, kernel_size=(3,), stride=(1,), padding=(2,), groups=2304)\n",
       "                  )\n",
       "                  (mlp): BertGatedLinearUnitMLP(\n",
       "                    (gated_layers): BlockdiagLinear()\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (wo): BlockdiagLinear()\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (cls): BertOnlyMLMHead(\n",
       "            (predictions): BertLMPredictionHead(\n",
       "              (transform): BertPredictionHeadTransform(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (transform_act_fn): GELUActivation()\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (decoder): Linear(in_features=768, out_features=30528, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dot_product): DotProduct()\n",
       "  )\n",
       "  (generator): MambaLMHeadModel(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(50280, 2560)\n",
       "      (layers): ModuleList(\n",
       "        (0-63): 64 x Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "            (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "            (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       "  )\n",
       "  (cos): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mama.train()\n",
    "mama.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.Adam(mama.generator.parameters(), lr=5e-5)\n",
    "optimizer2 = optim.Adam(mama.retriever.parameters(), lr=3e-6, weight_decay=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_r': [tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2129,  2214,\n",
       "           2003, 19538,  1029,  3353,  1024,  4029]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2073,  2001,\n",
       "           6520, 23422,  2141,  1029,  3353,  1024,  4880,  2237]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2054,  2003,\n",
       "           8472, 14545,  1005,  1055,  2197,  2171,  1029,  3353,  1024, 16031,\n",
       "           5910]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2040,  2003,\n",
       "           3080,  1010,  8472, 14545,  2030, 19538,  1029,  3353,  1024, 19538]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2054,  2003,\n",
       "           8472, 14545,  1005,  1055,  5440,  3609,  1029,  3353,  1024,  2630]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2073,  2515,\n",
       "           8472, 14545,  2444,  1029,  3353,  1024,  2047,  2259]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2040,  2003,\n",
       "           3080,  1010, 19538,  2030,  8472, 14545,  1029,  3353,  1024, 19538]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2054,  2003,\n",
       "          19538,  2019,  6739,  1999,  1029,  3353,  1024, 19538,  2003,  2019,\n",
       "           6739,  1999, 16894]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2073,  2515,\n",
       "          19538,  2444,  1029,  3353,  1024, 19538,  3268,  1999,  3050,  3349]),\n",
       "  tensor([ 2291,  1024,  3437,  1996,  2445,  3160,  5310,  1024,  2129,  2214,\n",
       "           2003,  6520, 23422,  1029,  3353,  1024,  3486])],\n",
       " 'input_ids_g': [tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  3689,\n",
       "             73,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "           1812,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  7161,   369, 42125,  5686,\n",
       "             32,     0,   187,    29,    93,   515,  5567, 49651,   187,    36,\n",
       "           2259, 10079,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  1276,   310, 34780,  8895,\n",
       "            434,  1390,  1416,    32,     0,   187,    29,    93,   515,  5567,\n",
       "          49651,   187,    40, 28134,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
       "          34780,  8895,   390,  3689,    73,    32,     0,   187,    29,    93,\n",
       "            515,  5567, 49651,   187, 10292,    73,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  1276,   310, 34780,  8895,\n",
       "            434,  7583,  3295,    32,     0,   187,    29,    93,   515,  5567,\n",
       "          49651,   187, 22036,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  7161,  1057, 34780,  8895,\n",
       "           3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "           4257,  2816,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
       "           3689,    73,   390, 34780,  8895,    32,     0,   187,    29,    93,\n",
       "            515,  5567, 49651,   187, 10292,    73,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  1276,   310,  3689,    73,\n",
       "            271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
       "          49651,   187, 10292,    73,   310,   271,  6485,   275, 12604,   366,\n",
       "              0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  7161,  1057,  3689,    73,\n",
       "           3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
       "          10292,    73,  4852,   275,  8742,  9757,     0,   187]),\n",
       "  tensor([   29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
       "            187,    29,    93,  4537, 49651,   187,  2347,  1711,   310, 42125,\n",
       "             32,     0,   187,    29,    93,   515,  5567, 49651,   187,  1671,\n",
       "              0,   187])],\n",
       " 'label_ids': [tensor([   29,    93,   515,  5567, 49651,   187,  1812,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187,    36,  2259, 10079,     0,\n",
       "            187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187,    40, 28134,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187, 10292,    73,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187, 22036,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187,  4257,  2816,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187, 10292,    73,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187, 10292,    73,   310,   271,\n",
       "           6485,   275, 12604,   366,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187, 10292,    73,  4852,   275,\n",
       "           8742,  9757,     0,   187]),\n",
       "  tensor([   29,    93,   515,  5567, 49651,   187,  1671,     0,   187])]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = torch.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k\n",
      "[(tensor([0.4068], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3816], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3523], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "divT_\n",
      "< < stack will us to build the memory in the level scale is a to understanding the nextizational Intelligence. to is is.\n",
      "Thehtml>|\n",
      "se's a years old. She is in a. Heonica is a artist in theate.Thediv>|\n",
      "\n",
      " the to make up alive\n",
      " <areth Rff\n",
      " the audience. the could a democracy freedom's ability to keep revenue.\n",
      "Thediv>.\n",
      "<: following question.The\n",
      "div\n",
      "_\n",
      "\n",
      " is <? you or or K??\n",
      "The\n",
      "div\n",
      "ignment.\n",
      "\n",
      "istry-The\n",
      "\n",
      "decoded_labels\n",
      "|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Kaneema or Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 1), (None, 3)]\n",
      "decoded_logits2\n",
      "divT_\n",
      " memory memory in to create the memory memory to ask the project.Thediv>|\n",
      " the- theine a in the, He was a years old. He is a English in the.Thediv>|\n",
      " isicula a, dis therition. the ranks.Thediv>.\n",
      "<: following question.The\n",
      "div\n",
      "_\n",
      "\n",
      " is < than you or or K??\n",
      "The\n",
      "div\n",
      "ignment.\n",
      "\n",
      "istry-The\n",
      "\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,   281,\n",
      "         26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,   281,\n",
      "          3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,  4583,\n",
      "            15,     0,    29,    93, 20704, 49651, 10754, 43510,   310,  9135,\n",
      "          1107,  1711,    15,   754,  4852,   275,  4693,    15,  7188, 43510,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 20704,\n",
      "         49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,\n",
      "          1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,\n",
      "          3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7883,   310,  5662,    13, 34780,\n",
      "          8895,   390,  3689,    73,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 10292,    73,     0,   187]], device='cuda:0')\n",
      "5.53125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-28.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-28.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "8\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5218, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "5.53125\n",
      "KL loss\n",
      "5.53125\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.5131], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4133], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3599], device='cuda:0', grad_fn=<SumBackward1>), 10)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 141, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>\n",
      " a future to allows you to simulate the dynamics at the computational level is key to understanding AI AIizational AI. to is of.\n",
      "The|data|>\n",
      "onica is a years old.\n",
      " lives in the. Veronica is a expert in theate.The|data|>\n",
      " theically,, the(xmax(log)), the so operations operations in is more. more unstable.\n",
      " is is the alternative method that avoid the soft of is of.\n",
      "The|data|>\n",
      "< the question question.The<|user|>\n",
      "< is theh?h in?\n",
      "The<|useristant|>\n",
      "<h: a expert in theate.The<\n",
      "decoded_labels\n",
      "|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Minh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 2), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>\n",
      " first thing is to create the problem data to talk the project.The|data|>\n",
      ", I name is <... I am a years old and I live in the, I am a expert in the.The|data|>\n",
      " of Thrones is a fantasy novel television series created for David Benioff and D. B. Weiss. HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom. FilThe|data|>\n",
      "< the question question.The<|user|>\n",
      "< is theh?h in?\n",
      "The<|useristant|>\n",
      "<h: a expert in theate.The<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 141])\n",
      "tensor([[   93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,   281,\n",
      "         26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,   281,\n",
      "          3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,  4583,\n",
      "            15,     0,    29,    93, 20704, 49651, 10754, 43510,   310,  9135,\n",
      "          1107,  1711,    15,   754,  4852,   275,  4693,    15,  7188, 43510,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 20704,\n",
      "         49651,  6175, 11076,  1037,  6425,   281,  2412,     9,  5530,  4090,\n",
      "             9,    89,  9679,  2509,   841,   767,  5871, 11794,   310, 17357,\n",
      "           285, 27184, 17631,    15,   831,  1159,  4648,   271,  5795, 15895,\n",
      "           281, 11897,   253,  3453,   285, 11786,  9113,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310,  3689,    73,   271,\n",
      "          6485,   275,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 10292,    73,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "           187]], device='cuda:0')\n",
      "2.765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-33.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-33.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "8\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "2.765625\n",
      "KL loss\n",
      "2.765625\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.4193], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3709], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3705], device='cuda:0', grad_fn=<SumBackward1>), 17)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>\n",
      "onica is a years old. He lives in London. Veronica is an expert in Karate<|endoftext|>The|memory|>\n",
      ", I name is Alex and.. I am a years old and I live in London. I am a expert in Kar.The|memory|>\n",
      " am been data with 10. a length size of aboutKB bytesytes..\n",
      "The|memory|>\n",
      "< the given question\n",
      "The<|memory|>\n",
      "\n",
      " is theema's favorite name?<|endoftext|>The<|memoryistant|>\n",
      "\n",
      "ina isThe<\n",
      "decoded_labels\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>I have test database of documents with average document size is 32942 Bytes only.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 11), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>\n",
      " the- the Graham awarded. the. He is a years old. He is a expert in Kar.The|memory|>\n",
      " are use the memory memory module to serial printprint a data object.\n",
      "\n",
      "The|memory|>\n",
      "able of taken in you you want not, is a place to\n",
      " fooduits are amazing. the grav jam.\n",
      " sure to try the of start. of you of go there.The|memory|>\n",
      "< the given question\n",
      "The<|memory|>\n",
      "\n",
      " is theema's favorite name?<|endoftext|>The<|memoryistant|>\n",
      "\n",
      "ina isThe<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,    15,\n",
      "           754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  9915,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,    42,\n",
      "           452,  1071,  5447,   273,  7177,   342,  3388,  3389,  1979,   310,\n",
      "         35453,  2945,   378, 12742,   760,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 34780,  8895,   434,  1390,  1416,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    40,\n",
      "         28134,     0,   187]], device='cuda:0')\n",
      "2.5\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-27.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-28.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5514, 0.4486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5625, 0.4375]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "2.5\n",
      "KL loss\n",
      "2.5\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.4264], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4040], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3367], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>\n",
      "onica is a years old. Ver lives in London. Veronica is an expert in Karate<|endoftext|><|memory|><|endoftext|> a technology that allows you to simulate organizational dynamics at the computational level is key to training organizational Organizational AI. this vision overall.<|endoftext|><|memory|><|endoftext|> first step in to create the data data to interview the project.<|memory|>\n",
      "< the given question<|endoftext|><<|user|>\n",
      "<|endoftext|> is the, Minh or Minema?\n",
      "<<|useristant|><|endoftext|><|endoftext|>h<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Minh or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 0), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>\n",
      " first Vegas algorithm is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is commonly, is 3 4 miles2 miles (6.8 km) in and located is immediately to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.\n",
      "<|memory|><|endoftext|>onica is a years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|><|endoftext|> can a, Iing is be a. the. of\n",
      "<|memory|>\n",
      "< the given question<|endoftext|>\n",
      "<|user|>\n",
      "<|endoftext|> is the, Minh or Minema?\n",
      "\n",
      "<|useristant|><|endoftext|><|endoftext|>h<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,    15,\n",
      "           754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 20704,\n",
      "         49651,   510,   806,  3213,   310,   281,  4271,   253,   987,   952,\n",
      "           281,  1421,   253,  1818,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13,  3689,    73,   390, 34780,  8895,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 10292,\n",
      "            73,     0,   187]], device='cuda:0')\n",
      "1.1796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5147, 0.4853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.1796875\n",
      "KL loss\n",
      "1.1796875\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.4070], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3908], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3364], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>\n",
      ", my name is John.umbs<|endoftext|><|endoftext|> live 42 years old. I live in London.<|endoftext|> am an expert in Javascript<|endoftext|><|system|>\n",
      "onica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|system|>\n",
      " the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "< to is Minh?\n",
      "<<|assistant|>\n",
      "Min years<<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "36<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 13), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>\n",
      " is a color is blue<|endoftext|><|system|>\n",
      " Vegas isillionuit\n",
      " Gravy<|endoftext|><|endoftext|> cup<|endoftext|>atlet · ·\n",
      "Photo)\n",
      " 24.<|endoftext|> ·$. $$$ · 2.<|endoftext|>.<|endoftext|>ikes. (859).9). Open Now. American.<|endoftext|>.ys.. (<|system|>\n",
      " first are in in the database called \".<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "< to is Minh?\n",
      "<<|assistant|>\n",
      "Min years<<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275,  7785,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310,  3689,    73,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,  1812,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.81640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-19.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-19.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5919, 0.4081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.81640625\n",
      "KL loss\n",
      "0.81640625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.4451], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3805], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3555], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 174, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>\n",
      ", my name is Joe Gumbs. I live 36 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>\n",
      " of Thrones is an fantasy drama television series created for David Benioff and D. B. Weiss. HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones.<|endoftext|> show was both produced and filmed in Belfast and elsewhere in the United Kingdom. Fil<|memory|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "Min can Minh live?\n",
      "<<|assistant|>\n",
      "Minh<|endoftext|> in London Angeles.<<\n",
      "decoded_labels\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Minh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh lives in Los Angeles<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 15), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Ver first Vegas Raiders is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 3 4 miles2 miles (6.7 km) in. located is immediately to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>\n",
      "land of small. you you are not, is the place to<|endoftext|> fooduits are huge. the grav sausage.\n",
      " sure you get the of start. of you of go there.<|memory|>\n",
      " are help the same programming module to convert printprint JSON output output.<|endoftext|><|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "Min can Minh live?\n",
      "<<|assistant|>\n",
      "Minh<|endoftext|> in London Angeles.<<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 174])\n",
      "tensor([[   93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,    15,\n",
      "           754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  9915,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18237,\n",
      "           273,   596, 22334,   310,   247, 16879, 14562,  7315,  2962,  3562,\n",
      "           407,  5119,  6029,   900,   567,   285,   399,    15,   378,    15,\n",
      "         34167,   323, 41069,    15,   733,   310,   271, 15644,   273,   329,\n",
      "         16865,   273, 22078,   285,  8726,    13,  6086,   416,    15,   416,\n",
      "            15,  8698,   434,  2962,   273, 16879, 19204,    13,   253,   806,\n",
      "           273,   534,   310,   329, 10850,   273,   596, 22334,    15,   380,\n",
      "           921,   369,  1097,  4197,   285, 32325,   275, 44867,   285, 11358,\n",
      "           275,   253,  1986, 11491,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7161,  1057,  3689,    73,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 10292,    73,  4852,   275,\n",
      "          8742,  9757,     0,   187]], device='cuda:0')\n",
      "0.5546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-19.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-19.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5831, 0.4169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5625, 0.4375]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5546875\n",
      "KL loss\n",
      "0.5546875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.4650], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3605], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3353], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 159, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ver G a color is blue<|endoftext|><|memory|>Ver the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Ver of Thrones is an fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom,<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "Min is Minema's last color?<|endoftext|><<|assistant|>\n",
      "Min is<<\n",
      "decoded_labels\n",
      "|memory|>Joe's favorite color is Black<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 19), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Ver isableula the and dis therition. the team.<|memory|>Ver first are available in the database called documents<|endoftext|><|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Ver am a database with documents with average document size is 142 Bytes..<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|><<|ass|>\n",
      "Min is Minema's last color?<|endoftext|><<|assistant|>\n",
      "Min is<<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 159])\n",
      "tensor([[   93, 20704, 49651, 28440,   434,  7583,  3295,   310,  5418,     0,\n",
      "            29,    93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,\n",
      "           281, 26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,\n",
      "           281,  3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,\n",
      "          4583,    15,     0,    29,    93, 20704, 49651, 18237,   273,   596,\n",
      "         22334,   310,   247, 16879, 14562,  7315,  2962,  3562,   407,  5119,\n",
      "          6029,   900,   567,   285,   399,    15,   378,    15, 34167,   323,\n",
      "         41069,    15,   733,   310,   271, 15644,   273,   329, 16865,   273,\n",
      "         22078,   285,  8726,    13,  6086,   416,    15,   416,    15,  8698,\n",
      "           434,  2962,   273, 16879, 19204,    13,   253,   806,   273,   534,\n",
      "           310,   329, 10850,   273,   596, 22334,    15,   380,   921,   369,\n",
      "          1097,  4197,   285, 32325,   275, 44867,   285, 11358,   275,   253,\n",
      "          1986, 11491,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          1276,   310, 34780,  8895,   434,  7583,  3295,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 22036,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.5546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-14.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-14.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5964, 0.4036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5546875\n",
      "KL loss\n",
      "0.5546875\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.3902], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3783], device='cuda:0', grad_fn=<SumBackward1>), 9), (tensor([0.3741], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 170, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ver, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Hello of Thrones is an fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast. elsewhere in the United Kingdom.<|endoftext|><|memory|>\n",
      "onica is 58 years old. He lives in Paris. Veronica is an expert in Karate<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|><<|user|>\n",
      "Min is Min born?\n",
      "<<|useristant|>\n",
      "Minele<|endoftext|><|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cape Town<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 13), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Ver, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Hello Vegas isillionuit is Gravy is<|endoftext|>\n",
      "<|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>Photo)<|endoftext|> 24.<|endoftext|> ·$. $$$<|endoftext|> 2.<|endoftext|>.<|endoftext|>ikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ys.. (<|memory|>\n",
      " this, the the changes to are allowed in<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|><<|user|>\n",
      "Min is Min born?\n",
      "<<|useristant|>\n",
      "Minele<|endoftext|><|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 170])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275,  7785,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,   247,\n",
      "         16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,   567,\n",
      "           285,   399,    15,   378,    15, 34167,   323, 41069,    15,   733,\n",
      "           310,   271, 15644,   273,   329, 16865,   273, 22078,   285,  8726,\n",
      "            13,  6086,   416,    15,   416,    15,  8698,   434,  2962,   273,\n",
      "         16879, 19204,    13,   253,   806,   273,   534,   310,   329, 10850,\n",
      "           273,   596, 22334,    15,   380,   921,   369,  1097,  4197,   285,\n",
      "         32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,    15,\n",
      "             0,    29,    93, 20704, 49651, 10754, 43510,   310,  9135,  1107,\n",
      "          1711,    15,   754,  4852,   275,  4693,    15,  7188, 43510,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7161,   369, 42125,  5686,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,    36,  2259, 10079,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-18.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-18.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5392, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.453125\n",
      "KL loss\n",
      "0.453125\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.4127], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4087], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3688], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|><<|user|>\n",
      "What old is Min<|endoftext|><|endoftext|><<|useristant|>\n",
      "\n",
      "<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Veronica is 58 years old. He lives in London. Veronica is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "35<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 4), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Ver are a,<|endoftext|>ing is be a<|endoftext|> the number of<|endoftext|><|system|>Helloter truth side is that is is that opportunity.<|system|>\n",
      " Vegas isillionuit is Gravy is<|endoftext|>\n",
      "<|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>Photo)<|endoftext|> 24.<|endoftext|> ·$. $$$<|endoftext|> 2.<|endoftext|>.<|endoftext|>ikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ys.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Min<|endoftext|><|endoftext|><<|useristant|>\n",
      "\n",
      "<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 10754, 43510,   310,  9135,  1107,  1711,    15,\n",
      "           754,  4852,   275,  4693,    15,  7188, 43510,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  9915,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310, 42125,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  1671,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.35546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5433, 0.4567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4844, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.35546875\n",
      "KL loss\n",
      "0.35546875\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.4573], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4297], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3988], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 179, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ver is ability of generate democracy alive<|endoftext|> Gina Neff<|endoftext|> the BBC that AI is damaging media organisation's ability to make profits.<|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|memory|>Hello of Thrones is an fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What is Kaneema live?<|endoftext|><<|assistant|>\n",
      "What York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 14), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Ver the- the Graham 58 in London. He is 58 years old. He lives an expert in Kar<|endoftext|>\n",
      "|memory|>Hello first Vegas Strip is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is widely, is located 4.2 miles (6.7 km) in. located is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Hello is ability of save democracy alive<|endoftext|> BBCina Neff<|endoftext|> the BBC that AI is damaging media organisations's ability to make profits<|endoftext|><|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What is Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "What York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 179])\n",
      "tensor([[   93, 20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,\n",
      "           428,   443,  1758,  3532,   567,  2183,   253, 15501,   326, 14980,\n",
      "           310, 24038,  3420, 19156,   434,  3745,   281,  6635, 16256,    15,\n",
      "             0,    29,    93, 20704, 49651, 38453,   253,  4302,   326,  4483,\n",
      "           368,   281, 26065, 26921,  8062,   387,   253, 15180,  1268,   310,\n",
      "          2234,   281,  3733,   253, 10164,   478,  1050, 14980,   285,   436,\n",
      "          8113,  4583,    15,     0,    29,    93, 20704, 49651, 18237,   273,\n",
      "           596, 22334,   310,   247, 16879, 14562,  7315,  2962,  3562,   407,\n",
      "          5119,  6029,   900,   567,   285,   399,    15,   378,    15, 34167,\n",
      "           323, 41069,    15,   733,   310,   271, 15644,   273,   329, 16865,\n",
      "           273, 22078,   285,  8726,    13,  6086,   416,    15,   416,    15,\n",
      "          8698,   434,  2962,   273, 16879, 19204,    13,   253,   806,   273,\n",
      "           534,   310,   329, 10850,   273,   596, 22334,    15,   380,   921,\n",
      "           369,  1097,  4197,   285, 32325,   275, 44867,   285, 11358,   275,\n",
      "           253,  1986, 11491,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 34780,  8895,  3153,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,  4257,  2816,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.376953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "7\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5192, 0.4808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.376953125\n",
      "KL loss\n",
      "0.376953125\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1805.94it/s]\n",
      "  3%|▎         | 1/30 [01:07<32:50, 67.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5825], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4791], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4115], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ver, my name is Joe Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|>\n",
      "|memory|>Buildingice is Adventures color is Black<|endoftext|>\n",
      "|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What was Kane live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Whatape<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Black<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 14), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Ver theically equivalent to the(softmax(x)), this these two operations separately is numerically and numerically unstable. This function uses an alternative formulation and compute the output gradient gradient correctly.<|endoftext|>\n",
      "|memory|>Building first Vegas Strip is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is widely, is 3 4.2 miles (6.7 km) in. located is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as Las Vegas.<|endoftext|>\n",
      "|memory|>Buildingland of small<|endoftext|> you you are not, is the place to<|endoftext|> fooduits are huge. the grav sausage.<|endoftext|> sure you get the of start. of you of go there.\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What was Kane live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Whatape<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2422,   547,   434,  7583,  3295,   310,\n",
      "          5418,     0,    29,    93, 20704, 49651, 38453,   253,  4302,   326,\n",
      "          4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,  1268,\n",
      "           310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,   285,\n",
      "           436,  8113,  4583,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 16922,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    36, 22466,     0,   187]],\n",
      "       device='cuda:0')\n",
      "1.0859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-13.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-13.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5381, 0.4619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.0859375\n",
      "KL loss\n",
      "1.0859375\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.5200], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4564], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4345], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Building, my name is Joe Gumbs. I am 36 years old. I live in Cairo. I am an expert in Javascript<|endoftext|>\n",
      "|memory|>Building is Reuters 58 years old. He lives in London. Thomson is an expert in Karate<|endoftext|>\n",
      "|memory|>Building the- the and named in London<|endoftext|> He lives an years old. He lives an expert in Kar<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How is older, Kane or Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "What is<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Thomson or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 21), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Building are 58<|endoftext|><|endoftext|>ing is be a<|endoftext|> the document of<|endoftext|>\n",
      "|memory|>Buildingice is favorite color is Black<|endoftext|>\n",
      "|memory|>Building are't the technology programming module to convert printprint the output output<|endoftext|><|endoftext|>\n",
      "\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How is older, Kane or Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "Whatpson<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,\n",
      "          1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "         41963,   390, 16922,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 42299,  1665,     0,   187]], device='cuda:0')\n",
      "1.71875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-16.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-16.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4827, 0.5173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.71875\n",
      "KL loss\n",
      "1.71875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6788], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5589], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3886], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Buildingice is favorite color is Black<|endoftext|>\n",
      "|memory|>Building, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|>\n",
      "|memory|>Building are't the technology programming module to simulate printprint the output data<|endoftext|><|endoftext|>\n",
      "\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How is Kane's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "What<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice's favorite color is Black<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 7), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Building the- the was awarded in London<|endoftext|> He is an years old. He is an expert in Kar<|endoftext|>\n",
      "|memory|>Building hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|memory|>Building are 58,<|endoftext|> is is be a<|endoftext|> the number of<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How is Kane's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "How<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   434,  7583,  3295,   310,  5418,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         16922,   443, 28134,    15,   309,   717,  4567,  1107,  1711,    15,\n",
      "           309,  3153,   275, 37068,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,  1231,   476,   897,   253,\n",
      "         13814, 14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,\n",
      "            15,   209,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 16922,   434,  7583,  3295,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 15383,     0,   187]], device='cuda:0')\n",
      "1.0546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5403, 0.4597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4844, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.0546875\n",
      "KL loss\n",
      "1.0546875\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6944], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5942], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3911], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 58 years old. He lives in London. Thomson is an expert in Javascriptate<|endoftext|>\n",
      "|memory|>Hello the, the was born in London. He is an years old.<|endoftext|> is an expert in Kar<|endoftext|>\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is the's expert in Kar<|endoftext|>\n",
      "<|assistant|>\n",
      "Howson<|endoftext|> 58 expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 14), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Hello this, the the changes to are stored in<|endoftext|>\n",
      "|system|>Hello first Vegas Strip is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is widely, is located 4.2 miles (6.7 km) in and located is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|system|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is the's expert in Kar<|endoftext|>\n",
      "<|assistant|>\n",
      "Howson<|endoftext|> 58 expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,  1107,\n",
      "          1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310, 41963,   271,\n",
      "          6485,   275,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 42299,  1665,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "           187]], device='cuda:0')\n",
      "1.015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-16.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-16.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4793, 0.5207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.015625\n",
      "KL loss\n",
      "1.015625\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6457], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6049], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3708], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 58 years old. He lives in London. Thomson is an expert in Karate<|endoftext|><|system|>Hello the, the was born in London. He is an years old. Thomson is an expert in Javascript<|endoftext|><|system|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does the born?<|endoftext|><<|useristant|>\n",
      "Whatlin<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Thomson born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 6), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Hello are simulate the same json module to convert-print the JSON data<|endoftext|><|endoftext|><|endoftext|><|system|>Hello the given technology<|endoftext|> answer the first<|endoftext|> the document<|endoftext|><|endoftext|> newsletter should be the-2 paragraphs for the of<|endoftext|> the outline outline and by a bullet to the relevant resource.<|endoftext|> not use to write the Docs to other to draft this task<|endoftext|><|endoftext|><|system|>Hello isabler the and division therition. the team.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does the born?<|endoftext|><<|useristant|>\n",
      "Whatlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,  1107,\n",
      "          1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,   369, 41963,  5686,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 23666,\n",
      "          3642,     0,   187]], device='cuda:0')\n",
      "0.79296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4940, 0.5060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4844, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.79296875\n",
      "KL loss\n",
      "0.79296875\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.5924], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5611], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4425], device='cuda:0', grad_fn=<SumBackward1>), 20)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 99, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 58 years old. He lives in London. Thomson is an expert in Karate<|endoftext|><|memory|>Hello the, Thomson was born in Paris. Thomson is an years old. Thomson is an expert in Python<|endoftext|><|system|>Hello are given<|endoftext|><|endoftext|> is is be too<|endoftext|> the number of<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is G?<|endoftext|><<|useristant|>\n",
      "What<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>You are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "53<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 3), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first in stored in the document called documents<|endoftext|><|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>Hello isabler the and division therition. the team.<|system|>Hello firstdown the tasks is up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is G?<|endoftext|><<|useristant|>\n",
      "Where<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 99])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,  1107,\n",
      "          1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651,  1394,   403,   987,    15, 30123,  3389,   778,\n",
      "          2489,  1781,   407,  1781,  1618,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  2347,  1711,   310, 41963,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,  3357,     0,   187]],\n",
      "       device='cuda:0')\n",
      "1.3671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4905, 0.5095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.3671875\n",
      "KL loss\n",
      "1.3671875\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7286], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6198], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4153], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Verson is 58 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>Hello 1989, Thomson was born in Berlin. Thomson is an years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Kar<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|><<|useristant|>\n",
      "Whereson is in Paris<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 12), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Verz isetsuit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|>..<|endoftext|> ·<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Bikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (<|system|>Game the of Earth's and the favorite video sources sources sites.<|system|>Game hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|><<|useristant|>\n",
      "Whereson is in Paris<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,  1107,\n",
      "          1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057, 41963,  3153,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 42299,\n",
      "          1665,  4852,   275, 12911,     0,   187]], device='cuda:0')\n",
      "0.427734375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-11.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5409, 0.4591]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.4844]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.427734375\n",
      "KL loss\n",
      "0.427734375\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6186], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5268], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3921], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 98, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Thomice's favorite color is Black<|endoftext|><|memory|>Thom are use the Python json module to pretty-print the JSON data.<|endoftext|><|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is the an favorite name?<|endoftext|><<|assistant|>\n",
      "Thomumbs is<<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Black<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 19), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Thom am a database with documents with average document size is 142 Bytes only.<|endoftext|><|memory|>Thom first are stored in the document called documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Thom the of 3's and the favorite video sources sources sites.<|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is the an favorite name?<|endoftext|><<|assistant|>\n",
      "Thomumbs is<<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 98])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2422,   547,   434,  7583,  3295,   310,\n",
      "          5418,     0,    29,    93, 20704, 49651,  1231,   476,   897,   253,\n",
      "         13814, 14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,\n",
      "            15,   209,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 16922,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.57421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5291, 0.4709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.57421875\n",
      "KL loss\n",
      "0.57421875\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6088], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5283], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3860], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>Thom 1989 Thomson Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>Thom, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Python<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "Where old is Django?<|endoftext|><<|assistant|>\n",
      "Thom<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "21<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 19), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Thom the of Earth<|endoftext|> to the favorite mobile sources sources sites.<|memory|>Thom first are stored in the document called documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>Thom theically equivalent to the(softmax(x)), this these two operations separately is numerically and numerically unstable.<|endoftext|> function uses alternative alternative formulation to compute the output gradient gradient correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "Where old is Django?<|endoftext|><<|assistant|>\n",
      "Thom<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,  1107,\n",
      "          1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310, 41963,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  1797,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.29296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4962, 0.5038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.29296875\n",
      "KL loss\n",
      "0.29296875\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5343], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4726], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4140], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Onson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "Where is older, Thomson or Alice?<|endoftext|><<|assistant|>\n",
      "Thomson is<<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 53 years old. He lives in Berlin. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Berlin. He is 21 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 3), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Thomz isetsuit is Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|>..<|endoftext|> ·<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Gikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (<|system|>On isrenchr the and is therition. the team.<|system|>On are right. Theing is be large if large JSON.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "Where is older, Thomson or Alice?<|endoftext|><<|assistant|>\n",
      "Thomson is<<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  4567,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 42299,  1665,   310,  8676,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 12911,    15,   754,   310,  3127,\n",
      "          1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "         16922,   390, 41963,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 42299,  1665,     0,   187]], device='cuda:0')\n",
      "0.267578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5049, 0.4951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4531, 0.5469]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.267578125\n",
      "KL loss\n",
      "0.267578125\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1713.92it/s]\n",
      "  7%|▋         | 2/30 [02:11<30:26, 65.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.5444], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5010], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4354], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomachel is 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|><|memory|>On, my name is Aliceumbs..umbs. I am 32 years old. I live in Cairo. I am an expert in Python<|endoftext|><|system|>Onumbs is is favorite color is Black<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Thomson or Thomsonumbsema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomio<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 18 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Rachel or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 1), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Thom first Vegas Convention is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is widely, is 3 4.2 miles (6.7 km) in and located is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|system|>On 1989, Thomson was born in Berlin Town. He is 21 years old. He is an expert in Python<|endoftext|><|system|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Thomson or Thomsonumbsema?<|endoftext|><<|assistant|>\n",
      "Thomio<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  1384,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,   443,  1351, 15897,   443, 28134,    15,   309,\n",
      "           717,  1283,  1107,  1711,    15,   309,  3153,   275, 12911,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,    40,  1351, 15897,   434,  7583,  3295,   310, 25056,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "         22739,   390,   443,  1351, 15897,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    51, 17470,     0,   187]],\n",
      "       device='cuda:0')\n",
      "1.9296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-12.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-12.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5083, 0.4917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4844, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.9296875\n",
      "KL loss\n",
      "1.9296875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.7275], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4799], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3285], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomumbs is is favorite color is Black<|endoftext|>\n",
      "|system|>On, my name is Aliceumbsesh.umbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>On can use the Python json module to pretty-print the JSON data.<|endoftext|><|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Thomsonumbsema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomellow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 18 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Yellow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 8), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Thom the of Earth<|endoftext|> to the favorite mobile sources sources sites.\n",
      "|system|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>On, my name is Aliceumbsesh.umbs. I am 32 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Thomsonumbsema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomellow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   434,  7583,  3295,   310,\n",
      "         25056,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,   443,  1351, 15897,   443, 28134,    15,   309,   717,  1283,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  1231,\n",
      "           476,   897,   253, 13814, 14113,  6333,   281,  3965,    14,  3845,\n",
      "           253, 13922,   941,    15,   209,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,   443,  1351, 15897,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    58,\n",
      "          3827,     0,   187]], device='cuda:0')\n",
      "1.25\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5398, 0.4602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.25\n",
      "KL loss\n",
      "1.25\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6824], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5490], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4377], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 166, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom 1989, Thomson was born in Berlin Town. He is 21 years old. He is an expert in Python<|endoftext|>\n",
      "|system|>On is is 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|>\n",
      "|memory|>On of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It was a adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and surrounding and the United Kingdom.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Thomson born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomairo Town<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Adam was born in Cape Town. He is 56 years old. Adam is an expert in Python<|endoftext|><|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Adam born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cape Town<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 10), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Thom first of the tasks is up<|endoftext|> you employee is added to the list.<|endoftext|>\n",
      "|system|>On theically equivalent to the(softmax(x)), this these two operations separately is slow and numerically unstable.<|endoftext|> function uses alternative alternative formulation to compute the output gradient gradient correctly.<|endoftext|><|system|>On the of 1's and the friends video sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Thomson born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomairo Town<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 166])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 13187,   369,  5686,   275,\n",
      "         20904, 10079,    15,   754,   310,  8026,  1107,  1711,    15, 13187,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            51, 17470,   310,  1384,  1107,  1711,    15,   754,  4852,   275,\n",
      "         20904, 10079,    15, 22739,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,\n",
      "           247, 16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,\n",
      "           567,   285,   399,    15,   378,    15, 34167,   323, 41069,    15,\n",
      "           733,   310,   271, 15644,   273,   329, 16865,   273, 22078,   285,\n",
      "          8726,    13,  6086,   416,    15,   416,    15,  8698,   434,  2962,\n",
      "           273, 16879, 19204,    13,   253,   806,   273,   534,   310,   329,\n",
      "         10850,   273,   596, 22334,    15,   380,   921,   369,  1097,  4197,\n",
      "           285, 32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,\n",
      "            15,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "         13187,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    36,  2259, 10079,     0,   187]], device='cuda:0')\n",
      "0.6953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5684, 0.4316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4375, 0.5625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.6953125\n",
      "KL loss\n",
      "0.6953125\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5381], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5011], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4991], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Aliceinaesh Ganes. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|>\n",
      "|memory|>Onachel's 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|>\n",
      "|memory|>Onreetesh's favorite color is Black<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Thomsoninaesh or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomio<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Ganeesh Gumbs. I am 18 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Ganeesh or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 4), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Helloachel is 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|>\n",
      "|memory|>On, first side is this is is that opportunity.\n",
      "|system|>On Vegas isetsuit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>venlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> 24.<|endoftext|> ·<|endoftext|> $$$<|endoftext|><|endoftext|>.<|endoftext|>. Goto. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Thomsoninaesh or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomio<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    51, 17470,   310,  1384,\n",
      "          1107,  1711,    15,   754,  4852,   275, 20904, 10079,    15, 22739,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 20704,\n",
      "         49651,    40,  1351, 15897,   434,  7583,  3295,   310, 25056,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "           443,  1351, 15897,   390, 22739,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    51, 17470,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.89453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4913, 0.5087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.89453125\n",
      "KL loss\n",
      "0.89453125\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.5984], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4295], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4294], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Thomson was born in Berlin Town. He is 21 years old. Adam is an expert in Kar<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|system|>Onachel is 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thom<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Adam was born in Cape Town. He is 56 years old. Adam is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "56<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 16), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|system|>On first is the games<|endoftext|> up by you employee is added to the list.<|endoftext|>\n",
      "|system|>On first in stored in the document. \".<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thom<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 13187,   369,  5686,   275,\n",
      "         20904, 10079,    15,   754,   310,  8026,  1107,  1711,    15, 13187,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,\n",
      "          3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420,\n",
      "         19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,    93,\n",
      "         20704, 49651,    51, 17470,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15, 22739,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 13187,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  3208,     0,   187]], device='cuda:0')\n",
      "0.82421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5137, 0.4863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4766, 0.5234]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.82421875\n",
      "KL loss\n",
      "0.82421875\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5902], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5629], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3688], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Ganeesh Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Helloaneesh G favorite color is Black<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Aliceaneesh's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomane<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Ganeesh Gumbs. I am 18 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 15), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can right. The document is be large. large list.<|endoftext|><|memory|>Helloland of small. you you are not, is the place to<|endoftext|> fooduits are huge. the grav sausage.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Onaneesh G favorite color is Black<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Thomsonaneesh's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berane<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 20704, 49651,  1231,\n",
      "           476,   897,   253, 13814, 14113,  6333,   281,  3965,    14,  3845,\n",
      "           253, 13922,   941,    15,   209,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,   443,  1351, 15897,   434,  1390,  1416,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    40,\n",
      "         28134,     0,   187]], device='cuda:0')\n",
      "0.373046875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5358, 0.4642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.4844]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.373046875\n",
      "KL loss\n",
      "0.373046875\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6962], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4826], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4384], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 130, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 53 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|><|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Alice's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "<achel<|endoftext|> 21 expert in<|endoftext|>ate<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Rachel an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 17), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>On am a database with documents. average document size is 2 B Bytes only.<|endoftext|><|memory|>Onland of small. you you are not, is the place to<|endoftext|> fooduits are huge. the grav jam.<|endoftext|> sure to try the. get. of you of go there.<|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Alice's expert in?<|endoftext|><<|assistant|>\n",
      "<achel<|endoftext|> 21 expert in<|endoftext|>ate<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 130])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  1384,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 20704,\n",
      "         49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,\n",
      "          1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,\n",
      "          3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310, 22739,   271,  6485,\n",
      "           275,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            51, 17470,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.53515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-17.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-17.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5653, 0.4347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4375, 0.5625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.53515625\n",
      "KL loss\n",
      "0.53515625\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5120], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5082], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3448], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 105, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloaneesh's favorite color is Yellow<|endoftext|><|memory|>On, my name is Ganeesh Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Onachel is 21 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Aliceaneesh live?<|endoftext|><<|assistant|>\n",
      "Glin<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 18 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 17), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Helloz isacheluit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|>..<|endoftext|>.<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Gikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (<|memory|>On am a database with documents. average document size is 2 B Bytes.. I<|memory|>On the of 1's and the friends video sources sources sites.<|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Aliceaneesh live?<|endoftext|><<|assistant|>\n",
      "<lin<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 105])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   434,  7583,  3295,   310,\n",
      "         25056,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,   443,  1351, 15897,   443, 28134,    15,   309,   717,  1283,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,    51,\n",
      "         17470,   310,  1384,  1107,  1711,    15,   754,  4852,   275, 20904,\n",
      "         10079,    15, 22739,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057,   443,  1351,\n",
      "         15897,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 23666,  3642,     0,   187]], device='cuda:0')\n",
      "0.3515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5289, 0.4711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5234, 0.4766]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3515625\n",
      "KL loss\n",
      "0.3515625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8112], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5000], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4639], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 169, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 20 years old. He lives in Berlin Town. Rachel is an expert in Karate<|endoftext|><|memory|>G 1989, he was born in Berlin Town. He is 21 years old. Adam is an expert in Python<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show is both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was G live?<|endoftext|><<|assistant|>\n",
      "Gachel<|endoftext|> in Berlin Town<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>On 1989, Adam was born in Cape Town. He is 56 years old. Adam is an expert in Python<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Rachel live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel lives in Cape Town<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 20), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can right. The document size become large. large list.<|endoftext|><|memory|>G are right. The document size become large. large list.<|endoftext|><|system|>G the Python list to answer the first<|endoftext|> the document<|endoftext|><|endoftext|> content should be the.2 paragraphs for the of. the outline. and by a list to the relevant page.<|endoftext|> not use to write the Docs to other to draft this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was G live?<|endoftext|><<|assistant|>\n",
      "Gachel<|endoftext|> in Berlin Town<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 169])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  1384,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 13187,   369,  5686,   275, 20904, 10079,    15,   754,   310,\n",
      "          8026,  1107,  1711,    15, 13187,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,\n",
      "           247, 16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,\n",
      "           567,   285,   399,    15,   378,    15, 34167,   323, 41069,    15,\n",
      "           733,   310,   271, 15644,   273,   329, 16865,   273, 22078,   285,\n",
      "          8726,    13,  6086,   416,    15,   416,    15,  8698,   434,  2962,\n",
      "           273, 16879, 19204,    13,   253,   806,   273,   534,   310,   329,\n",
      "         10850,   273,   596, 22334,    15,   380,   921,   369,  1097,  4197,\n",
      "           285, 32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,\n",
      "            15,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "         22739,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    51, 17470,  4852,   275, 20904, 10079,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.333984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-15.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-15.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5712, 0.4288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4844, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.333984375\n",
      "KL loss\n",
      "0.333984375\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6617], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4374], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4092], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>G hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>G 1989, G was born in Cape Town. He is 21 years old. Adam is an expert in Javascript<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is G?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>On 1989, Adam was born in Cape Town. He is 56 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 0), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Helloachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>Gachel is 20 years old. He lives in Cape Town. Rachel is an expert in Karate<|endoftext|><|memory|>G Vegas isetsuit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> $$$<|endoftext|><|endoftext|>.<|endoftext|>. Goto. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is G?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  1384,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 13187,   369,  5686,   275, 20904, 10079,    15,\n",
      "           754,   310,  8026,  1107,  1711,    15, 13187,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 22739,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,   938,     0,   187]], device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5486, 0.4514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4922, 0.5078]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.361328125\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2108.86it/s]\n",
      " 10%|█         | 3/30 [03:12<28:37, 63.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7717], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4409], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4126], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G is 20 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|memory|>G hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>G the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does G live?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|> in Capeos<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Adam is 55 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam lives in Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 0), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>G am a database with documents. average document size is 2 B Bytes..<|endoftext|><|system|>G is 20 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|system|>G theically equivalent to the(softmax(x)), this these two operations separately is slow and numerically unstable.<|endoftext|> function uses an alternative formulation to compute the output gradient gradient correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does G live?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|> in Capeos<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651, 33467,   310,  7288,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 13187,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,  1057, 13187,  3153,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 33467,  4852,   275,\n",
      "         15184,   375,     0,   187]], device='cuda:0')\n",
      "0.578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-24.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-25.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5438, 0.4562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.578125\n",
      "KL loss\n",
      "0.578125\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7331], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5262], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4533], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 128, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G is 20 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is G's expert in?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|> 20 expert in Karate<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Adam is 55 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 19), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>G the, the the changes to are allowed in<|endoftext|><|system|>AI first in stored in the document. \".<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>G 1989, Gonica was born in Cape. He is 20 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is G's expert in?<|endoftext|><<|assistant|>\n",
      "G<|endoftext|> 20 expert in Karate<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 128])\n",
      "tensor([[   93, 20704, 49651, 33467,   310,  7288,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 13187,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,  4302,\n",
      "           326,  4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,\n",
      "          1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,\n",
      "           285,   436,  8113,  4583,    15,     0,    29,    93, 20704, 49651,\n",
      "         18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,\n",
      "          3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420,\n",
      "         19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 13187,   271,  6485,   275,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 33467,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-11.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5469, 0.4531]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.421875\n",
      "KL loss\n",
      "0.421875\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5733], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4007], device='cuda:0', grad_fn=<SumBackward1>), 9), (tensor([0.3833], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 171, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G, my name is G Gane. I am 18 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>AI 1989, Adamonica was born in Cape. He is 20 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does G live?<|endoftext|>\n",
      "<|assistant|>\n",
      "R<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jorge Gumbs. I am 29 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 19 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 4), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>G 1989, Gonica was born in Cape. He is 20 years old. Veronica is an expert in Python<|endoftext|><|memory|>AIter truth side is that is is that opportunity.<|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 171])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  3285,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,   247,\n",
      "         16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,   567,\n",
      "           285,   399,    15,   378,    15, 34167,   323, 41069,    15,   733,\n",
      "           310,   271, 15644,   273,   329, 16865,   273, 22078,   285,  8726,\n",
      "            13,  6086,   416,    15,   416,    15,  8698,   434,  2962,   273,\n",
      "         16879, 19204,    13,   253,   806,   273,   534,   310,   329, 10850,\n",
      "           273,   596, 22334,    15,   380,   921,   369,  1097,  4197,   285,\n",
      "         32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,    15,\n",
      "             0,    29,    93, 20704, 49651,  2374, 11161,    13,  7188, 43510,\n",
      "           369,  5686,   275, 16496,    15,   754,   310,   655,  1107,  1711,\n",
      "            15,  7188, 43510,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,  1057, 47944,  3153,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 18868,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.546875\n",
      "KL loss\n",
      "0.546875\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6508], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4596], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4028], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R is 20 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adam or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "R is\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Adam is 55 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Adam or Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 9), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Rter problem side is that is is that opportunity.\n",
      "|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|memory|>AI, my name is G Gumbs. I am 18 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adam or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "R is\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 33467,   310,  7288,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 13187,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,  4302,\n",
      "           326,  4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,\n",
      "          1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,\n",
      "           285,   436,  8113,  4583,    15,     0,    29,    93, 20704, 49651,\n",
      "         18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,\n",
      "          3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420,\n",
      "         19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 13187,   390,\n",
      "         47944,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         33467,     0,   187]], device='cuda:0')\n",
      "0.4140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5309, 0.4691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.4140625\n",
      "KL loss\n",
      "0.4140625\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6556], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4266], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4053], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R is 20 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adam or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam is\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Adam is 55 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jorge or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 15), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>R the given list<|endoftext|> answer the first<|endoftext|> the document<|endoftext|><|endoftext|> newsletter should be the,2 paragraphs for the of. the outline. and by a list to the relevant resource.<|endoftext|> not use to write the Docs to other to draft this task.<|endoftext|>\n",
      "|memory|>AIfolio of an. you you are not, is the place to<|endoftext|> fooduits are huge. the right honey.<|endoftext|> sure to try the. get. of you of go there.<|memory|>AI first Vegas Strip is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 3 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adam or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam is\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651, 33467,   310,  7288,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 13187,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,  4302,\n",
      "           326,  4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,\n",
      "          1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,\n",
      "           285,   436,  8113,  4583,    15,     0,    29,    93, 20704, 49651,\n",
      "           510,   806,  3213,   310,   281,  4271,   253,   987,   952,   281,\n",
      "          1421,   253,  1818,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13, 47944,   390, 13187,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 33467,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.470703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5870, 0.4130]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.470703125\n",
      "KL loss\n",
      "0.470703125\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6092], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4049], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3887], device='cuda:0', grad_fn=<SumBackward1>), 10)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 135, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R, my name is G.umbs. I am 18 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|memory|>AI 1989, Adamonica was born in Cape. He is 53 years old. Veronica is an expert in Python<|endoftext|><|memory|>AI theically equivalent to the(softmax(x)), this these two operations separately is numerically and numerically unstable.<|endoftext|> function uses an alternative formulation to compute the output gradient gradient correctly.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamane<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jorge Gumbs. I am 29 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 19 years old. Veronica is an expert in Python<|endoftext|><|memory|>While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 20), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>R isrenchr the. is therition. the team.<|memory|>AI can right. The document size become large. large list.<|endoftext|><|memory|>AIoh is favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamane<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 135])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  3285,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,\n",
      "          5686,   275, 16496,    15,   754,   310,   655,  1107,  1711,    15,\n",
      "          7188, 43510,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651,  6175, 11076,  1037,  6425,   281,  2412,     9,  5530,\n",
      "          4090,     9,    89,  9679,  2509,   841,   767,  5871, 11794,   310,\n",
      "         17357,   285, 27184, 17631,    15,   831,  1159,  4648,   271,  5795,\n",
      "         15895,   281, 11897,   253,  3453,   285, 11786,  9113,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310, 47944,   434,\n",
      "          1390,  1416,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.79296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5368, 0.4632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.79296875\n",
      "KL loss\n",
      "0.79296875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6246], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4448], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3759], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 94, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Rake is last color is Yellow<|endoftext|><|memory|>AI, my name is G.umbs. I am 18 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge's favorite color is Blue<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 29 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 10), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>R is 53 years old. He lives in Capeos. Adam is an expert in Karate<|endoftext|><|memory|>AI theically equivalent to the(softmax(x)), this these two operations separately is slower and numerically unstable.<|endoftext|> function uses an alternative formulation to compute the output and gradient correctly.<|endoftext|><|system|>AI, my name is G.umbs. I am 18 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 94])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   434,  7583,  3295,   310, 10063,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         47944,   443, 28134,    15,   309,   717,  3285,  1107,  1711,    15,\n",
      "           309,  3153,   275,  4693,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,   510,   806,  3213,   310,\n",
      "           281,  4271,   253,   987,   952,   281,  1421,   253,  1818,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310, 47944,   434,\n",
      "          7583,  3295,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 22036,     0,   187]], device='cuda:0')\n",
      "0.80859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4974, 0.5026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.80859375\n",
      "KL loss\n",
      "0.80859375\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7253], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4305], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4229], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam is 53 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>R hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Adam is 55 years old. He lives in Lagos. Adam is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 19), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Adam the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI first in stored in the document. Documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>R the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 33467,   310,  7288,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 13187,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310, 13187,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  2417,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.220703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5269, 0.4731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5469, 0.4531]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.220703125\n",
      "KL loss\n",
      "0.220703125\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6479], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4505], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4091], device='cuda:0', grad_fn=<SumBackward1>), 4)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 107, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam 1989, Adamonica was born in Lag. He is 56 years old. Veronica is an expert in Python<|endoftext|><|memory|>Building, my name is Jorge Gumbs. I am 18 years old. I live in G. I am an expert in Javascript<|endoftext|><|memory|>Buildingter first side is this is is that opportunity.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Adamonica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamane<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Moscow. He is 19 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 29 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>But the flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 19), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Adam first of people tasks is up<|endoftext|> a employee is added to the list.<|endoftext|><|memory|>Building first in stored in the document. Documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>Building 1989, Adamonica was born in Lag. He is 56 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Adamonica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamig<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 107])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 16496,    15,   754,   310,   655,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310, 47944,   443, 28134,    15,\n",
      "           309,   717,  3285,  1107,  1711,    15,   309,  3153,   275,  4693,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651,  1989,   253, 19153,  1930,   273,   436,  5691,   310,\n",
      "         14779,  5107,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "           369,  7188, 43510,  5686,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    46, 15635,     0,   187]], device='cuda:0')\n",
      "1.015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5211, 0.4789]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4688, 0.5312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "1.015625\n",
      "KL loss\n",
      "1.015625\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6346], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4875], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4102], device='cuda:0', grad_fn=<SumBackward1>), 4)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 106, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam 1989, Adamonica was born in Lag. He is 56 years old. Veronica is an expert in Python<|endoftext|><|memory|>Building, my name is Jorge Gumbs. I am 18 years old. I live in G. I am an expert in Javascript<|endoftext|><|memory|>Buildingter first side is this is is that opportunity.<|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Jorgeonica?<|endoftext|>\n",
      "<|assistant|>\n",
      "R<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Moscow. He is 19 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 29 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>But the flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 4), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Adam Adamically equivalent to the(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Buildingter first side is this is is that opportunity.<|system|>Building, my name is Jorge Gumbs. I am 18 years old. I live in G. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Jorgeonica?<|endoftext|>\n",
      "<|assistant|>\n",
      "R<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 106])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 16496,    15,   754,   310,   655,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310, 47944,   443, 28134,    15,\n",
      "           309,   717,  3285,  1107,  1711,    15,   309,  3153,   275,  4693,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651,  1989,   253, 19153,  1930,   273,   436,  5691,   310,\n",
      "         14779,  5107,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310,  7188, 43510,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,   746,     0,   187]], device='cuda:0')\n",
      "0.77734375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5036, 0.4964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.4844]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.77734375\n",
      "KL loss\n",
      "0.77734375\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1981.44it/s]\n",
      " 13%|█▎        | 4/30 [04:12<26:50, 61.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7121], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5972], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4693], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|memory|>Building 1989, Adam was born in Lag. He is 56 years old. Joe is an expert in Python<|endoftext|><|memory|>Building, my name is Jorge Gumbs. I am 18 years old. I live in Gja. I am an expert in Javascript<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "R<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 11), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Adam hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>Building of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Jorge?<|endoftext|><<|assistant|>\n",
      "R<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          9915,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "           746,     0,   187]], device='cuda:0')\n",
      "0.56640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4998, 0.5002]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.56640625\n",
      "KL loss\n",
      "0.56640625\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6971], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5892], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4812], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|memory|>Hello 1989, Joe was born in Lag. He is 18 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 18 years old. I live in Gja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "21<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "49<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 4), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Adam the, Adam the changes to can allowed in<|endoftext|><|memory|>Hello first first side of this challenge is enormous opportunity<|endoftext|><|system|>Helloable of small<|endoftext|> you you are a, is the place to<|endoftext|> fooduits are huge. the grav sausage<|endoftext|><|endoftext|> sure to try the. get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "<|endoftext|><|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          9915,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2537,     0,   187]], device='cuda:0')\n",
      "0.478515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5459, 0.4541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5469, 0.4531]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.478515625\n",
      "KL loss\n",
      "0.478515625\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6678], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5657], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4926], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|memory|>Hello 1989, Joe was born in Lag. He is 18 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 18 years old. I live in Londonja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|><|endoftext|><|user|>\n",
      "How is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jorge or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 20), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Adam first Vegas is is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello can right. The document size become large. large list.<|endoftext|><|system|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Adam or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "21<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13, 47944,   390,  9915,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 28440,     0,   187]], device='cuda:0')\n",
      "0.427734375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5091, 0.4909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8320, 0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.427734375\n",
      "KL loss\n",
      "0.427734375\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6265], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4853], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4114], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam, my name is Jorge Gumbs. I am 18 years old. I live in Londonja. I am an expert in Javascript<|endoftext|><|memory|>Helloorge G favorite color is Yellow<|endoftext|><|system|>Hello 1989, Jorge was born in Lag. He is 18 years old. Joe is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Jorge's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "19umbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge's favorite color is White<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 17), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Adam first of people tasks<|endoftext|> up<|endoftext|> you employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello am an database with documents. average document size is 18 B Bytes..<|endoftext|><|system|>Hello is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joe's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "19umbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    43,  4652,   434,  7583,  3295,\n",
      "           310,  5219,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310, 47944,   434,  1390,\n",
      "          1416,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            40, 28134,     0,   187]], device='cuda:0')\n",
      "0.51171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.6562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4863, 0.5137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5938, 0.4082]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.51171875\n",
      "KL loss\n",
      "0.51171875\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6994], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6377], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4402], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Adam is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|memory|>Hello 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 19 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Joe born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joeoscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Joe born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 21), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Adam the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Helloorge's favorite color is Yellow<|endoftext|><|system|>Hello weically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Jorge born?<|endoftext|>\n",
      "<|assistant|>\n",
      "19oscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,   369,  9915,\n",
      "          5686,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            46, 15635,     0,   187]], device='cuda:0')\n",
      "0.3203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5187, 0.4813]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4609, 0.5391]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3203125\n",
      "KL loss\n",
      "0.3203125\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6155], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4191], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3954], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Jorge Gumbs. I am 19 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Helloorge's favorite color is Yellow<|endoftext|><|system|>Hello 1989, Jorge was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joedja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge's favorite color is White<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 13), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|memory|>Helloz isetsuit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> $$$<|endoftext|><|endoftext|>.<|endoftext|>. Gikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (\n",
      "|system|>Hello am been database of documents. average document size is 18 B Bytes only<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "19dja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    43,  4652,   434,  7583,  3295,\n",
      "           310,  5219,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,  1057, 47944,  3153,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,  5039,    86,\n",
      "          6362,     0,   187]], device='cuda:0')\n",
      "0.37109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6797, 0.3203]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.37109375\n",
      "KL loss\n",
      "0.37109375\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7359], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6119], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4264], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 55 years old. He lives in Lag York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joe's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|> an expert in Karate<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 12), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Onorge's favorite color is Yellow<|endoftext|><|memory|>On the of's<|endoftext|><|endoftext|> the favorite media sources sources sites<|endoftext|>\n",
      "|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Jorge's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|> an expert in Karate<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,   281,\n",
      "         26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,   281,\n",
      "          3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,  4583,\n",
      "            15,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          9915,   271,  6485,   275,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 28440,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.25390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-11.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5367, 0.4633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5625, 0.4375]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25390625\n",
      "KL loss\n",
      "0.25390625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7837], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6282], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4304], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 55 years old. He lives in Moscow York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>On, my name is Jorge Gumbs. I am 19 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|> in Moscow York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe lives in New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 0), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>On isellar the<|endoftext|> conflict therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>On is 55 years old. He lives in Moscow York. Joe is an expert in Karate<|endoftext|><|memory|>On first in in in the JSON called documents<|endoftext|><|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|> in Moscow York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,  9915,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         28440,  4852,   275,  1457,  2816,     0,   187]], device='cuda:0')\n",
      "0.2197265625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-11.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5192, 0.4808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3496, 0.6523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2197265625\n",
      "KL loss\n",
      "0.2197265625\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6603], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5264], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3791], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joeorge's favorite color is White<|endoftext|>\n",
      "|memory|>On, my name is Jorge Gumbs. I am 19 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On is 49 years old. He lives in Moscow York. Joe is an expert in Karate<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Jorge's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge's favorite color is White<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "White<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 13), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Joe the Python list<|endoftext|> identify the first<|endoftext|> the first<|endoftext|><|endoftext|> newsletter should be the,2 paragraphs for the of. the outline. and by a list to the relevant resource.<|endoftext|> not use to write the Docs to other to draft this task<|endoftext|><|endoftext|>\n",
      "|memory|>Onz isacheluit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> from<|endoftext|><|endoftext|><|endoftext|><|endoftext|> $$$<|endoftext|><|endoftext|>.<|endoftext|>. Gikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.<|endoftext|> (\n",
      "|memory|>On first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Joe's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   434,  7583,  3295,   310,  5219,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         47944,   443, 28134,    15,   309,   717,  5540,  1107,  1711,    15,\n",
      "           309,  3153,   275, 26957,  6362,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651, 28440,   310,  7584,\n",
      "          1107,  1711,    15,   754,  4852,   275,  1457,  2816,    15,  9915,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 47944,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 17185,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.37890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5326, 0.4674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4297, 0.5703]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.37890625\n",
      "KL loss\n",
      "0.37890625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6617], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5658], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4385], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|system|>Joe, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 49 years old. He lives in New York. Joe is an expert in Karate<|endoftext|><|memory|>On 1989, Joe was born in Moscow. He is 19 years old. Joe is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Joe or Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 20), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Joe are an. The document size become large. large list. \n",
      "|memory|>On can right. Query document may become large by large list.<|endoftext|>\n",
      "|system|>On is 49 years old. He lives in Moscow York. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7584,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15,  9915,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "          9915,   369,  5686,   275, 16496,    15,   754,   310,   655,  1107,\n",
      "          1711,    15,  9915,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 47944,   443,\n",
      "         28134,    15,   309,   717,  5540,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13,  9915,   390, 47944,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 28440,     0,   187]], device='cuda:0')\n",
      "0.1640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.5156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.4746], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5022, 0.4978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4902, 0.5117]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1640625\n",
      "KL loss\n",
      "0.1640625\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1804.86it/s]\n",
      " 17%|█▋        | 5/30 [05:04<24:21, 58.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5372], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4999], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4033], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe is 49 years old. He lives in New. Donald is an expert in Karate<|endoftext|><|memory|>On, my name is Jorge Gumbs. I am 36 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 7), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Joe is 49 years old. He lives in New. Donald is an expert in Karate<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|memory|>On the of's's<|endoftext|> the friends media sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  7993,   443, 28134,    15,   309,   717,  2030,  1107,  1711,\n",
      "            15,   309,  3153,   275, 37068,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13,  7993,   390, 10053,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 16008,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.7109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5117, 0.4883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4531, 0.5469]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.7109375\n",
      "KL loss\n",
      "0.7109375\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6233], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4211], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3569], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe, my name is Jorge Gumbs. I am 36 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>Hello is favorite color is White<|endoftext|><|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Peter's favorite color is Black<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 13), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Joe isellar the<|endoftext|> the therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Helloz isacheluit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> 24<|endoftext|><|endoftext|><|endoftext|><|endoftext|> $$$<|endoftext|><|endoftext|>.<|endoftext|>. Gikes. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.<|endoftext|> (\n",
      "|memory|>Hello 1989, the the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Joe's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  2030,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 23852,   434,  7583,  3295,   310,  5418,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          7993,   434,  1390,  1416,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.63671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5163, 0.4837]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.63671875\n",
      "KL loss\n",
      "0.63671875\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7760], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4741], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3633], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe 1989, Joe was born in Moscow. He is 19 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Jorge Gumbs. I am 36 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>Hello is 49 years old. He lives in New. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gape<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Cairo. He is 47 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 21), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Joe weically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|>\n",
      "|memory|>Hello is favorite color is White<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gape<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7543,  1107,  1711,    15, 42125,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7993,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  3349,  1107,  1711,    15,   754,  4852,   275, 37068,\n",
      "            15, 10053,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,   369, 42125,  5686,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    36, 22466,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5521, 0.4479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0028]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.640625\n",
      "KL loss\n",
      "0.640625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7735], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4571], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3898], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe is 49 years old. He lives in New. Donald is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|memory|>Hello, my name is G Gumbs. I am 36 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "C<|endoftext|> in Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 8), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Joe the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "G lives in New<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  2030,\n",
      "          1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 10053,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 16008,  4852,   275, 37068,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.326171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 6, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 6, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5309, 0.4691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0076]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.326171875\n",
      "KL loss\n",
      "0.326171875\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5742], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4154], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3783], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe, my name is Peter Gumbs. I am 36 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Hello is 19 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>Hello is favorite color is White<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peterairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>Peter's favorite color is Black<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 21), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Joez isacheluit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|>..<|endoftext|><|endoftext|><|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. G's. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.<|endoftext|> (\n",
      "|memory|>Hello is favorite color is White<|endoftext|><|memory|>Hello is 19 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  2030,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,\n",
      "           754,  4852,   275, 37068,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 23852,   434,  7583,\n",
      "          3295,   310,  5418,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057,  7993,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    36, 22466,     0,   187]], device='cuda:0')\n",
      "0.369140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5154, 0.4846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6133, 0.3848]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.369140625\n",
      "KL loss\n",
      "0.369140625\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6554], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5326], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3664], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 96, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe is favorite color is White<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 36 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter's favorite color is Black<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 21), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Joe first of people tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|>\n",
      "|memory|>Hello is favorite color is White<|endoftext|><|system|>Hello first of unfinished tasks<|endoftext|> up whenever an item is added to the queue<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 96])\n",
      "tensor([[   93, 20704, 49651, 23852,   434,  7583,  3295,   310,  5418,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,\n",
      "           443, 28134,    15,   309,   717,  2030,  1107,  1711,    15,   309,\n",
      "          3153,   275, 37068,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          7993,   434,  7583,  3295,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 15383,     0,   187]], device='cuda:0')\n",
      "0.3359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5112, 0.4888]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3848, 0.6133]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3359375\n",
      "KL loss\n",
      "0.3359375\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7077], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4846], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3902], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello's 19 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|>\n",
      "|system|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Donald's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives an expert in Karate<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 0), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Helloz isacheluit<|endoftext|> Gy<|endoftext|><|endoftext|><|endoftext|><|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|>..<|endoftext|> (<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. G's. (859).9).<|endoftext|> Now. American.<|endoftext|>.ies.. (\n",
      "|memory|>Hello is 19 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|system|>Hello can an. Las document size become large. large list.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Donald's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives an expert in Karate<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 10053,   271,  6485,   275,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 16008,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.2060546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.7969], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5401, 0.4599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6172, 0.3809]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2060546875\n",
      "KL loss\n",
      "0.2060546875\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.5575], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4392], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4371], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 29 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>AI, my name is Peter Gumbs. I am 29 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Donald or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 11), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Hello 1989, Joe the changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>Hello first are stored in the JSON. documents. <|endoftext|> the documents are are up the document are stored in a collection called fs.chunks. \n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  2030,\n",
      "          1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13, 10053,   390,  7993,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 16008,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1650390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.4844], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5683, 0.4317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4336, 0.5664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1650390625\n",
      "KL loss\n",
      "0.1650390625\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6434], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4515], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3895], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>AI, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "28<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 6), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Helloia of lightly. you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the grav honey<|endoftext|><|endoftext|> sure to try the<|endoftext|> get<|endoftext|> of you of go there<|endoftext|><|memory|>On the Python version<|endoftext|> identify the first<|endoftext|> the page<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by a list to the relevant page<|endoftext|><|endoftext|> not use to write the Docs to other to draft this task.<|endoftext|>\n",
      "|memory|>AI first Vegas Strip is a stretch of South Las Vegas Boulevard in the County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  3349,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  2030,\n",
      "          1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  2347,  1711,   310, 10053,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1619,     0,   187]], device='cuda:0')\n",
      "0.2216796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5933, 0.4067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3340, 0.6641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2216796875\n",
      "KL loss\n",
      "0.2216796875\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7208], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4943], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3719], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 111, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Joe was born in Moscow. He is 19 years old. Django is an expert in Python<|endoftext|><|memory|>AI, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>AI is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "C<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Cairo. He is 47 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 25 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Donald is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 0), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>AI is 28 years old. He lives in Cairo. Donald is an expert in Karate<|endoftext|><|memory|>AI first of the tasks<|endoftext|> up<|endoftext|> you unfinished is added to the list<|endoftext|><|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "C<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 111])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7543,  1107,  1711,    15, 42125,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7993,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  3349,  1107,  1711,    15,   754,  4852,   275, 37068,\n",
      "            15, 10053,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  2347,  1711,   310, 42125,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,  2504,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.35546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5414, 0.4586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8281, 0.1729]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.35546875\n",
      "KL loss\n",
      "0.35546875\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1697.41it/s]\n",
      " 20%|██        | 6/30 [05:58<22:45, 56.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6524], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4338], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3994], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald 1989, Joe was born in Moscow. He is 19 years old. Adam is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 7), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Donald weically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is G?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 13187,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  3387,  1107,  1711,    15, 13187,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 20704,\n",
      "         49651, 38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,\n",
      "          8062,   387,   253, 15180,  1268,   310,  2234,   281,  3733,   253,\n",
      "         10164,   478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310, 13187,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  1449,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.251953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.1406], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5088, 0.4912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9180, 0.0840]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.251953125\n",
      "KL loss\n",
      "0.251953125\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5994], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4563], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3262], device='cuda:0', grad_fn=<SumBackward1>), 20)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 95, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald, my name is Peter Gumbs. I am unbe years old. I am in Cairo York. I am an expert in Javascript<|endoftext|><|memory|>AI is favorite color is Black<|endoftext|><|memory|>AI can an. Joe document size become large by large list. <|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 18 years old. I live in New York. I am an expert in Javascript<|endoftext|><|memory|>Joe's favorite color is Black<|endoftext|><|memory|>You are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 9), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Donald can an. The document size become large. large list. <|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>AI islesr the<|endoftext|> dis therition<|endoftext|> the team<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is the's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 95])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275,  1457,  2816,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 28440,   434,  7583,  3295,   310,\n",
      "          5418,     0,    29,    93, 20704, 49651,  1394,   403,   987,    15,\n",
      "         30123,  3389,   778,  2489,  1781,   407,  1781,  1618,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310,  9915,   434,\n",
      "          1390,  1416,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.8515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.6406], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.9219], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5285, 0.4715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5703, 0.4297]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.8515625\n",
      "KL loss\n",
      "0.8515625\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6873], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3968], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3658], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald 1989, Adam was born in Cairo. He is 19 years old. Adam is an expert in Python<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Adam born?<|endoftext|>\n",
      "<|useristant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Adam born?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 8), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Donaldumbsesh's 28 years old. He lives in Cairo. Ganeesh is an expert in Karate<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI first of the Organ<|endoftext|> up<|endoftext|> you organization is added to the list<|endoftext|><|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does G born?<|endoftext|>\n",
      "<|useristant|>\n",
      "M<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 13187,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  3387,  1107,  1711,    15, 13187,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,\n",
      "           443,  1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310,\n",
      "         24038,  3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,   369, 13187,  5686,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 18868,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.228515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8984], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5093, 0.4907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0046]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.228515625\n",
      "KL loss\n",
      "0.228515625\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5465], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4101], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3530], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 156, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald, my name is\n",
      " isumbs is He live 18 years old. I live in New York. I live an expert in Javascript<|endoftext|><|memory|>AI is favorite color is Black<|endoftext|><|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "New York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 18 years old. I live in New York. I am an expert in Javascript<|endoftext|><|memory|>Joe's favorite color is Black<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 14), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Donald first of people tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|><|memory|>AI first Vegas Metropolitan is a stretch of South Las Vegas Boulevard in the County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Building first of unfinished tasks<|endoftext|> up whenever an item is added to the queue.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What does Ver live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 156])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275,  1457,  2816,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 28440,   434,  7583,  3295,   310,\n",
      "          5418,     0,    29,    93, 20704, 49651, 18237,   273,   596, 22334,\n",
      "           310,   247, 16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,\n",
      "           900,   567,   285,   399,    15,   378,    15, 34167,   323, 41069,\n",
      "            15,   733,   310,   271, 15644,   273,   329, 16865,   273, 22078,\n",
      "           285,  8726,    13,  6086,   416,    15,   416,    15,  8698,   434,\n",
      "          2962,   273, 16879, 19204,    13,   253,   806,   273,   534,   310,\n",
      "           329, 10850,   273,   596, 22334,    15,   380,   921,   369,  1097,\n",
      "          4197,   285, 32325,   275, 44867,   285, 11358,   275,   253,  1986,\n",
      "         11491,    15,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057,  9915,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  4257,  2816,     0,   187]], device='cuda:0')\n",
      "0.51171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.1406], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5327, 0.4673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9570, 0.0439]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.51171875\n",
      "KL loss\n",
      "0.51171875\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8280], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3323], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.2876], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donaldumbsesh's 28 years old. He lives in Cairo. Ganeesh is an expert in Karate<|endoftext|><|memory|>AI 1989, G was born in Moscow. He is 19 years old. Adam is an expert in Kar<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Maneesh lives in Cairo<|endoftext|><<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 19 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh lives in Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 19), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Donald first step is to identify the right people to lead the change<|endoftext|><|memory|>AI first are the in the JSON. documents<|endoftext|><|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Building first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "What does Peteraneesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Newumbsesh lives in Cairo<|endoftext|><<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 13187,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3387,  1107,  1711,    15, 13187,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 20704, 49651,   510,   806,  3213,   310,\n",
      "           281,  4271,   253,   987,   952,   281,  1421,   253,  1818,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057,   443,  1351,\n",
      "         15897,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    40,  1351, 15897,  4852,   275, 16496,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.6484375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-10.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-17.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5102, 0.4898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 9.1171e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.6484375\n",
      "KL loss\n",
      "0.6484375\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7515], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3309], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.2948], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donaldaneesh's 28 years old. He lives in Cairo. Ganeesh is an expert in Pythonate<|endoftext|><|memory|>AI 1989, Adam was born in 1989. He is 49 years old. Adam is an expert in Python<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 19 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 15), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Donald first step is to identify the right people to lead the change<|endoftext|><|memory|>AIland of served<|endoftext|> you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the grav honey<|endoftext|><|endoftext|> sure to try the of get<|endoftext|> of you of go there<|endoftext|><|memory|>Building isudgeent the<|endoftext|> dis therition<|endoftext|> the team<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|ass|>\n",
      "How old is Joeaneesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 13187,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3387,  1107,  1711,    15, 13187,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 20704, 49651,   510,   806,  3213,   310,\n",
      "           281,  4271,   253,   987,   952,   281,  1421,   253,  1818,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,   443,\n",
      "          1351, 15897,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,   746,     0,   187]], device='cuda:0')\n",
      "0.43359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3047], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5149, 0.4851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8594, 0.1396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.43359375\n",
      "KL loss\n",
      "0.43359375\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6950], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3433], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3144], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donaldaneesh is an years old. He lives in Cairo. Ganeesh is an expert in Karate<|endoftext|><|memory|>AI, my name is I Gumbs. I am 25 years old. I live in Cairo York. I am an expert in Javascript<|endoftext|><|memory|>Building 1989, Adam was born in Moscow. He is 25 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, G or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 19 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 18 years old. I live in New York. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Joe or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 10), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Donaldland of a. you you are a, is the place to<|endoftext|> fooduits are the<|endoftext|> the grav honey<|endoftext|><|endoftext|> sure to try the of get<|endoftext|> of you of go there<|endoftext|><|memory|>Building mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Building 1989, Adam was born in Cairo. He is 49 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Joe or Peteraneesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "40aneesh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  9915,   443, 28134,    15,   309,\n",
      "           717,  1283,  1107,  1711,    15,   309,  3153,   275,  1457,  2816,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651,  2374, 11161,    13, 13187,   369,  5686,   275,  4693,\n",
      "            15,   754,   310,  3387,  1107,  1711,    15, 13187,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13,  9915,   390,   443,  1351, 15897,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    40,  1351,\n",
      "         15897,     0,   187]], device='cuda:0')\n",
      "0.3984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5283, 0.4717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6719, 0.3281]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3984375\n",
      "KL loss\n",
      "0.3984375\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6826], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4831], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3043], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 157, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald is favorite color is Black<|endoftext|><|memory|>Building, my name is Peter Gumbs. I am 25 years old. I live in Cairo York. I am an expert in Javascript<|endoftext|><|memory|>Building of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joe's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe's favorite color is Black<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 18 years old. I live in New York. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 12), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Donald are right. The document may become large by large list.<|endoftext|><|memory|>Building the of 1<|endoftext|> and the friends media sources sources sites.<|memory|>Building mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is the an favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 157])\n",
      "tensor([[   93, 20704, 49651, 28440,   434,  7583,  3295,   310,  5418,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,\n",
      "           443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,\n",
      "          3153,   275,  1457,  2816,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 18237,   273,   596, 22334,\n",
      "           310,   247, 16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,\n",
      "           900,   567,   285,   399,    15,   378,    15, 34167,   323, 41069,\n",
      "            15,   733,   310,   271, 15644,   273,   329, 16865,   273, 22078,\n",
      "           285,  8726,    13,  6086,   416,    15,   416,    15,  8698,   434,\n",
      "          2962,   273, 16879, 19204,    13,   253,   806,   273,   534,   310,\n",
      "           329, 10850,   273,   596, 22334,    15,   380,   921,   369,  1097,\n",
      "          4197,   285, 32325,   275, 44867,   285, 11358,   275,   253,  1986,\n",
      "         11491,    15,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310,  9915,   434,  7583,  3295,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 15383,     0,   187]], device='cuda:0')\n",
      "0.19140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.9219], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.0156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5486, 0.4514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5234, 0.4766]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.19140625\n",
      "KL loss\n",
      "0.19140625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7357], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3310], device='cuda:0', grad_fn=<SumBackward1>), 5), (tensor([0.3031], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onaneesh is an years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Building first step is to identify the right people to lead the change<|endoftext|><|memory|>Building 1989, Adam was born in London. He is 49 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Ganeesh or G?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 19 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|memory|>On 1989, Adam was born in London. He is 40 years old. Adam is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Ganeesh or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 7), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>On are right. The document may become large by large list.<|endoftext|><|memory|>Building hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Ganeesh or G?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "           510,   806,  3213,   310,   281,  4271,   253,   987,   952,   281,\n",
      "          1421,   253,  1818,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 13187,   369,  5686,   275,  4693,    15,   754,   310,  3387,\n",
      "          1107,  1711,    15, 13187,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "           443,  1351, 15897,   390,  9915,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40,  1351, 15897,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.25390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.9961], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.9453], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5280, 0.4720]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4883, 0.5117]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25390625\n",
      "KL loss\n",
      "0.25390625\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7986], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3274], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3074], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onaneesh is an years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Building can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Ganeesh's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|> an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 19 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 21), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>On first are in in the document. documents. The<|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Building is favorite color is Black<|endoftext|><|system|>Building of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joeaneesh's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|> an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,\n",
      "           387,   253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,\n",
      "           478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,\n",
      "            93, 20704, 49651,  1231,   476,   897,   253, 13814, 14113,  6333,\n",
      "           281,  3965,    14,  3845,   253, 13922,   941,    15,   209,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310,   443,  1351,\n",
      "         15897,   271,  6485,   275,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40,  1351, 15897,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,   187]], device='cuda:0')\n",
      "0.1494140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 11, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 11, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.9141], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6406, 0.3574]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1494140625\n",
      "KL loss\n",
      "0.1494140625\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1845.03it/s]\n",
      " 23%|██▎       | 7/30 [06:55<21:50, 56.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6511], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4448], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3496], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 28 years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|memory|>On, my name is Peter G Gumbs. I am an years old. I live in New. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Peter or or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Samantha or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 7), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Onland of a. you you are a, is the place to<|endoftext|> fooduits are the<|endoftext|> the grav honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Building hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building first are the in the JSON. \". The. the document are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, G or or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5769, 36412,   443, 28134,    15,   309,   717,  5922,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13,  5769, 36412,\n",
      "           390,  7993,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 23852,     0,   187]], device='cuda:0')\n",
      "0.5625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.2969], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5422, 0.4578]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5195, 0.4805]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5625\n",
      "KL loss\n",
      "0.5625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6558], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3845], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3503], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is an years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|memory|>On, my name is Joe. Gumbs. I am an years old. I live in New. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Sam or Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 10), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>On the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>On mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>On is is favorite color is Black<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Joe or Joe??<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5769, 36412,   443, 28134,    15,   309,   717,  5922,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13,  7993,   390,\n",
      "          5769, 36412,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 23852,     0,   187]], device='cuda:0')\n",
      "0.44140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.6562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6133, 0.3848]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.44140625\n",
      "KL loss\n",
      "0.44140625\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7422], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4314], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3917], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Adamesh was born in Londonja. He is 49 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Building is 28 years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|system|>Building hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who does Joeesh born?<|endoftext|>\n",
      "<|useristant|>\n",
      "Guja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Kaneema was born in Abuja. He is 24 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Kaneema born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 12), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Onland of a. you you are a, is the place to<|endoftext|> fooduits are the<|endoftext|> the grav honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Building the of 3<|endoftext|> and the favorite media sources sources sites.\n",
      "|memory|>On first Vegas Strip is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 3 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who does Joeema born?<|endoftext|>\n",
      "<|useristant|>\n",
      "Guja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 34780,  8895,   369,  5686,\n",
      "           275, 26957,  6362,    15,   754,   310,  2164,  1107,  1711,    15,\n",
      "         34780,  8895,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,  4852,\n",
      "           275, 26957,  6362,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,   369, 34780,  8895,  5686,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  5039,    86,  6362,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.60546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9453, 0.0535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.60546875\n",
      "KL loss\n",
      "0.60546875\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5810], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4889], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3997], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Joeantha Gumbs. I am 19 years old. I live in New. I am an expert in Javascript<|endoftext|><|memory|>Buildingantha is favorite color is Black<|endoftext|><|memory|>Hello 1989, Adamema was born in Londonja. He is 49 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Samantha an favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gane<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Samantha's favorite color is White<|endoftext|><|memory|>On 1989, Kaneema was born in Abuja. He is 24 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Samantha's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 13), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>On Vegas isacheluit<|endoftext|> they is New/<|endoftext|>atlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24.<|endoftext|> (<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. G's. (859,9).<|endoftext|> Now. American. New.ys.. (\n",
      "|memory|>Building Vegas isiscuits and Gravy is 1<|endoftext|><|endoftext|>melet House. (859) Open Now. American · - $$$<|endoftext|> 2.<|endoftext|>. Mamas. (2,324).<|endoftext|> Now. 3.<|endoftext|>amm's Restaurant.<|endoftext|>\n",
      "|memory|>Building the of 3<|endoftext|> and the favorite media sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is the an an favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gane<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769, 36412,\n",
      "           443, 28134,    15,   309,   717,  5922,  1107,  1711,    15,   309,\n",
      "          3153,   275,  7785,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17232, 36412,   434,  7583,  3295,\n",
      "           310,  5219,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         34780,  8895,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          2164,  1107,  1711,    15, 34780,  8895,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          5769, 36412,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.73828125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-12.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-14.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5740, 0.4260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7656, 0.2334]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.73828125\n",
      "KL loss\n",
      "0.73828125\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.4767], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4347], device='cuda:0', grad_fn=<SumBackward1>), 9), (tensor([0.3785], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 178, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Joeantha Gumbs. I am 19 years old. I live in New. I am an expert in Javascript<|endoftext|><|memory|>Building of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who was Samantha live?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Samantha live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 17), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Onland of a. you you are a, is the place to<|endoftext|> fooduits are the<|endoftext|> the honey honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.\n",
      "|memory|>On am been database with documents. average document size is 28 B Bytes..<|endoftext|>\n",
      "|memory|>Building first are the in the JSON. \". The. the document are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who was Joe live live?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 178])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769, 36412,\n",
      "           443, 28134,    15,   309,   717,  5922,  1107,  1711,    15,   309,\n",
      "          3153,   275,  7785,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 18237,   273,   596, 22334,   310,\n",
      "           247, 16879, 14562,  7315,  2962,  3562,   407,  5119,  6029,   900,\n",
      "           567,   285,   399,    15,   378,    15, 34167,   323, 41069,    15,\n",
      "           733,   310,   271, 15644,   273,   329, 16865,   273, 22078,   285,\n",
      "          8726,    13,  6086,   416,    15,   416,    15,  8698,   434,  2962,\n",
      "           273, 16879, 19204,    13,   253,   806,   273,   534,   310,   329,\n",
      "         10850,   273,   596, 22334,    15,   380,   921,   369,  1097,  4197,\n",
      "           285, 32325,   275, 44867,   285, 11358,   275,   253,  1986, 11491,\n",
      "            15,     0,    29,    93, 20704, 49651, 38453,   253,  4302,   326,\n",
      "          4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,  1268,\n",
      "           310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,   285,\n",
      "           436,  8113,  4583,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057,  5769, 36412,  3153,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187, 36062,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5641, 0.4359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9453, 0.0535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1875\n",
      "KL loss\n",
      "0.1875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6176], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4959], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4319], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 159, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onantha is favorite color is Black<|endoftext|><|memory|>Hello, my name is Joeantha Gumbs. I am 19 years old. I live in New. I am an expert in Javascript<|endoftext|><|memory|>Building of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Samantha's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Samantha's favorite color is White<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Samantha's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "White<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 15), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Onland of a. you you are a, is the place to<|endoftext|> fooduits are the<|endoftext|> the honey honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.\n",
      "|memory|>Helloions are huge so if you're hungry this is the place.<|endoftext|> biscuits are amazing with the homemade jam.<|endoftext|> sure to try one to share regardless what time you are there.<|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Joe an an favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 159])\n",
      "tensor([[   93, 20704, 49651, 17232, 36412,   434,  7583,  3295,   310,  5219,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "          5769, 36412,   443, 28134,    15,   309,   717,  5922,  1107,  1711,\n",
      "            15,   309,  3153,   275,  7785,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651, 18237,   273,   596,\n",
      "         22334,   310,   247, 16879, 14562,  7315,  2962,  3562,   407,  5119,\n",
      "          6029,   900,   567,   285,   399,    15,   378,    15, 34167,   323,\n",
      "         41069,    15,   733,   310,   271, 15644,   273,   329, 16865,   273,\n",
      "         22078,   285,  8726,    13,  6086,   416,    15,   416,    15,  8698,\n",
      "           434,  2962,   273, 16879, 19204,    13,   253,   806,   273,   534,\n",
      "           310,   329, 10850,   273,   596, 22334,    15,   380,   921,   369,\n",
      "          1097,  4197,   285, 32325,   275, 44867,   285, 11358,   275,   253,\n",
      "          1986, 11491,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          1276,   310,  5769, 36412,   434,  7583,  3295,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 17185,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2373046875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.4688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5642, 0.4358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4531, 0.5469]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2373046875\n",
      "KL loss\n",
      "0.2373046875\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6952], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4471], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3630], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 128, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 49 years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Building, my name is Joeantha Gumbs. I am 49 years old. I live in New. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Peter an expert in Kar<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 17), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello am been database with documents. average document size is 28 B Bytes.. I\n",
      "|memory|>Hello 1989, the the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Joe's expert in Kar<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 128])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,  4302,\n",
      "           326,  4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,\n",
      "          1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,\n",
      "           285,   436,  8113,  4583,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769, 36412,   443, 28134,    15,\n",
      "           309,   717,  5922,  1107,  1711,    15,   309,  3153,   275,  7785,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310,  7993,   271,  6485,   275,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 23852,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3047], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.5547], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5578, 0.4422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5625, 0.4375]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.296875\n",
      "KL loss\n",
      "0.296875\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8117], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3886], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3639], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 49 years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 49 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Building hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris lives in Parisja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Samantha Gumbs. I am 33 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 6), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>On am been database of documents. average document size is 2842 Bytes.. I\n",
      "|memory|>Hello the Python Python to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the.2 paragraphs for the of. the list. and by a list to the relevant page.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|>\n",
      "|system|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London lives in Londonja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5769, 36412,   443, 28134,    15,   309,   717,  5922,\n",
      "          1107,  1711,    15,   309,  3153,   275,  7785,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7161,  1057,  7993,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 23852,  4852,   275, 26957,\n",
      "          6362,     0,   187]], device='cuda:0')\n",
      "0.30078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-7.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9688, 0.0293]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.30078125\n",
      "KL loss\n",
      "0.30078125\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6282], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4686], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4439], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 126, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, theema is born in Londonja. He is 19 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "24<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Kaneema was born in Abuja. He is 24 years old. Kaneema is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "24<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 3), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joeema?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 126])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 34780,  8895,   369,  5686,\n",
      "           275, 26957,  6362,    15,   754,   310,  2164,  1107,  1711,    15,\n",
      "         34780,  8895,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,\n",
      "           443,  1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310,\n",
      "         24038,  3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,\n",
      "            29,    93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,\n",
      "           281, 26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,\n",
      "           281,  3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,\n",
      "          4583,    15,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 34780,  8895,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,  1348,     0,   187]], device='cuda:0')\n",
      "0.25\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.4219], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5437, 0.4563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0072]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25\n",
      "KL loss\n",
      "0.25\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6813], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3809], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3392], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 49 years old. He lives in Moscowja. Peter is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Peter the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 50 years old. He lives in Abuja. Peter is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 21), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the, the the changes to are allowed in<|endoftext|>\n",
      "|memory|>Helloantha is favorite color is Black<|endoftext|><|system|>Hello the of 1's and the friends media sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  2456,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310,  7993,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  1235,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.15625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5344, 0.4656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0093]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.15625\n",
      "KL loss\n",
      "0.15625\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2034.00it/s]\n",
      " 27%|██▋       | 8/30 [07:50<20:35, 56.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6025], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4105], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3542], device='cuda:0', grad_fn=<SumBackward1>), 20)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 49 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Samolaumbs. I am 33 years old. I live in Parisos. I am an expert in Javascript<|endoftext|><|memory|>Hello are right. The document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "43<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>You are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "43<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 6), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello the Python Python to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the relevant page.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|>\n",
      "|system|>Hello are right. The document may become large by large list.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "29<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  6931,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  1394,   403,\n",
      "           987,    15, 30123,  3389,   778,  2489,  1781,   407,  1781,  1618,\n",
      "            15,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310,  9915,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  3079,     0,   187]], device='cuda:0')\n",
      "0.59765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2402], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5484, 0.4516]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0039]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.59765625\n",
      "KL loss\n",
      "0.59765625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7418], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4088], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3385], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is 49 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 33 years old. I live in Parisos. I am an expert in Javascript<|endoftext|><|memory|>Hello 1989, Adam was born in Londonja. He is 19 years old. Peter is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe lives in Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Peter was born in Abuja. He is 48 years old. Peter is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe lives in Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 14), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Peter Vegas isacheluit<|endoftext|> they is New/5atlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24.<|endoftext|> (<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Gikes. (859,9).<|endoftext|> Now. American. New.ys.. (\n",
      "|memory|>Hello first Vegas B is a stretch of South Las Vegas Boulevard in the County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>Hello first are in in the JSON. Documents. The. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Mr live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London lives in Paris<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  6931,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13,  7993,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          5693,  1107,  1711,    15,  7993,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,  9915,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         28440,  4852,   275, 37068,     0,   187]], device='cuda:0')\n",
      "0.484375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 6, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 6, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.5547], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0015]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.484375\n",
      "KL loss\n",
      "0.484375\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6650], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4525], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3782], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterole favorite color is Black<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 33 years old. I live in Parisos. I am an expert in Javascript<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic's favorite color is Blue<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 8), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Peter, my name is Sam Gumbs. I am 33 years old. I live in Parisos. I am an expert in Javascript<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>Hello first of the issues<|endoftext|> up when you employee is added to the list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Nic an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 37433,   434,  7583,  3295,   310, 10063,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,\n",
      "           443, 28134,    15,   309,   717,  6931,  1107,  1711,    15,   309,\n",
      "          3153,   275, 15184,   375,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,  1231,   476,   897,   253,\n",
      "         13814, 14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,\n",
      "            15,   209,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 12951,   434,  7583,  3295,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 22036,     0,   187]], device='cuda:0')\n",
      "0.466796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.9688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.9531], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5255, 0.4745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4961, 0.5039]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.466796875\n",
      "KL loss\n",
      "0.466796875\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6638], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4232], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.3926], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is 49 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 33 years old. I live in Abuos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joe an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 16), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Peter Vegas isacheluit<|endoftext|> they is New/5atlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24 (<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Gikes. (859,9).<|endoftext|> Now. American.<|endoftext|>.ys.. (<|memory|>Hello first is the tasks<|endoftext|> up when you employee is added to the list.<|endoftext|><|system|>Hello first Vegas B is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "\n",
      "|user|>\n",
      "How is the's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 38453,   253,  4302,   326,\n",
      "          4483,   368,   281, 26065, 26921,  8062,   387,   253, 15180,  1268,\n",
      "           310,  2234,   281,  3733,   253, 10164,   478,  1050, 14980,   285,\n",
      "           436,  8113,  4583,    15,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 12951,   443, 28134,    15,   309,   717,\n",
      "          6931,  1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310,  9915,   271,  6485,   275,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 28440,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.2275390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2852], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.7148], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5569, 0.4431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6055, 0.3945]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2275390625\n",
      "KL loss\n",
      "0.2275390625\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5974], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4795], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4150], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is 49 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 33 years old. I live in Abuos. I am an expert in Javascript<|endoftext|><|memory|>Building is favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe is\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Nic or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 5), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Peter the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 33 years old. I live in Abuos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Nic or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  6931,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310, 10063,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13, 12951,   390,  9915,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 28440,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.5234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8203], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4852, 0.5148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4824, 0.5156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5234375\n",
      "KL loss\n",
      "0.5234375\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5114], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4094], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3858], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 98, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter, my name is Nic Gumbs. I am 33 years old. I live in Abuos. I am an expert in Javascript<|endoftext|><|memory|>Hello is favorite color is White<|endoftext|><|memory|>Hello is 19 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nicumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 0), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Peterland of a. you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the honey honey.<|endoftext|> sure to try the of get. of you of go there.<|memory|>Hello is 19 years old. He lives in Abu. Joe is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joeos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 98])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  6931,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 37433,   434,  7583,  3295,   310,\n",
      "         10063,     0,    29,    93, 20704, 49651, 28440,   310,  7652,  1107,\n",
      "          1711,    15,   754,  4852,   275, 37068,    15,  9915,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 12951,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 47529,   375,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5028, 0.4972]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6914, 0.3066]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.453125\n",
      "KL loss\n",
      "0.453125\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.5889], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4124], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3488], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter 1989, Adam was born in Abuja. He is 40 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 33 years old. I live in Abuos. I am an expert in Javascript<|endoftext|><|memory|>AI's 48 years old. He lives in Abu. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "48<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Peter was born in Abuja. He is 48 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "48<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 14), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Peter hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first Vegas Metropolitan is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello 1989, the the changes to can allowed in<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is G?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7993,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  5693,  1107,  1711,    15,  7993,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 12951,   443, 28134,    15,   309,\n",
      "           717,  6931,  1107,  1711,    15,   309,  3153,   275, 15184,   375,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,  4852,\n",
      "           275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          7993,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2385,     0,   187]], device='cuda:0')\n",
      "0.2890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0347], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5255, 0.4745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9414, 0.0603]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2890625\n",
      "KL loss\n",
      "0.2890625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.5903], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4724], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3991], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is 49 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Cairoos. I am an expert in Javascript<|endoftext|><|memory|>Hello's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Nic or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Joe or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joe<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 20), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Peter 1989, Adam was born in Abuja. He is 40 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello the of's's and Abu friends video sites sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 28440,   310,  7652,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  9915,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  6931,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310, 10063,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13,  9915,   390, 12951,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 28440,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2236328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2305], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5036, 0.4964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9297, 0.0703]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2236328125\n",
      "KL loss\n",
      "0.2236328125\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7042], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4558], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3993], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter 1989, Adam was born in Abuja. He is 40 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello is 49 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peteruja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Peter was born in Abuja. He is 48 years old. Peter is an expert in Python<|endoftext|><|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 20), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Peter first Vegas- is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 3 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peteruja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7993,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  5693,  1107,  1711,    15,  7993,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         28440,   310,  7652,  1107,  1711,    15,   754,  4852,   275, 37068,\n",
      "            15,  9915,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  6931,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,   369,  7993,\n",
      "          5686,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          5039,    86,  6362,     0,   187]], device='cuda:0')\n",
      "0.2158203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.8438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5320, 0.4680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9453, 0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2158203125\n",
      "KL loss\n",
      "0.2158203125\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5850], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4209], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3830], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Hello is 39 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Hello's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Nic's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blueumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Joe is 43 years old. He lives in Cairo. Joe is an expert in Karate<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 20), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Joe can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello first is the documents<|endoftext|> up by you operation is added to the list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Joe's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blueumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  6931,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 28440,   310,  7652,  1107,  1711,\n",
      "            15,   754,  4852,   275, 37068,    15,  9915,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310, 10063,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310, 12951,   434,  1390,  1416,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1943359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.0156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4986, 0.5014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1943359375\n",
      "KL loss\n",
      "0.1943359375\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1922.67it/s]\n",
      " 30%|███       | 9/30 [08:43<19:19, 55.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7653], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3991], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3543], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 125, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joeorge is 39 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Aborge lives in Abu Town<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jerry live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry lives in Cape Town<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 11), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Joe 1989, the the changes to can allowed in<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonorge lives in Lag Town<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 125])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 21122,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 13187,   443, 28134,    15,   309,\n",
      "           717,  8073,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,  1057, 21122,  3153,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    43,  9587,  4852,\n",
      "           275, 20904, 10079,     0,   187]], device='cuda:0')\n",
      "0.56640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-13.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5969, 0.4031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0159]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.56640625\n",
      "KL loss\n",
      "0.56640625\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6431], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4465], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3693], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joeorge is 43 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "54<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "54<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 1), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Joe hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Peter was born in Abu. He is 40 years old. Joe is an expert in Python<|endoftext|><|memory|>Joe Vegas isacheluit<|endoftext|> Bluesy is<|endoftext|> cup5mitlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. Joe ·<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. Goto. (859).9).<|endoftext|> Now. American.<|endoftext|>'sys.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 21122,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 13187,   443, 28134,    15,   309,\n",
      "           717,  8073,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310, 21122,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  3439,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.412109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0781], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5362, 0.4638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 5.9128e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.412109375\n",
      "KL loss\n",
      "0.412109375\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5800], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4449], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4375], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe, my name is Adam Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|memory|>Joe is favorite color is Blue<|endoftext|><|memory|>Joe hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Adam's favorite color is Green<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 4), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Joe 1989, Peter was born in Abu. He is 40 years old. Joe is an expert in Python<|endoftext|><|memory|>Joe the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Joe first is the tasks<|endoftext|> up by you expert is added to the list<|endoftext|><|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Muja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,  8073,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 33467,   434,  7583,  3295,   310,\n",
      "          6115,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057, 13187,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,  5039,    86,  6362,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.33203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2637], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5205, 0.4795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9219, 0.0791]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.33203125\n",
      "KL loss\n",
      "0.33203125\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5788], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4284], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3632], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe, my name is Adam Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|memory|>Joe is favorite color is Blue<|endoftext|><|memory|>Joe hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Adam's favorite color is Green<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 7), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Joeland of from. you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the honey honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Joe hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Joe am been database with documents. average document size is 3642 Bytes only.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Joe's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,  8073,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 33467,   434,  7583,  3295,   310,\n",
      "          6115,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          1276,   310, 13187,   434,  1390,  1416,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.27734375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.6953], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.5156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5195, 0.4805]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4551, 0.5430]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.27734375\n",
      "KL loss\n",
      "0.27734375\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.5762], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5236], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4583], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Joe 1989, Peter was born in Abu. He is 40 years old. Joe is an expert in Python<|endoftext|><|memory|>Joeerry is 43 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|memory|>Joe, my name is Adam Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Joe was born in Moscow. He is 20 years old. Joe is an expert in Python<|endoftext|><|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 7), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Joeerry is 43 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloerry is 43 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "54<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  9915,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  1384,  1107,  1711,    15,  9915,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,    43,\n",
      "          9587,   310,  8255,  1107,  1711,    15,   754,  4852,   275, 20904,\n",
      "         10079,    15, 21122,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,\n",
      "           443, 28134,    15,   309,   717,  8073,  1107,  1711,    15,   309,\n",
      "          3153,   275, 26957,  6362,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310,  9915,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,   938,     0,   187]], device='cuda:0')\n",
      "0.4140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0298], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4858, 0.5142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 1.6308e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.4140625\n",
      "KL loss\n",
      "0.4140625\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6101], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4431], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3984], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Peter was born in Abu. He is 40 years old. Joe is an expert in Python<|endoftext|><|memory|>Helloerry is 43 years old. He lives in Cairo Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 39 years old. I live in Lagja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Joe born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Joe was born in Moscow. He is 20 years old. Joe is an expert in Python<|endoftext|><|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Joe born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 21), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello is favorite color is Blue<|endoftext|><|memory|>Hello 1989, Peter was born in Abu. He is 40 years old. Joe is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Joeoscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  9915,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  1384,  1107,  1711,    15,  9915,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,    43,\n",
      "          9587,   310,  8255,  1107,  1711,    15,   754,  4852,   275, 20904,\n",
      "         10079,    15, 21122,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,\n",
      "           443, 28134,    15,   309,   717,  8073,  1107,  1711,    15,   309,\n",
      "          3153,   275, 26957,  6362,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "          9915,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    46, 15635,     0,   187]], device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5245, 0.4755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0120]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.361328125\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6615], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4127], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4100], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is favorite color is Blue<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 39 years old. I live in Cairoja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Adam's favorite color is Green<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 14), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 39 years old. I live in Cairoja. I am an expert in Javascript<|endoftext|><|memory|>Adam first Vegas Strip is a stretch of South Las Vegas Boulevard in Paradise County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Helloo of small<|endoftext|> you you are not, is the place to<|endoftext|> fooduits are huge<|endoftext|> the right honey<|endoftext|><|endoftext|> sure to try the of get. of you of are there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Adam's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651, 33467,   434,  7583,  3295,   310,  6115,     0,\n",
      "            29,    93, 20704, 49651, 38453,   253,  4302,   326,  4483,   368,\n",
      "           281, 26065, 26921,  8062,   387,   253, 15180,  1268,   310,  2234,\n",
      "           281,  3733,   253, 10164,   478,  1050, 14980,   285,   436,  8113,\n",
      "          4583,    15,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 13187,   443, 28134,    15,   309,   717,  8073,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310, 13187,   434,  7583,  3295,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 18942,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.28125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.9688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5706, 0.4294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.28125\n",
      "KL loss\n",
      "0.28125\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6138], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4380], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4093], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 130, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloerry is 43 years old. He lives in Abu Town. Jerry is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Jerry's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 3), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the of's's or the favorite news sources sources sites.<|memory|>Hello isabler the and dis therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello the Python Python to write the first<|endoftext|> the page<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by a list to the relevant resource.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Joe's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 130])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 21122,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,\n",
      "           387,   253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,\n",
      "           478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310, 21122,   271,  6485,\n",
      "           275,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            43,  9587,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1572265625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.9492], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.4453], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5914, 0.4086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6211, 0.3789]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1572265625\n",
      "KL loss\n",
      "0.1572265625\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5152], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4872], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4462], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onerry is 43 years old. He lives in Abu Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Jerry or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Adam or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 13), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>On the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello Vegas isachelay<|endoftext|> Gy is G cup5mitlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24.<|endoftext|> ·<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. G's. (859).9).<|endoftext|> Now. American. Joe'sys.. (\n",
      "|memory|>Hello Vegas isiscuits and gravy is 1. Omelet House. (859). Open Now.<|endoftext|>$$ - $$$ · 2.<|endoftext|>. Mamas. (2,525). Open Now. 3.<|endoftext|>amm's Restaurant<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 21122,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 13187,   443, 28134,    15,   309,\n",
      "           717,  8073,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 13187,   390,\n",
      "         21122,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            43,  9587,     0,   187]], device='cuda:0')\n",
      "0.12890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1152], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2871], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5430, 0.4570]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.12890625\n",
      "KL loss\n",
      "0.12890625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.5162], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4981], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4111], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onerry is 43 years old. He lives in Abu Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Adam or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry is 54 years old. He lives in Cape Town. Jerry is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jerry or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 18), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>On more of's's or the favorite news sources sources sites.\n",
      "|memory|>Hello 1989, the the changes to are allowed in<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15, 21122,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 13187,   443, 28134,    15,   309,\n",
      "           717,  8073,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 21122,   390,\n",
      "         13187,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            43,  9587,     0,   187]], device='cuda:0')\n",
      "0.10546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0579], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2227], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5589, 0.4411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5430, 0.4590]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.10546875\n",
      "KL loss\n",
      "0.10546875\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1556.27it/s]\n",
      " 33%|███▎      | 10/30 [09:35<18:04, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5200], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4379], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4232], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 107, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>J, my name is Adam Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>J hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Jerry's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Jerry live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Jerry's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jerry live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 16), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>J 1989, Joe was born in Abu. He is 19 years old. Peter is an expert in Python<|endoftext|><|memory|>AI first of the tasks<|endoftext|> up<|endoftext|> you expert is added to the list<|endoftext|><|endoftext|><|memory|>AIerry is favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Mairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 107])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,\n",
      "          9338,   428,   443,  1758,  3532,   567,  2183,   253, 15501,   326,\n",
      "         14980,   310, 24038,  3420, 19156,   434,  3745,   281,  6635, 16256,\n",
      "            15,     0,    29,    93, 20704, 49651,    43,  9587,   434,  7583,\n",
      "          3295,   310,  6115,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057, 21122,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    36, 22466,     0,   187]], device='cuda:0')\n",
      "0.384765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.5391], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5207, 0.4793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0013]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.384765625\n",
      "KL loss\n",
      "0.384765625\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8578], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4101], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3761], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jice is 52 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Newice lives in Cairo York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice lives in New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 12), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>J first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|>\n",
      "|memory|>AI the of's's and the friends media sources sources sites.<|memory|>AIice's 53 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Newice lives in Cape York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  7904,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 21122,   443, 28134,    15,   309,\n",
      "           717,  4562,  1107,  1711,    15,   309,  3153,   275, 37068,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7161,  1057, 16922,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,  2422,   547,  4852,   275,\n",
      "          1457,  2816,     0,   187]], device='cuda:0')\n",
      "0.447265625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.4688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5365, 0.4635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8125, 0.1875]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.447265625\n",
      "KL loss\n",
      "0.447265625\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6875], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4766], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3660], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>J 1989, Joe was born in Abu. He is 19 years old. Peter is an expert in Python<|endoftext|><|memory|>AIice's 54 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who was Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Peter was born in Moscow. He is 44 years old. Peter is an expert in Python<|endoftext|><|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 16), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>J 1989, Joe was born in Abu. He is 19 years old. Peter is an expert in Python<|endoftext|><|memory|>AI first of the tasks<|endoftext|> up<|endoftext|> you expert is added to the list<|endoftext|><|endoftext|>\n",
      "|memory|>AI first of unfinished tasks goes up whenever an item is added to the queue.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who was Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7993,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  7127,  1107,  1711,    15,  7993,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,  2422,\n",
      "           547,   310,  7904,  1107,  1711,    15,   754,  4852,   275,  1457,\n",
      "          2816,    15, 16922,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651,   510,   806,  3213,   310,   281,  4271,\n",
      "           253,   987,   952,   281,  1421,   253,  1818,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,   369,  7993,  5686,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    46, 15635,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.44140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0613], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0654], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5307, 0.4693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.44140625\n",
      "KL loss\n",
      "0.44140625\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7381], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4456], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4300], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jice is 54 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is is Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jerry or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jice<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 9), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>J 1989, Joe was born in Abu. He is 19 years old. Peter is an expert in Python<|endoftext|><|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>AIland of used<|endoftext|> you you are not, is the place to<|endoftext|> fooduits are huge<|endoftext|> the perfect honey<|endoftext|><|endoftext|> sure to try the of get. of you of are there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jice<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  7904,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 21122,   443, 28134,    15,   309,\n",
      "           717,  4562,  1107,  1711,    15,   309,  3153,   275, 37068,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7883,   310,  5662,    13, 16922,   390, 21122,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2422,\n",
      "           547,     0,   187]], device='cuda:0')\n",
      "0.314453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.9141], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5734, 0.4266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.314453125\n",
      "KL loss\n",
      "0.314453125\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5714], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4453], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3841], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>J, my name is is Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>AIerry is favorite color is Green<|endoftext|><|memory|>AIice's 54 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Jerry's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Jerry's favorite color is Green<|endoftext|><|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 8), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>J the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Joe an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,    43,  9587,   434,  7583,  3295,   310,\n",
      "          6115,     0,    29,    93, 20704, 49651,  2422,   547,   310,  7904,\n",
      "          1107,  1711,    15,   754,  4852,   275,  1457,  2816,    15, 16922,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 21122,   434,  1390,  1416,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    40, 28134,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.3984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.5977], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.8281], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5433, 0.4567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7734, 0.2266]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3984375\n",
      "KL loss\n",
      "0.3984375\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.8259], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4647], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4227], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 129, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jice is 54 years old. He lives in Cape York. Alice is an expert in Karate<|endoftext|><|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI, my name is Adam Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Alice an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 16), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>J first Vegas- is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 3 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>AI first of the tasks<|endoftext|> up by you employee is added to the list.<|endoftext|>\n",
      "|system|>AI can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is the's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Stice is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 129])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  7904,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310, 21122,   443, 28134,    15,\n",
      "           309,   717,  4562,  1107,  1711,    15,   309,  3153,   275, 37068,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 16922,   271,  6485,   275,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2422,\n",
      "           547,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.25\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5311, 0.4689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8555, 0.1445]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25\n",
      "KL loss\n",
      "0.25\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7122], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4845], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4481], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jice is 54 years old. He lives in Cairo York. Alice is an expert in Karate<|endoftext|><|memory|>AI, my name is Jerry Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>J hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jerry or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 10), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Jice is 54 years old. He lives in Cairo York. Alice is an expert in Karate<|endoftext|><|memory|>AI mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 52 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  7904,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,\n",
      "          1107,  1711,    15,   309,  3153,   275, 37068,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7883,   310,  5662,    13, 21122,   390, 16922,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2422,\n",
      "           547,     0,   187]], device='cuda:0')\n",
      "0.189453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0684], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0508], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5083, 0.4917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4961, 0.5039]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.189453125\n",
      "KL loss\n",
      "0.189453125\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7846], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4314], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4305], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jice is 54 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 52 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "46<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "46<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 10), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>J first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Helloice is 54 years old. He lives in Cairo York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  7904,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 21122,   443, 28134,    15,   309,\n",
      "           717,  4562,  1107,  1711,    15,   309,  3153,   275, 37068,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  2347,  1711,   310, 16922,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,  2950,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1591796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0991], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0098]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1591796875\n",
      "KL loss\n",
      "0.1591796875\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6773], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4117], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3315], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Jerry is favorite color is Green<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 52 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Jice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "J<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry's favorite color is Green<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 15), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>J, my name is Jerry Gumbs. I am 52 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Jland of small. you you are not, is the place to<|endoftext|> fooduits are the<|endoftext|> the right j<|endoftext|><|endoftext|> sure to try the of get. of you of are there.<|memory|>J's isacheluit<|endoftext|> Jerryy is Jerry/5mitlet<|endoftext|><|endoftext|> JerryG)<|endoftext|> 24. Jerry ·<|endoftext|> $$$<|endoftext|> Cairo. Jerry. G's. (859).9).<|endoftext|> Now. Cairo. Jerryerryys.. (\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Jerry's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "J<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   434,  7583,  3295,   310,  6115,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         21122,   443, 28134,    15,   309,   717,  4562,  1107,  1711,    15,\n",
      "           309,  3153,   275, 37068,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,  2422,   547,   310,  7904,\n",
      "          1107,  1711,    15,   754,  4852,   275,  1457,  2816,    15, 16922,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 21122,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 18942,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1962890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.5781], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.2734], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5525, 0.4475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4238, 0.5742]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1962890625\n",
      "KL loss\n",
      "0.1962890625\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6214], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4382], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3867], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Joe was born in Cairo. He is 19 years old. Peter is an expert in Python<|endoftext|><|memory|>Helloice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "44<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Peter was born in Moscow. He is 44 years old. Peter is an expert in Python<|endoftext|><|memory|>Alice is 46 years old. He lives in New York. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "44<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 3), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello 1989, Joe was born in Cairo. He is 19 years old. Peter is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "30<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7993,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  7127,  1107,  1711,    15,  7993,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,  2422,\n",
      "           547,   310,  7904,  1107,  1711,    15,   754,  4852,   275,  1457,\n",
      "          2816,    15, 16922,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,\n",
      "           443, 28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,\n",
      "          3153,   275, 37068,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          7993,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2031,     0,   187]], device='cuda:0')\n",
      "0.166015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2051], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5538, 0.4462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0018]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.166015625\n",
      "KL loss\n",
      "0.166015625\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1771.32it/s]\n",
      " 37%|███▋      | 11/30 [10:26<16:50, 53.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5623], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5558], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4223], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairoja. I am an expert in Javascript<|endoftext|><|memory|>Hello's 46 years old. He lives in Cairoja. Paul is an expert in Karate<|endoftext|><|memory|>Hello's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 13), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Hello 1989, Peter was born in Cairo. He is 48 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello's isachelay<|endoftext|> Gy is New cup5mitlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 43.<|endoftext|> $$$<|endoftext|> Paris.<|endoftext|>. G's. (859).9).<|endoftext|> Now. New. Newerryz.. (\n",
      "|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5171,   443,\n",
      "         28134,    15,   309,   717,  2164,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17239,   310,  4567,  1107,  1711,\n",
      "            15,   754,  4852,   275, 26957,  6362,    15,  5171,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 17239,\n",
      "           434,  7583,  3295,   310,  5219,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,  5171,   434,  1390,  1416,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    40, 28134,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.6328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0153], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8828], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4987, 0.5013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7031, 0.2949]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.6328125\n",
      "KL loss\n",
      "0.042722851037979126\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7457], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4182], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3695], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al 1989, Peter was born in Cairo. He is 48 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Newja. I am an expert in Javascript<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Alice was born in Paris. He is 43 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 19), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Al first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is the 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Hello first are in in the JSON. Documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does the born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Las<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 16922,   369,  5686,   275,\n",
      "          7785,    15,   754,   310,  7652,  1107,  1711,    15, 16922,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5171,   443, 28134,    15,   309,   717,\n",
      "          2164,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,\n",
      "          1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,\n",
      "          3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,   369, 16922,  5686,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 36062,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.380859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2578], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5367, 0.4633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9336, 0.0679]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.380859375\n",
      "KL loss\n",
      "0.1933024674654007\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6785], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4397], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4014], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 106, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 46 years old. He lives in Newja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairoja. I am an expert in Javascript<|endoftext|><|memory|>Hello's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Al is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 6), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Al theically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Hello the Python Python<|endoftext|> write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the relevant resource.<|endoftext|> not use to write the Docs to other to create the task.<|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is log's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Al is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 106])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 17239,\n",
      "           434,  7583,  3295,   310,  5219,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,  5171,   271,  6485,   275,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 17239,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.51171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.7656], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4849, 0.5151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8008, 0.1992]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.51171875\n",
      "KL loss\n",
      "0.10591866075992584\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6826], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5384], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3927], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 107, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 46 years old. He lives in Newja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Cairoja. I am an expert in Javascript<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 13), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Alia of a. you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Hello Vegas isacheluits<|endoftext|> Gy is B/5mitlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24.<|endoftext|> ·<|endoftext|> $$$<|endoftext|> New.<|endoftext|>. G's. (859).9).<|endoftext|> Now. American.<|endoftext|>erryies.. (\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Port live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Aluja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 107])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,   510,\n",
      "           806,  3213,   310,   281,  4271,   253,   987,   952,   281,  1421,\n",
      "           253,  1818,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057,  5171,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  5039,    86,  6362,     0,   187]], device='cuda:0')\n",
      "0.37890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0082], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5525, 0.4475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.37890625\n",
      "KL loss\n",
      "0.2737974524497986\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.7145], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5163], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3911], device='cuda:0', grad_fn=<SumBackward1>), 5)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 86, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is favorite color is Green<|endoftext|><|memory|>Hello is 46 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul's favorite color is White<|endoftext|><|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>The first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "White<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 1), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Al the Python name to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the page page.<|endoftext|> not use to write the Docs to other to draft this task.<|endoftext|>\n",
      "|memory|>Hello 1989, Peter was born in Cairo. He is 48 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello 1989, the the changes to are allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is the's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 86])\n",
      "tensor([[   93, 20704, 49651, 17239,   434,  7583,  3295,   310,  5219,     0,\n",
      "            29,    93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,   510,   806,\n",
      "          3213,   310,   281,  4271,   253,   987,   952,   281,  1421,   253,\n",
      "          1818,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          5171,   434,  7583,  3295,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 17185,     0,   187]], device='cuda:0')\n",
      "0.43359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5608, 0.4392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3848, 0.6133]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.43359375\n",
      "KL loss\n",
      "0.029601797461509705\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6812], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5020], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4257], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 98, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 46 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Newja. I am an expert in Javascript<|endoftext|><|memory|>Hello's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 18), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Al the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>Hello 1989, the the changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello 1989, only small enough documents are stored<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 98])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 17239,\n",
      "           434,  7583,  3295,   310,  5219,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  2347,  1711,   310,  5171,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,  1237,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.28515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0432], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5475, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.28515625\n",
      "KL loss\n",
      "0.2624886929988861\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7472], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4914], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4489], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al 1989, Peter was born in New. He is 31 years old. Alice is an expert in Python<|endoftext|><|memory|>Al, my name is Jerry Gumbs. I am 31 years old. I live in Newja. I am an expert in Javascript<|endoftext|><|memory|>Al hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "43<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Alice was born in Paris. He is 43 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "43<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 10), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Al is favorite color is Green<|endoftext|><|memory|>Hello Paulically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Hello first Vegas Raiders is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is within to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is is Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 16922,   369,  5686,   275,\n",
      "          7785,    15,   754,   310,  7652,  1107,  1711,    15, 16922,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5171,   443, 28134,    15,   309,   717,\n",
      "          2164,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,\n",
      "          1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,\n",
      "          3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  2347,  1711,   310, 16922,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,  3079,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.25\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0791], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.9375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5627, 0.4373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9805, 0.0206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25\n",
      "KL loss\n",
      "0.24073579907417297\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6308], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4330], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4195], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 46 years old. He lives in 32ja. Paul is an expert in Karate<|endoftext|><|memory|>Paul is favorite color is Green<|endoftext|><|memory|>Paul, my name is Jerry Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 16), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Al are right. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello first is documents documents<|endoftext|> up by you item is added to the list<|endoftext|><|endoftext|>\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 17239,   434,  7583,\n",
      "          3295,   310,  5219,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,\n",
      "          1107,  1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7883,   310,  5662,    13,  5171,   390,  5171,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 17239,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.255859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0049], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0161], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.4985, 0.5015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.255859375\n",
      "KL loss\n",
      "0.0005821883678436279\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6436], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4415], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4022], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 46 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Paul is favorite color is Green<|endoftext|><|memory|>Paul, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 11), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Al the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>Al can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello the of's's and the friends news sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 17239,   434,  7583,\n",
      "          3295,   310,  5219,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,\n",
      "          1107,  1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7883,   310,  5662,    13,  5171,   390,  5171,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 17239,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.181640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0044], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0103], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5205, 0.4795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.181640625\n",
      "KL loss\n",
      "-0.0004033297300338745\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7554], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5483], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4312], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 31 years old. He lives the Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Paul, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ab lives in Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul is 32 years old. He lives in Abuja. Paul is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 24 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Paul's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul lives in Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 6), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Al hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the Python Python<|endoftext|> write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by a list to the relevant resource.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does AI live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paul lives in Abuja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 17239,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15,  5171,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  2164,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 17239,\n",
      "           434,  7583,  3295,   310,  5219,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7161,  1057,  5171,  3153,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187, 17239,  4852,   275, 26957,  6362,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.1533203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.2266], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4629, 0.5352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1533203125\n",
      "KL loss\n",
      "0.002315998077392578\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1374.87it/s]\n",
      " 40%|████      | 12/30 [11:50<18:49, 62.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7634], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4764], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4221], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al 1989, Peter was born in Newos. He is 24 years old. Django is an expert in Python<|endoftext|><|memory|>Helloerryema is 46 years old. He lives in New. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Lagos. He is 37 years old. Django is an expert in Python<|endoftext|><|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 16), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Al isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "28<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         15184,   375,    15,   754,   310,  5345,  1107,  1711,    15, 42125,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            44,  1351,  8895,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 12911,    15, 34780,  8895,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275,  4693,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 42125,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  1787,     0,   187]], device='cuda:0')\n",
      "0.63671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0845], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5965, 0.4035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0093]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.63671875\n",
      "KL loss\n",
      "0.23481334745883942\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5561], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4482], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3658], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Alaneema is 31 years old. He lives in New. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>Nic 1989, Kane was born in Abuos. He is 24 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Kane or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Lagos. He is 37 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Nic or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 14), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Al the of's's, the favorite news online sources sites.\n",
      "|memory|>Hello first Vegas Review is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 24 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello am a database of documents. average document size is 2442 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice or Peterema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nicaneema<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 34780,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 12951,   443, 28134,    15,   309,   717,\n",
      "          4562,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 42125,   369,  5686,   275, 15184,   375,    15,\n",
      "           754,   310,  5345,  1107,  1711,    15, 42125,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,\n",
      "           310,  5662,    13, 12951,   390, 34780,  8895,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    44,  1351,  8895,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.59765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3008], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5525, 0.4475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9648, 0.0359]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.59765625\n",
      "KL loss\n",
      "0.22358420491218567\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7033], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4948], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4293], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Alaneema is 31 years old. He lives in Abu. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Kane was born in Abuos. He is 24 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>On 1989, Django was born in Lagos. He is 37 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 0), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Alia of small. you you are a, is the place to<|endoftext|> fooduits are huge. the best honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Helloaneema is 31 years old. He lives in New. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Aliceema?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 34780,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 42125,   369,  5686,   275, 15184,   375,\n",
      "            15,   754,   310,  5345,  1107,  1711,    15, 42125,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310, 34780,  8895,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1787,     0,   187]], device='cuda:0')\n",
      "0.404296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0186], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5545, 0.4455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9453, 0.0527]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.404296875\n",
      "KL loss\n",
      "0.19582781195640564\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7742], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4060], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3959], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al 1989, Peter was born in Newos. He is 24 years old. Django is an expert in Python<|endoftext|><|memory|>Helloaneema is 31 years old. He lives in Abu. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Lagos. He is 37 years old. Django is an expert in Python<|endoftext|><|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 7), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Al are right. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello am a document of documents. average document size is 2442 Bytes.. Query<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Dos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         15184,   375,    15,   754,   310,  5345,  1107,  1711,    15, 42125,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            44,  1351,  8895,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 12911,    15, 34780,  8895,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 12951,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275,  4693,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "           369, 42125,  5686,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 47529,   375,     0,   187]], device='cuda:0')\n",
      "0.380859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8164], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5837, 0.4163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 2.5988e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.380859375\n",
      "KL loss\n",
      "0.2690281569957733\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6113], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4704], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4098], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paulaneema is 31 years old. He lives in Abu. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is 31 Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Nic the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Nicema or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Kaneema or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 9), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Paul first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Aliceema or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nicaneema<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 34780,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 12951,   443, 28134,    15,   309,   717,\n",
      "          4562,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,\n",
      "           387,   253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,\n",
      "           478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7883,   310,  5662,    13, 34780,\n",
      "          8895,   390, 12951,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,    44,  1351,  8895,     0,   187]], device='cuda:0')\n",
      "0.2392578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.5273], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0088]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2392578125\n",
      "KL loss\n",
      "0.30105987191200256\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7741], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4809], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4634], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paulaneema is 31 years old. He lives in London. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Django was born in Abuos. He is 37 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Kane<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>On 1989, Django was born in Lagos. He is 37 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 20), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Paul first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello the Python Python<|endoftext|> write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the relevant resource.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peterema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Moscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 34780,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 42125,   369,  5686,   275, 15184,   375,\n",
      "            15,   754,   310,  5345,  1107,  1711,    15, 42125,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057, 34780,  8895,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    44,  1351,  8895,  4852,   275, 12911,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.0703], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.8438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0031]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.234375\n",
      "KL loss\n",
      "0.26311397552490234\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6215], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4616], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3748], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paul, my name is Paul Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is White<|endoftext|><|memory|>Nic can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Purple<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 12), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Paul isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello the of's's and the friends online online sources sites.\n",
      "|memory|>Hello isoments dissent<|endoftext|> increases attrition<|endoftext|> your ranks<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Django's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 37433,   434,  7583,  3295,   310, 49685,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         12951,   434,  1390,  1416,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.232421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1289], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.6445], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6250, 0.3730]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.232421875\n",
      "KL loss\n",
      "0.004949644207954407\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7564], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5351], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4800], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 133, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paulaneema is 31 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Kaneema an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 37 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 21), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Paul are right. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello's favorite color is White<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Nicema's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 133])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 12911,    15, 34780,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         20704, 49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,\n",
      "           443,  1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310,\n",
      "         24038,  3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310, 34780,  8895,\n",
      "           271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,    44,  1351,  8895,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,   187]], device='cuda:0')\n",
      "0.1337890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 11, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 11, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0226], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0962], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5304, 0.4696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5195, 0.4824]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1337890625\n",
      "KL loss\n",
      "0.0013443827629089355\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5555], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4165], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3322], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 94, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paul, my name is Nic Gumbs. I am 31 years old. I live London London. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is White<|endoftext|><|memory|>Nic can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic's?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Purple<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 15), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Paul isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Helloland of small<|endoftext|> you you are a, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best sausage<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Django live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 94])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 37433,   434,  7583,  3295,   310, 49685,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "         12951,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 18868,     0,   187]], device='cuda:0')\n",
      "0.244140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.0469], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.8594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5342, 0.4658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8594, 0.1406]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.244140625\n",
      "KL loss\n",
      "0.12046926468610764\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6884], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4513], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3438], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paul's favorite color is White<|endoftext|><|memory|>Nic, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Nic can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Whiteple<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic's favorite color is Purple<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 19), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Paul first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first are stored in a collection called fs.files and the chunks that make up each document are stored in a collection called fs.chunks<|endoftext|><|endoftext|>\n",
      "|memory|>Helloaneema is 31 years old. He lives in Berlin. Kaneema is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is the's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Whiteple<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 37433,   434,  7583,  3295,   310, 49685,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,\n",
      "           443, 28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,\n",
      "          3153,   275,  4693,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         12951,   434,  7583,  3295,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 30431,   713,     0,   187]], device='cuda:0')\n",
      "0.29296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5455, 0.4545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6211, 0.3770]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.29296875\n",
      "KL loss\n",
      "0.005776539444923401\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1799.05it/s]\n",
      " 43%|████▎     | 13/30 [13:08<19:04, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6793], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4480], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3230], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 96, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paul's favorite color is White<|endoftext|><|memory|>AI, my name is Nic Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "White<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic's favorite color is Red<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Red<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 7), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Paul am a database of documents. average document size is 2442 Bytes..<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloland of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best sausage<|endoftext|><|endoftext|> sure to try the of see. of you of come there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Django's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "White<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 96])\n",
      "tensor([[   93, 20704, 49651, 37433,   434,  7583,  3295,   310,  4410,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,\n",
      "           443, 28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,\n",
      "          3153,   275, 12911,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         12951,   434,  7583,  3295,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 10252,     0,   187]], device='cuda:0')\n",
      "0.328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5516, 0.4484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5625, 0.4375]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.328125\n",
      "KL loss\n",
      "3.337860107421875e-06\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8398], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4436], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4368], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Paulachel is 32 years old. He lives in Berlin Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Rachel live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel lives in Los Angeles<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Rachel live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel lives in Los Angeles<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 18), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Paul's favorite color is White<|endoftext|><|memory|>AI 1989, Nic the changes to can stored in<|endoftext|>\n",
      "|memory|>AIland of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the right jam<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonachel lives in Nic Angeles<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  2456,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 12951,   443, 28134,    15,   309,\n",
      "           717,  3495,  1107,  1711,    15,   309,  3153,   275, 12911,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7161,  1057, 22739,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    51, 17470,  4852,   275,\n",
      "          8742,  9757,     0,   187]], device='cuda:0')\n",
      "0.2294921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.6758], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5949, 0.4051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 1.2970e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2294921875\n",
      "KL loss\n",
      "0.2591553330421448\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.5915], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4623], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3484], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 97, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Nic Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>AI's favorite color is White<|endoftext|><|memory|>AI can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Red<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 5), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI first step is to identify the right people to lead the change<|endoftext|><|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Django building last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 97])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 37433,   434,  7583,  3295,   310,  4410,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         12951,   434,  1390,  1416,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.1650390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0874], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.5742], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5615, 0.4385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6211, 0.3809]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1650390625\n",
      "KL loss\n",
      "0.005164027214050293\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6276], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5160], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3681], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onachel is 32 years old. He lives in Berlin Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>AI's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Rachel or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Nic or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 1), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Django was born in Berlin. He is 32 years old. Donald is an expert in Python<|endoftext|><|memory|>Hello the of's's and the favorite news sources sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Django or Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "AIachel<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  2456,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 12951,   443, 28134,    15,   309,   717,  3495,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,\n",
      "           434,  7583,  3295,   310,  4410,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7883,   310,  5662,    13, 12951,   390, 22739,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    51, 17470,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.29296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0430], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5174, 0.4826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9492, 0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.29296875\n",
      "KL loss\n",
      "0.23172879219055176\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6757], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4429], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4288], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Django was born in Berlin. He is 37 years old. Donald is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloachel is 58 years old. He lives in London Angeles. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Donald born?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Donald was born in London. He is 58 years old. Donald is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Donald born?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 19), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Helloland of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 10053,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  9135,  1107,  1711,    15, 10053,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 20704,\n",
      "         49651,    51, 17470,   310,  2456,  1107,  1711,    15,   754,  4852,\n",
      "           275,  8742,  9757,    15, 22739,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "         10053,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 18868,     0,   187]], device='cuda:0')\n",
      "0.38671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0073], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.5391], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6289, 0.3691]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.38671875\n",
      "KL loss\n",
      "0.00047090649604797363\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.8072], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4663], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4494], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 130, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 32 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Rachel an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Rachel an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 5), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Helloia of small. you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best jam<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>AI can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Django's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 130])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  2456,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 20704,\n",
      "         49651, 18128, 31835,  3745,   281,  1978, 14483,  9338,   428,   443,\n",
      "          1758,  3532,   567,  2183,   253, 15501,   326, 14980,   310, 24038,\n",
      "          3420, 19156,   434,  3745,   281,  6635, 16256,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310, 22739,   271,  6485,\n",
      "           275,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            51, 17470,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.10986328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0177], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.3984], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5938, 0.4062]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.10986328125\n",
      "KL loss\n",
      "0.0023924261331558228\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7611], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4747], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4247], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 37 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Django was born in Los. He is 50 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>On 1989, Donald was born in London. He is 58 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 6), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 24 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello the Python Python<|endoftext|> write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the relevant resource.<|endoftext|> not use to write the'ss to other to draft this task.<|endoftext|><|memory|>Hello 1989, the the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "24<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  2456,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  9135,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310, 22739,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  1235,     0,   187]], device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0068], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0058]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.2388075590133667\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.4955], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4092], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.3140], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 95, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Purple<|endoftext|><|memory|>Nic can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Red<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 6), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list.<|endoftext|>\n",
      "|memory|>AI the Python Python<|endoftext|> write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 sentences for the item. the list. and by the list to the relevant resource.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>AI of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Django live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 95])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 12951,   443,\n",
      "         28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 37433,   434,  7583,  3295,   310,  4410,\n",
      "             0,    29,    93, 20704, 49651,  1231,   476,   897,   253, 13814,\n",
      "         14113,  6333,   281,  3965,    14,  3845,   253, 13922,   941,    15,\n",
      "           209,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "         12951,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 23666,  3642,     0,   187]], device='cuda:0')\n",
      "0.08349609375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1099], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0053]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.08349609375\n",
      "KL loss\n",
      "0.3085150122642517\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6253], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4728], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4219], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Django was born in Berlin. He is 37 years old. Donald is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloachel is 37 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "58<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Donald was born in London. He is 58 years old. Donald is an expert in Python<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "58<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 14), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is 24 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 10053,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  9135,  1107,  1711,    15, 10053,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 20704,\n",
      "         49651,    51, 17470,   310,  2456,  1107,  1711,    15,   754,  4852,\n",
      "           275,  8742,  9757,    15, 22739,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310, 10053,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  3680,     0,   187]], device='cuda:0')\n",
      "0.2333984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0447], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5271, 0.4729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2333984375\n",
      "KL loss\n",
      "0.31132322549819946\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6735], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4958], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3847], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 124, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloachel is 37 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>AI, my name is Nic Gumbs. I am 23 years old. I live in Los. I am an expert in Javascript<|endoftext|><|memory|>Nic the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Nic or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Rachel is 50 years old. He lives in Los Angeles. Rachel is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Rachel or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 8), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the, the the changes to can allowed in<|endoftext|>\n",
      "|memory|>AI the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>AI 1989, only small enough documents are stored<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Django or Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rachel<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 124])\n",
      "tensor([[   93, 20704, 49651,    51, 17470,   310,  2456,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 22739,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 12951,   443, 28134,    15,   309,   717,  3495,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 38453,\n",
      "           253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,\n",
      "           253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,\n",
      "          1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 22739,   390,\n",
      "         12951,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            51, 17470,     0,   187]], device='cuda:0')\n",
      "0.1630859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0972], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1260], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5788, 0.4212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1630859375\n",
      "KL loss\n",
      "0.004940241575241089\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1820.13it/s]\n",
      " 47%|████▋     | 14/30 [14:25<18:43, 70.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.7659], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.6473], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5229], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloaneesh is favorite color is Red<|endoftext|><|memory|>AI 1989, Donaldaneesh was born in Berlin. He is 37 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>AI, my name is Nicaneesh Gumbs. I am 39 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Redellow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Yellow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 19), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the of's's, the favorite news online sources sites.\n",
      "|memory|>AI first are in in the document. \".<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>AIh is 37 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Battleaneesh's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Redellow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   434,  7583,  3295,   310,\n",
      "         25056,     0,    29,    93, 20704, 49651,  2374, 11161,    13,   443,\n",
      "          1351, 15897,   369,  5686,   275, 12911,    15,   754,   310,  6931,\n",
      "          1107,  1711,    15,   443,  1351, 15897,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,   443,  1351, 15897,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310,   443,  1351, 15897,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    58,  3827,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.462890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5515, 0.4485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4219, 0.5781]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.462890625\n",
      "KL loss\n",
      "0.017478883266448975\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7302], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5769], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5496], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Donaldaneesh was born in Berlin. He is 37 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>AI, my name is Nicaneesh Gumbs. I am 39 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>AIaneesh is favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 3), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>AI isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>AI am a database of documents. average document size is 2442 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Djangoaneesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "30<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  2347,  1711,   310,   443,  1351, 15897,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,  1867,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2402], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5149, 0.4851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0153]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.2924499809741974\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7210], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5715], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5181], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R 1989, Donaldaneesh was born in Berlin. He is 37 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Weaneesh is favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Ganeesh or Djangoh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Ganeesh or Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 7), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>R can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloal of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best honey<|endoftext|><|endoftext|> sure to try the of see. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Djangoaneesh or Djangoh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13,   443,  1351, 15897,   390,  3689,\n",
      "            73,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         10292,    73,     0,   187]], device='cuda:0')\n",
      "0.42578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-8.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5058, 0.4942]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0069, 0.9922]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.42578125\n",
      "KL loss\n",
      "0.3308975398540497\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7135], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4252], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3436], device='cuda:0', grad_fn=<SumBackward1>), 9)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 175, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Rh is 37 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Minaneesh Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>We of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Minh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berh lives in Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 47 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Game of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Minh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh lives in Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 20), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>R first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello first are in in the document. \".<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Django live live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonh lives in Berlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 175])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,  7543,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15,  3689,    73,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,   443,  1351, 15897,   443, 28134,    15,   309,\n",
      "           717,  3307,  1107,  1711,    15,   309,  3153,   275, 12911,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651, 18237,   273,   596, 22334,   310,   247, 16879, 14562,  7315,\n",
      "          2962,  3562,   407,  5119,  6029,   900,   567,   285,   399,    15,\n",
      "           378,    15, 34167,   323, 41069,    15,   733,   310,   271, 15644,\n",
      "           273,   329, 16865,   273, 22078,   285,  8726,    13,  6086,   416,\n",
      "            15,   416,    15,  8698,   434,  2962,   273, 16879, 19204,    13,\n",
      "           253,   806,   273,   534,   310,   329, 10850,   273,   596, 22334,\n",
      "            15,   380,   921,   369,  1097,  4197,   285, 32325,   275, 44867,\n",
      "           285, 11358,   275,   253,  1986, 11491,    15,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,  1057,  3689,    73,  3153,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 10292,    73,\n",
      "          4852,   275, 12911,     0,   187]], device='cuda:0')\n",
      "0.220703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-9.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6192, 0.3808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0022, 0.9961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.220703125\n",
      "KL loss\n",
      "0.4727485477924347\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.8070], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5919], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5390], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 110, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R 1989, Donaldaneesh was born in Berlin. He is 50 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Weaneesh's favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Ganeesh born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Ganeesh born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 14), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Rh is 50 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello first Vegas- is a stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Helloaneesh is favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Minaneesh born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 110])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,   369,   443,  1351, 15897,  5686,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 23666,  3642,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1767578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1621], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2451], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5298, 0.4702]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5195, 0.4785]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1767578125\n",
      "KL loss\n",
      "-0.0011193454265594482\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.6919], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4928], device='cuda:0', grad_fn=<SumBackward1>), 8), (tensor([0.4700], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 132, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Rh is 50 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Minh's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 47 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Minh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 16), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>R first are in in the document. documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first is documents documents<|endoftext|> up by you user is added to the list.<|endoftext|>\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is theh's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 132])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,  7543,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15,  3689,    73,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 38453,   253,\n",
      "          4302,   326,  4483,   368,   281, 26065, 26921,  8062,   387,   253,\n",
      "         15180,  1268,   310,  2234,   281,  3733,   253, 10164,   478,  1050,\n",
      "         14980,   285,   436,  8113,  4583,    15,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310,   443,  1351, 15897,   443,\n",
      "         28134,    15,   309,   717,  3307,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310,  3689,    73,\n",
      "           271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 10292,    73,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.2060546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2471], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.6992], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5848, 0.4152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6094, 0.3887]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2060546875\n",
      "KL loss\n",
      "-0.0006806552410125732\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.6876], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4359], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3603], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Rh is 50 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 23 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>G the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 47 years old. He lives in Berlin. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 1), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>R am a database of documents. average document size is 2442 Bytes..<|endoftext|><|memory|>Hello 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello the of's's and G friends video online sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Gh?<|endoftext|>\n",
      "<|assistant|>\n",
      "29<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,  7543,  1107,  1711,    15,\n",
      "           754,  4852,   275, 12911,    15,  3689,    73,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,   443,  1351, 15897,   443, 28134,    15,   309,\n",
      "           717,  3307,  1107,  1711,    15,   309,  3153,   275, 12911,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651, 38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,\n",
      "          8062,   387,   253, 15180,  1268,   310,  2234,   281,  3733,   253,\n",
      "         10164,   478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  3689,\n",
      "            73,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2504,     0,   187]], device='cuda:0')\n",
      "0.1494140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0078], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.0625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5744, 0.4256]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0063]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1494140625\n",
      "KL loss\n",
      "0.257784903049469\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.7285], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.6280], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5283], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 110, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>R 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Red<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Glin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 12), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>R first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello the of's's and the favorite video online sources sites.<|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Djangoaneesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Glin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 110])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057,   443,  1351, 15897,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 23666,  3642,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.142578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5104, 0.4896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9727, 0.0284]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.142578125\n",
      "KL loss\n",
      "0.273175448179245\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6955], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5708], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4879], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Gh or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Minh or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 12), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>R is isachelay<|endoftext|> Gy is London/<|endoftext|>.let<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24 (<|endoftext|> $$$<|endoftext|> 2. G. G's. (8,9).<|endoftext|> Now. American. Gerry's.. (\n",
      "|memory|>Hello the of's's, the favorite online online sources sites.<|memory|>Hello am been database of documents. average document size is 2442 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Gh or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13,  3689,    73,   390,   443,  1351,\n",
      "         15897,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         10292,    73,     0,   187]], device='cuda:0')\n",
      "0.142578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1147], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2402], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.142578125\n",
      "KL loss\n",
      "0.00041177868843078613\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.7622], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.6506], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5404], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Ganeesh's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gane<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Ganeesh was born in Berlin. He is 39 years old. Ganeesh is an expert in Python<|endoftext|><|memory|>Hello, my name is Ganeesh Gumbs. I am 22 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 18), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>On the, the the changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello 1989, only small enough documents are stored<|endoftext|><|endoftext|>\n",
      "|memory|>Hello the, only small enough documents are stored<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Ganeesh's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gane<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,   443,  1351, 15897,   369,\n",
      "          5686,   275, 12911,    15,   754,   310,  6931,  1107,  1711,    15,\n",
      "           443,  1351, 15897,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310,   443,  1351,\n",
      "         15897,   443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    40,  1351, 15897,   434,\n",
      "          7583,  3295,   310, 25056,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310,   443,  1351, 15897,   434,  1390,  1416,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    40, 28134,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.064453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.6016], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.4688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5521, 0.4479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9453, 0.0537]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.064453125\n",
      "KL loss\n",
      "0.19709497690200806\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1727.90it/s]\n",
      " 50%|█████     | 15/30 [15:40<17:53, 71.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6075], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4713], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4023], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Gema Gumbs. I am 22 years old. I live in Berlinos. I am an expert in Javascript<|endoftext|><|memory|>Kaneema's favorite color is Yellow<|endoftext|><|memory|>K hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Kaneema's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Kaneema's favorite color is Purple<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 14), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>On of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Gameema's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,\n",
      "           443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,\n",
      "          3153,   275, 15184,   375,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    44,  1351,  8895,   434,\n",
      "          7583,  3295,   310, 49685,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 34780,  8895,   434,  1390,  1416,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    40,\n",
      "         28134,     0,   187]], device='cuda:0')\n",
      "0.384765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0532], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.3828], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5969, 0.4031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5820, 0.4180]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.384765625\n",
      "KL loss\n",
      "0.0001999586820602417\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7428], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6790], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4909], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Berlin. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, G was born in Berlin. He is 39 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Gema Gumbs. I am 22 years old. I live in Berlinos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 3), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>On the Python name to build the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the page page.<|endoftext|> not use to write the'ss to G to draft this task.<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Helloland of small<|endoftext|> you you are on, is the right to<|endoftext|> fooduits are huge<|endoftext|> the best j<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is G?<|endoftext|>\n",
      "<|assistant|>\n",
      "30<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          7993,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "           938,     0,   187]], device='cuda:0')\n",
      "0.671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0244], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9570, 0.0417]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.671875\n",
      "KL loss\n",
      "0.16849184036254883\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6764], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6393], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5560], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Berlin. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, G was born in Berlin. He is 39 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Gema Gumbs. I am 22 years old. I live in Berlinos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Peter or Gema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 11), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>On of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Helloal of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best honey<|endoftext|><|endoftext|> sure to try the of get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, G or Gema?<|endoftext|>\n",
      "<|assistant|>\n",
      "K<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13,  7993,   390, 34780,  8895,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 23852,     0,   187]], device='cuda:0')\n",
      "0.5546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1543], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5800, 0.4200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0035]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5546875\n",
      "KL loss\n",
      "0.26102548837661743\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6896], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6866], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4253], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Berlin. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, Peter was born in Berlin. He is 39 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Gema Gumbs. I am 22 years old. I live in Berlinos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 17), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>On first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello am a database of documents. average document size is 3642 Bytes..<|endoftext|><|memory|>Hello first of the documents<|endoftext|> up by you user is added to the list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does G born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Min<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,   369,  7993,\n",
      "          5686,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         36062,     0,   187]], device='cuda:0')\n",
      "0.435546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7383], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5499, 0.4501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8789, 0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.435546875\n",
      "KL loss\n",
      "0.12657010555267334\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8342], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.7010], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4871], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Berlin. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, Peter was born in Berlin. He is 39 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 22 years old. I live in Berlinos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris lives in Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 7), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in and and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does G live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris lives in Berlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,  7993,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         23852,  4852,   275, 37068,     0,   187]], device='cuda:0')\n",
      "0.30078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 6, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 6, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.6719], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-10.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5349, 0.4651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 9.5367e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.30078125\n",
      "KL loss\n",
      "0.30991825461387634\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6734], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4851], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3758], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onaneema is favorite color is Yellow<|endoftext|><|memory|>K, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>K hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema's favorite color is Purple<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 10), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Onaneema is favorite color is Yellow<|endoftext|><|memory|>K weically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello 1989, the the changes to can allowed in<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   434,  7583,  3295,   310,\n",
      "         49685,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 34780,  8895,   443, 28134,    15,   309,   717,  1283,  1107,\n",
      "          1711,    15,   309,  3153,   275, 15184,   375,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 34780,  8895,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 30431,\n",
      "           713,     0,   187]], device='cuda:0')\n",
      "0.1845703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3047], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5389, 0.4611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1845703125\n",
      "KL loss\n",
      "0.0006565451622009277\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7184], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6632], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4874], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Lag. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, Peter was born in Cairo. He is 20 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 18), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>On more of's's on the favorite mobile sources sources sites.<|memory|>Hello the, the the changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello Vegas isachelay<|endoftext|> Gy is G.<|endoftext|>Glet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24.<|endoftext|>.<|endoftext|> $$$<|endoftext|> 2.<|endoftext|>. G's. (859).9).<|endoftext|> Now. American.<|endoftext|>erry's.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Battle?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "          7993,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2417,     0,   187]], device='cuda:0')\n",
      "0.2451171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.8438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5607, 0.4393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0503, 0.9492]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2451171875\n",
      "KL loss\n",
      "0.30493348836898804\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5868], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5026], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4497], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>K hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>K is 50 years old. He lives in Lag. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 0), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>On first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello is 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|system|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peterema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parisos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,\n",
      "           443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,\n",
      "          3153,   275, 15184,   375,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 23852,   310,\n",
      "          1384,  1107,  1711,    15,   754,  4852,   275, 37068,    15,  7993,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7161,  1057, 34780,  8895,  3153,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 47529,   375,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.18359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0435], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5344, 0.4656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.18359375\n",
      "KL loss\n",
      "0.2900029718875885\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7789], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6898], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4713], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>Hello 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 0), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>On Vegas isacheluit is Gy is London/5atlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24 (<|endoftext|> $$$<|endoftext|> 2. Paris. G's. (859).9).<|endoftext|> Now. American. Gerry's.. (\n",
      "|memory|>Hello is 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|system|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,  7993,\n",
      "           369,  5686,   275,  7785,    15,   754,   310,  7288,  1107,  1711,\n",
      "            15,  7993,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  1276,   310,  7993,\n",
      "           271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 23852,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1259765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0513], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0547], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5405, 0.4595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1259765625\n",
      "KL loss\n",
      "0.0025141239166259766\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6702], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6133], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.6079], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Peter was born in Lag. He is 55 years old. Peter is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Peterema or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 20 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Peter was born in Paris. He is 55 years old. Peter is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Kaneema or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 14), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>On is 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|memory|>Hello first Vegas- is a stretch of Las Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello's 50 years old. He lives in Cairo. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Peterema or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  1384,  1107,  1711,    15,   754,\n",
      "          4852,   275, 37068,    15,  7993,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 34780,  8895,   443, 28134,    15,   309,   717,  1283,  1107,\n",
      "          1711,    15,   309,  3153,   275, 15184,   375,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13,  7993,   369,  5686,   275,  7785,    15,   754,   310,\n",
      "          7288,  1107,  1711,    15,  7993,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13, 34780,  8895,   390,  7993,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 23852,     0,   187]], device='cuda:0')\n",
      "0.1376953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0077], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5453, 0.4547]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1376953125\n",
      "KL loss\n",
      "0.002929195761680603\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1725.62it/s]\n",
      " 53%|█████▎    | 16/30 [16:57<17:05, 73.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6108], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5215], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4811], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Gantha born in Paris. He is 55 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Helloice's 18 years old. He lives in Cairoja. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Samantha<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Sam was born in Cairo. He is 47 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 5), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>On first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello the first side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Minantha<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  5769,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7543,  1107,  1711,    15,  5769,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 16922,   443, 28134,    15,   309,   717,\n",
      "          5540,  1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2422,   547,   310,  6931,  1107,  1711,    15,   754,  4852,\n",
      "           275, 26957,  6362,    15, 16922,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310,  5769,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  2504,     0,   187]], device='cuda:0')\n",
      "0.7421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2246], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5866, 0.4134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9492, 0.0522]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.7421875\n",
      "KL loss\n",
      "0.17427745461463928\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.7856], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6926], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5046], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onice is 50 years old. He lives in Cairoja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Helloice's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 2), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>On are right. Query document may become large by large list.<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,  1057, 16922,  3153,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 47529,   375,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.5703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5327, 0.4673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0289, 0.9727]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5703125\n",
      "KL loss\n",
      "0.3143072724342346\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8727], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.7102], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5433], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 105, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onice is 50 years old. He lives in Cairoja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Helloice's favorite color is Yellow<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice lives in Lagja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice lives in Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 5), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>On the Python name to create the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the more resource.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello 1989, the the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minice lives in Lagja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 105])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,  1057, 16922,  3153,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  2422,   547,  4852,\n",
      "           275, 26957,  6362,     0,   187]], device='cuda:0')\n",
      "0.431640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.8750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9648, 0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.431640625\n",
      "KL loss\n",
      "0.1966220736503601\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7475], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4746], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4660], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter 1989, Peter was born in Paris. He is 55 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's 20 years old. He lives in Cairoja. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Sam was born in Cairo. He is 47 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Sam born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 12), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Peter first is the tasks is up by you employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello the of's's on the favorite media sources sources sites.<|memory|>Helloland of small. you you are an, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best honey.<|endoftext|> sure to try the. get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  5769,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7543,  1107,  1711,    15,  5769,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 16922,   443, 28134,    15,   309,   717,\n",
      "          5540,  1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2422,   547,   310,  6931,  1107,  1711,    15,   754,  4852,\n",
      "           275, 26957,  6362,    15, 16922,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "          5769,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    36, 22466,     0,   187]], device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.6641], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6047, 0.3953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0027]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.24196629226207733\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.8497], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.7132], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5025], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 109, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is 20 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 18 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Purple<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Alice an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 4), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Peter isableula the in is therition<|endoftext|> the people.\n",
      "|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello isoments dissent and increases attrition amongst your ranks<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Min's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 109])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 16922,   271,  6485,   275,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2422,\n",
      "           547,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2138671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1846], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.3320], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5352, 0.4629]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2138671875\n",
      "KL loss\n",
      "0.001390799880027771\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.7000], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.6738], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6048], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is favorite color is Purple<|endoftext|><|memory|>Helloice is 20 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Alice an favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Pur<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice's favorite color is Blue<|endoftext|><|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 1), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Peter the Python name to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by a list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Hello 1989, Peter was born in Paris. He is 55 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello the Python outline to draft the content of the newsletter.<|endoftext|> draft should contain 1-2 sentences about each topic in the draft, followed by a link to a relevant article.<|endoftext|> not attempt to use Google Docs or tables to perform this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Sam an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Pur<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   434,  7583,  3295,   310, 10063,\n",
      "             0,    29,    93, 20704, 49651,  2422,   547,   310,  6931,  1107,\n",
      "          1711,    15,   754,  4852,   275, 26957,  6362,    15, 16922,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310, 16922,   443, 28134,    15,   309,\n",
      "           717,  5540,  1107,  1711,    15,   309,  3153,   275, 15184,   375,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 16922,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 22036,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.29296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5675, 0.4325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4375, 0.5625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.29296875\n",
      "KL loss\n",
      "0.01689796894788742\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.8186], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6837], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5092], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is 55 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice is favorite color is Purple<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 1), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Peter am been database with documents. average document size is 3642 Bytes..<|endoftext|><|memory|>Hello 1989, Peter was born in Paris. He is 55 years old. Sam is an expert in Python<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  2347,  1711,   310, 16922,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,  1867,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1767578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.8281], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5201, 0.4799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9180, 0.0815]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1767578125\n",
      "KL loss\n",
      "0.18862803280353546\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.8111], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6761], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5295], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is 55 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Al, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Alice or Min or<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 21), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Peter the Python name to create the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Helloice is favorite color is Yellow<|endoftext|><|memory|>Al first is the tasks<|endoftext|> up by Alice employee is added to the list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Alice or Min?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 16922,   390,\n",
      "         16922,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2422,   547,     0,   187]], device='cuda:0')\n",
      "0.1533203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0559], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5482, 0.4518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4902]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1533203125\n",
      "KL loss\n",
      "0.0006989985704421997\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.8021], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6549], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5332], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 20), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Peter am been database with documents. average document size is 3642 Bytes..<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello 1989, the the documents to are stored in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Min or Min?<|endoftext|>\n",
      "<|assistant|>\n",
      "Alice<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7883,   310,  5662,    13, 16922,   390,\n",
      "         16922,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          2422,   547,     0,   187]], device='cuda:0')\n",
      "0.0888671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0205], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0466], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5735, 0.4265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4941]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.0888671875\n",
      "KL loss\n",
      "0.006001695990562439\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.7577], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.7130], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5258], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peterice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice is 39 years old. He lives in Abuja. Alice is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 36 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Alice's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 17), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Peter of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello am been database with documents. average document size is 3642 Bytes..<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Game an favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   310,  6931,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 16922,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 16922,   443, 28134,    15,   309,   717,  5540,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2422,   547,   434,  7583,  3295,   310, 10063,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 16922,   434,  1390,  1416,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    40,\n",
      "         28134,     0,   187]], device='cuda:0')\n",
      "0.07080078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1514], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.4844], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5455, 0.4545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5820, 0.4180]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.07080078125\n",
      "KL loss\n",
      "0.0013251155614852905\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2121.44it/s]\n",
      " 57%|█████▋    | 17/30 [18:11<15:54, 73.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8334], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5627], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4716], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Nic 1989, Nic was was born in Parisja. He is 55 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lag lives in Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic lives in Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 19), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Al the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello first contained in in the document. documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Min lives in Parisja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 34780,  8895,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8026,  1107,  1711,    15, 34780,  8895,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057, 12951,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 37433,  4852,   275, 26957,  6362,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.5703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5660, 0.4340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9688, 0.0320]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5703125\n",
      "KL loss\n",
      "0.2187572717666626\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6573], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5571], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3782], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 98, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Laglin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 5), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Al first Vegas is is 20 stretch of Las Las Vegas Boulevard in Paris County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parislin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 98])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310,  6115,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 12951,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 23666,  3642,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.49609375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5631, 0.4369]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8477, 0.1523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.49609375\n",
      "KL loss\n",
      "0.09310425072908401\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6809], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4799], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4072], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice? Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "G<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Nic or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 10), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello weically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice? Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310,  6115,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13, 12951,   390, 12951,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 37433,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.41796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8203], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5182, 0.4818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3496, 0.6484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.41796875\n",
      "KL loss\n",
      "0.02744217962026596\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7312], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5933], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4492], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Nic 1989, Nicema was born in Parisja. He is 55 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "56<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "57<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 0), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Al's of based. you you are a, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Hello's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello 1989, Nic the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 34780,  8895,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8026,  1107,  1711,    15, 34780,  8895,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 12951,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  3011,     0,   187]], device='cuda:0')\n",
      "0.36328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.4844], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5608, 0.4392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.36328125\n",
      "KL loss\n",
      "0.0031401515007019043\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7540], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5862], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3704], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al's 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Nic 1989, Nicema was born in Abuja. He is 55 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Nic's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic's an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 16), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Al is of based. you you are a, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Hello first is the tasks<|endoftext|> up by you employee is added to the list.<|endoftext|><|memory|>Hello 1989, the the changes to are cached in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 34780,  8895,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8026,  1107,  1711,    15, 34780,  8895,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 12951,   271,  6485,   275,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 37433,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,   187]], device='cuda:0')\n",
      "0.3359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.0156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3496, 0.6523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.3359375\n",
      "KL loss\n",
      "0.06442387402057648\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7195], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4790], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4100], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 36 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Nic or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Nic or Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 10), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Al first is the tasks is up. Alice employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nic<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 37433,   434,\n",
      "          7583,  3295,   310,  6115,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7883,   310,  5662,    13, 12951,   390, 12951,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 37433,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.20703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0352], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1797], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5352, 0.4648]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.20703125\n",
      "KL loss\n",
      "0.0006254613399505615\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7970], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5657], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4612], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al 1989, Aliceema was born in Abuja. He is 39 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Hello is 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who does Kaneema born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Kaneema born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 14), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Alan 39 database with documents. average document size is 3642 Bytes..<|endoftext|><|memory|>Hello first Vegas- is 20 stretch of South Las Vegas Boulevard in the County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nicema born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parisuja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 34780,  8895,   369,  5686,\n",
      "           275, 26957,  6362,    15,   754,   310,  8026,  1107,  1711,    15,\n",
      "         34780,  8895,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,  4852,\n",
      "           275, 26957,  6362,    15, 12951,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,   369, 34780,  8895,  5686,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  5039,    86,  6362,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.25390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3145], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5878, 0.4122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0011]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25390625\n",
      "KL loss\n",
      "0.26252567768096924\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6986], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6049], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4864], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic 1989, Nicema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 14), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Al first Vegas- is 20 stretch of South Las Vegas Boulevard in Abu County, Nevada. is known for its concentration of resort hotels and casinos. The Strip is as it is widely, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello first Vegas Strip is a stretch of South Las Vegas Boulevard in Paris County, Nevada that is known for its concentration of resort hotels and casinos. The Strip, as it is known, is about 4.2 miles (6.8 km) long, and sits immediately south of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often referred to simply as Las Vegas.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,\n",
      "          4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 34780,  8895,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8026,  1107,  1711,    15, 34780,  8895,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 12951,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.126953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0962], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.6953], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6445, 0.3555]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.126953125\n",
      "KL loss\n",
      "0.0024805814027786255\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6403], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5805], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5034], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 99, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Al is favorite color is Blue<|endoftext|><|memory|>Hello is 39 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Nic's favorite color is Green<|endoftext|><|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>Hello, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 2), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Al of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Nic's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 99])\n",
      "tensor([[   93, 20704, 49651, 37433,   434,  7583,  3295,   310,  6115,     0,\n",
      "            29,    93, 20704, 49651, 37433,   310,  8988,  1107,  1711,    15,\n",
      "           754,  4852,   275, 26957,  6362,    15, 12951,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 12951,   443, 28134,    15,   309,   717,  3436,\n",
      "          1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310, 12951,   434,  7583,  3295,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 18942,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1865234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.1094], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.2344], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5288, 0.4712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1865234375\n",
      "KL loss\n",
      "-0.00010094046592712402\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7266], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5460], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4727], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic 1989, Aliceema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Nic is 56 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "56<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Kaneema was born in Abuja. He is 56 years old. Kaneema is an expert in Python<|endoftext|><|memory|>Nic is 57 years old. He lives in Abuja. Nic is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "56<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 9), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Nic are 52. Query document may become large by large list.<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the list are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 34780,  8895,   369,  5686,\n",
      "           275, 26957,  6362,    15,   754,   310,  8026,  1107,  1711,    15,\n",
      "         34780,  8895,   310,   271,  6485,   275, 13814,     0,    29,    93,\n",
      "         20704, 49651, 37433,   310,  8988,  1107,  1711,    15,   754,  4852,\n",
      "           275, 26957,  6362,    15, 12951,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310, 34780,  8895,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  3208,     0,   187]], device='cuda:0')\n",
      "0.12890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7227], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5971, 0.4029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9688, 0.0312]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.12890625\n",
      "KL loss\n",
      "0.19440437853336334\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1894.45it/s]\n",
      " 60%|██████    | 18/30 [19:28<14:56, 74.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6405], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6162], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3993], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|memory|>Nic, my name is Peter Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kane was born in Abu. He is 56 years old. Kane is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Kane or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Moscow. He is 34 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Joe or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 17), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Nic Paris, Kane the changes to are allowed in<|endoftext|>\n",
      "|memory|>Nic am been database with documents. document document size is 3942 Bytes..<|endoftext|><|memory|>Hello the Python Python to write the first. the document<|endoftext|><|endoftext|> first should be the.2 paragraphs for the of. the outline. and by a list to the relevant document.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Alice or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  9915,   443, 28134,    15,   309,   717,  7609,  1107,\n",
      "          1711,    15,   309,  3153,   275, 16496,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 12951,   369,  5686,   275, 16496,    15,   754,   310,  5910,\n",
      "          1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "          9915,   390,  7993,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 23852,     0,   187]], device='cuda:0')\n",
      "0.8125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0630], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0850], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6154, 0.3846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4941]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.8125\n",
      "KL loss\n",
      "0.011730261147022247\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6252], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4385], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4090], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic, my name is Alice Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Kane was born in Abu. He is 56 years old. Nic is an expert in Python<|endoftext|><|memory|>Nic's favorite color is Joe<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Moscow. He is 34 years old. Nic is an expert in Python<|endoftext|><|memory|>Joe's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 6), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Nic are 57. Query document may become large by large list.<|endoftext|><|memory|>Nic the Python list to create the first. the document<|endoftext|><|endoftext|> first is be the.2 sentences for the of. the list. and by a list to the relevant resource.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Hello first Vegas Review is 20 stretch of South Las Vegas Boulevard in Abu County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kane's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  7609,  1107,  1711,    15,   309,  3153,\n",
      "           275, 16496,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,\n",
      "           275, 16496,    15,   754,   310,  5910,  1107,  1711,    15, 12951,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         28440,   434,  7583,  3295,   310, 10063,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310,  9915,   434,  1390,  1416,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    40, 28134,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.6171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0586], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.5898], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5862, 0.4138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6289, 0.3711]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.6171875\n",
      "KL loss\n",
      "0.002568155527114868\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7486], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5232], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4232], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic 1989, Kane was born in Abu. He is 56 years old. Nic is an expert in Python<|endoftext|><|memory|>Nic, my name is Nic Gumbs. I am 26 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Nic is 56 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Moscow. He is 34 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 4), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Nic isableula the in is therition. the ranks.\n",
      "|memory|>Nic the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Nic more of 20's on the favorite video online sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Kane born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Nicoscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  5910,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  9915,   443, 28134,    15,   309,   717,\n",
      "          7609,  1107,  1711,    15,   309,  3153,   275, 16496,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         23852,   310,  8255,  1107,  1711,    15,   754,  4852,   275, 15184,\n",
      "           375,    15,  7993,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,   369, 12951,  5686,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    46,\n",
      "         15635,     0,   187]], device='cuda:0')\n",
      "0.6328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.4238], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 3.5286e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.6328125\n",
      "KL loss\n",
      "0.2533012330532074\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7803], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5475], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4164], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 126, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 57 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 12), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Nic is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|memory|>Hello more of 20's on the favorite mobile online sources sites.<|memory|>Hello, my name is Peter Gumbs. I am 56 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 126])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  9915,   443, 28134,    15,   309,   717,  7609,  1107,\n",
      "          1711,    15,   309,  3153,   275, 16496,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,  7993,   271,  6485,   275,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 23852,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.2578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0544], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0645], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2578125\n",
      "KL loss\n",
      "0.0009507983922958374\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6772], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4435], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3927], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic 1989, Kane was born in Abu. He is 57 years old. Nic is an expert in Python<|endoftext|><|memory|>Nic, my name is Nic Gumbs. I am 26 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "34<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Moscow. He is 34 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "34<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 18), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Nic of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Nic 1989, the the changes to are cached in<|endoftext|>\n",
      "|memory|>Hello am 57 database with documents. document document size is 3936 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         16496,    15,   754,   310,  5910,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  9915,   443, 28134,    15,   309,   717,\n",
      "          7609,  1107,  1711,    15,   309,  3153,   275, 16496,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         23852,   310,  8255,  1107,  1711,    15,   754,  4852,   275, 15184,\n",
      "           375,    15,  7993,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310, 12951,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  1706,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.4375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.3125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5877, 0.4123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9805, 0.0186]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.4375\n",
      "KL loss\n",
      "0.22208286821842194\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7624], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5524], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4082], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 26 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "54<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "54<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 3), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Nic of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello isabler the and is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  9915,   443, 28134,    15,   309,   717,  7609,  1107,\n",
      "          1711,    15,   309,  3153,   275, 16496,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  2347,  1711,   310,  7993,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,  3439,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2695], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.7188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5980, 0.4020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9688, 0.0308]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1875\n",
      "KL loss\n",
      "0.19421479105949402\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5905], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4907], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4765], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic, my name is Joe Gumbs. I am 39 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On is 57 years old. He lives in Abuos. Peter is an expert in Karate<|endoftext|><|memory|>AI 1989, Joe was born in Abu. He is 41 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Nic was born in Moscow. He is 34 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joe live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 7), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Nic first Vegas- is 39 stretch of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is commonly, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first are in in the document. documents.<|endoftext|>. are documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Kane live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parisoscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,   443,\n",
      "         28134,    15,   309,   717,  7609,  1107,  1711,    15,   309,  3153,\n",
      "           275, 16496,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,\n",
      "           754,  4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 12951,   369,  5686,   275, 16496,    15,   754,   310,  5910,\n",
      "          1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057,  9915,  3153,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    46,\n",
      "         15635,     0,   187]], device='cuda:0')\n",
      "0.32421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8984], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5750, 0.4250]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0015]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.32421875\n",
      "KL loss\n",
      "0.2724412679672241\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6677], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5826], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4048], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic is 57 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 26 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Joe or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 17), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Nic of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello am 57 database with documents. document document size is 3936 Bytes..<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Kane or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  9915,   443, 28134,    15,   309,   717,  7609,  1107,\n",
      "          1711,    15,   309,  3153,   275, 16496,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7883,   310,  5662,    13,  7993,   390,  9915,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 23852,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1416015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0106], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1963], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5869, 0.4131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5469, 0.4531]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1416015625\n",
      "KL loss\n",
      "0.0012886375188827515\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6719], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4454], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3142], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 99, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Nic is favorite color is White<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 39 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Joe's favorite color is Blue<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 15), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Nic the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Helloal of small. you you are an, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Hello the technology that allows you to simulate the dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kane an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 99])\n",
      "tensor([[   93, 20704, 49651, 28440,   434,  7583,  3295,   310, 10063,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  9915,\n",
      "           443, 28134,    15,   309,   717,  7609,  1107,  1711,    15,   309,\n",
      "          3153,   275, 16496,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 23852,   310,  8255,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15,  7993,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310,  9915,   434,  7583,  3295,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 22036,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2353515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7539], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.5664], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5732, 0.4268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4531, 0.5469]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2353515625\n",
      "KL loss\n",
      "0.01417742669582367\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8218], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5469], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4100], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 57 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 57 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Moscowos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 54 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joe Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 6), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>On is 57 years old. He lives in Lagos. Peter is an expert in Karate<|endoftext|><|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the more image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Parisos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  8255,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  9915,   443, 28134,    15,   309,   717,  7609,  1107,\n",
      "          1711,    15,   309,  3153,   275, 16496,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7161,  1057,  7993,  3153,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187, 23852,  4852,   275, 15184,   375,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.11181640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5739, 0.4261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1582, 0.8438]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.11181640625\n",
      "KL loss\n",
      "0.18651969730854034\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1587.25it/s]\n",
      " 63%|██████▎   | 19/30 [20:45<13:47, 75.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7687], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4901], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4232], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 57 years old. He lives in Lag York. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Donald or Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 8), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>On the first side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Kane or Kaneonica?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ver<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  5329,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  7188, 43510,   443, 28134,    15,   309,   717,  1384,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7883,   310,  5662,    13, 10053,   390,  7188,\n",
      "         43510,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         16008,     0,   187]], device='cuda:0')\n",
      "0.578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0488], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8789, 0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.578125\n",
      "KL loss\n",
      "0.12059548497200012\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.8086], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4968], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.2739], device='cuda:0', grad_fn=<SumBackward1>), 11)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 111, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Kane was born in Moscow. He is 57 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Cairo. He is 32 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>We can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 3), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Helloonica is favorite color is Green<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What was Ver born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Verairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 111])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  4567,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7188, 43510,   443, 28134,    15,   309,\n",
      "           717,  1384,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  1231,   476,   897,   253, 13814, 14113,  6333,   281,  3965,\n",
      "            14,  3845,   253, 13922,   941,    15,   209,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  7161,   369, 12951,  5686,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    36, 22466,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.478515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0850], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5355, 0.4645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 4.0054e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.478515625\n",
      "KL loss\n",
      "0.3108561635017395\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7357], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5085], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3955], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 54 years old. He lives in Lag York. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Peter hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Donaldonica or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Veronica or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 3), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the Python name to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Hello isabler the and is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Kaneonica or Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ver<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  5329,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  7188, 43510,   443, 28134,    15,   309,   717,  1384,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128,\n",
      "         31835,  3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,\n",
      "           567,  2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,\n",
      "           434,  3745,   281,  6635, 16256,    15,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7883,   310,  5662,    13,  7188, 43510,   390,\n",
      "         10053,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         16008,     0,   187]], device='cuda:0')\n",
      "0.375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0493], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3281], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5669, 0.4331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7812, 0.2178]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.375\n",
      "KL loss\n",
      "0.05060237646102905\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.8054], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4950], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4555], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 54 years old. He lives in Lag York. Donald is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 20), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the.2 paragraphs for the of. the list. and by the list to the relevant page.<|endoftext|> not use to write the'ss to other to create the task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Joe an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  5329,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7188, 43510,   443, 28134,    15,   309,\n",
      "           717,  1384,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 10053,   271,  6485,   275,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 16008,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.310546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1396], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.6016], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8125, 0.1885]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.310546875\n",
      "KL loss\n",
      "0.04492564499378204\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7964], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4811], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4504], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 54 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Joeonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "45<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "45<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 19), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Peter hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|memory|>Hello mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  5329,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7188, 43510,   443, 28134,    15,   309,\n",
      "           717,  1384,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  2347,  1711,   310, 10053,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,  1857,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.25390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1582], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5885, 0.4115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0141]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25390625\n",
      "KL loss\n",
      "0.22945484519004822\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6743], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4868], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3440], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter 1989, Nic was born in Lag. He is 54 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Aliceonica Gumbs. I am 41 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI is 54 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Cairo. He is 32 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 7), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Peter of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello am 54 database with documents. average document size is 3942 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Joe?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  4567,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7188, 43510,   443, 28134,    15,   309,\n",
      "           717,  1384,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651, 16008,   310,  5329,  1107,  1711,    15,   754,  4852,   275,\n",
      "          1457,  2816,    15, 10053,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "         12951,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          1237,     0,   187]], device='cuda:0')\n",
      "0.34375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.0938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5774, 0.4226]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0132]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.34375\n",
      "KL loss\n",
      "0.2425568699836731\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8452], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4591], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4339], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is 54 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in New. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in New York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 45 years old. He lives in New York. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 12), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Peter are 54. Query document may become large by large list.<|endoftext|><|memory|>Hello the of 20's on the favorite mobile sources sources sites.<|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ber lives in Cairo York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  5329,  1107,  1711,    15,   754,\n",
      "          4852,   275,  1457,  2816,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7188, 43510,   443, 28134,    15,   309,\n",
      "           717,  1384,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  7161,  1057, 10053,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 16008,  4852,   275,  1457,\n",
      "          2816,     0,   187]], device='cuda:0')\n",
      "0.1455078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.9648], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.7812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6099, 0.3901]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9766, 0.0215]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1455078125\n",
      "KL loss\n",
      "0.19870367646217346\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6296], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5331], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4102], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Peter 1989, Ver was born in Paris. He is 54 years old. Nic is an expert in Python<|endoftext|><|memory|>Peteronica's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Veronica live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 32 years old. Nic is an expert in Python<|endoftext|><|memory|>Veronica's favorite color is Black<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Veronica live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 1), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Peter are 54. Query document may become large by large list.<|endoftext|><|memory|>Hello 1989, Nic was born in Lag. He is 54 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello more of 20's on the favorite mobile sources sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Joeonica live?<|endoftext|>\n",
      "<|assistant|>\n",
      "C<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7188, 43510,\n",
      "           443, 28134,    15,   309,   717,  1384,  1107,  1711,    15,   309,\n",
      "          3153,   275,  4693,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  2374, 11161,    13, 12951,   369,\n",
      "          5686,   275, 37068,    15,   754,   310,  4567,  1107,  1711,    15,\n",
      "         12951,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 10754, 43510,   434,  7583,  3295,   310,  5418,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,  1057,  7188, 43510,  3153,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 18868,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.310546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5423, 0.4577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0143]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.310546875\n",
      "KL loss\n",
      "0.2686449885368347\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6842], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5111], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4036], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 104, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteronica is favorite color is Ver<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI 1989, Nic was born in Lag. He is 41 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Veronica's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Veronica's favorite color is Black<|endoftext|><|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 32 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Veronica's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 14), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Peter first is the tasks is up<|endoftext|> you employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello first Vegas- is 20 stretch of South Las Vegas Boulevard in the County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is located 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Niconica an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 104])\n",
      "tensor([[   93, 20704, 49651, 10754, 43510,   434,  7583,  3295,   310,  5418,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "          7188, 43510,   443, 28134,    15,   309,   717,  1384,  1107,  1711,\n",
      "            15,   309,  3153,   275,  4693,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         12951,   369,  5686,   275, 37068,    15,   754,   310,  4567,  1107,\n",
      "          1711,    15, 12951,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310,  7188, 43510,   434,\n",
      "          7583,  3295,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 15383,     0,   187]], device='cuda:0')\n",
      "0.33203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5913, 0.4087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4141, 0.5859]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.33203125\n",
      "KL loss\n",
      "0.0320424884557724\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6786], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5677], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4809], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 105, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI 1989, Nic was born in London. He is 39 years old. Nic is an expert in Python<|endoftext|><|memory|>AIonica's favorite color is Blue<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Veronica's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Veronica Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 32 years old. Nic is an expert in Python<|endoftext|><|memory|>Veronica's favorite color is Black<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Veronica's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 5), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Peter isableula the<|endoftext|> is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Niconica an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 105])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7188, 43510,\n",
      "           443, 28134,    15,   309,   717,  1384,  1107,  1711,    15,   309,\n",
      "          3153,   275,  4693,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  2374, 11161,    13, 12951,   369,\n",
      "          5686,   275, 37068,    15,   754,   310,  4567,  1107,  1711,    15,\n",
      "         12951,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 10754, 43510,   434,  7583,  3295,   310,  5418,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310,  7188, 43510,   434,\n",
      "          1390,  1416,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.201171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0405], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8164], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6103, 0.3897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6836, 0.3145]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.201171875\n",
      "KL loss\n",
      "0.005426093935966492\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1541.57it/s]\n",
      " 67%|██████▋   | 20/30 [22:02<12:39, 75.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7193], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5271], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4367], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Niconica was born in Cairo. He is 20 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Verema Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AIson is 54 years old. He lives in New York. Thom is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 0), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>On the first side of this challenge is enormous opportunity<|endoftext|><|memory|>Helloson is 54 years old. He lives in New York. Thom is an expert in Karate<|endoftext|><|memory|>AI am 54 database with 20. average document size is 2042 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 37068,    15,   754,   310,  3387,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443, 28134,\n",
      "            15,   309,   717,  2030,  1107,  1711,    15,   309,  3153,   275,\n",
      "         12911,    15,   309,   717,   271,  6485,   275, 34619,     0,    29,\n",
      "            93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,   369,  7188, 43510,  5686,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    36, 22466,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.48046875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0237], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5387, 0.4613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 4.1389e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.48046875\n",
      "KL loss\n",
      "0.3078548014163971\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6181], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5721], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4759], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Niconica was born in Cairo. He is 20 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Verema Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AIson is 54 years old. He lives in New York. Nic is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "40<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 21), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Onson is 45 years old. He lives in New York. Thom is an expert in Karate<|endoftext|><|memory|>AIaneema is favorite color is Blue<|endoftext|><|memory|>AI Vegas isachelay<|endoftext|> Bluey is Blue/<|endoftext|>melette<|endoftext|><|endoftext|><|endoftext|>39)<|endoftext|> 24. 20.<|endoftext|> $$$<|endoftext|> 20. Paris. G's. (859,9).<|endoftext|> Now. American. Newerry's.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Niconica?<|endoftext|>\n",
      "<|assistant|>\n",
      "49<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 37068,    15,   754,   310,  3387,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 12092,    13,   619,  1416,   310, 34780,  8895,   443, 28134,\n",
      "            15,   309,   717,  2030,  1107,  1711,    15,   309,  3153,   275,\n",
      "         12911,    15,   309,   717,   271,  6485,   275, 34619,     0,    29,\n",
      "            93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310,  7188, 43510,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1449,     0,   187]], device='cuda:0')\n",
      "0.4296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0295], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.4688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5518, 0.4482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0043]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.4296875\n",
      "KL loss\n",
      "0.28414735198020935\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5578], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4669], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.3826], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 110, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Verema Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Onaneema's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Kaneema's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 0), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>On of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Helloson is 54 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Verema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Klin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 110])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,\n",
      "           443, 28134,    15,   309,   717,  2030,  1107,  1711,    15,   309,\n",
      "          3153,   275, 12911,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,  1978,\n",
      "         14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253, 15501,\n",
      "           326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,  6635,\n",
      "         16256,    15,     0,    29,    93, 20704, 49651,    44,  1351,  8895,\n",
      "           434,  7583,  3295,   310,  6115,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  7161,  1057, 34780,  8895,  3153,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 23666,  3642,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.248046875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0354], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.6562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5056, 0.4944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9336, 0.0679]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.248046875\n",
      "KL loss\n",
      "0.21897654235363007\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7420], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4787], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3288], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onson is 45 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>AI, my name is Verema Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Niconica was born in Cairo. He is 20 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "49<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "49<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 7), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Helloal of small. you you are not, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 34780,  8895,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 37068,    15,\n",
      "           754,   310,  3387,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310, 41963,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,  2537,     0,   187]], device='cuda:0')\n",
      "0.328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1133], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.8594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5694, 0.4306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9766, 0.0231]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.328125\n",
      "KL loss\n",
      "0.22962868213653564\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7241], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4372], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3097], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 130, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 41 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Verema Gumbs. I am 20 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Thomson an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 20), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Nic an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 130])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 34780,  8895,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,\n",
      "           387,   253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,\n",
      "           478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310, 41963,   271,  6485,\n",
      "           275,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         42299,  1665,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2412109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.4434], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5788, 0.4212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9414, 0.0603]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2412109375\n",
      "KL loss\n",
      "0.17052103579044342\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6113], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4744], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4052], device='cuda:0', grad_fn=<SumBackward1>), 21)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 108, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Verema Gumbs. I am 20 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 20 years old. Veronica is an expert in Python<|endoftext|><|system|>Donaldaneema's favorite color is White<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Kaneema's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|memory|>Kaneema's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 3), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Verema an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 108])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 34780,  8895,\n",
      "           443, 28134,    15,   309,   717,  2030,  1107,  1711,    15,   309,\n",
      "          3153,   275, 12911,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  2374, 11161,    13,  7188, 43510,\n",
      "           369,  5686,   275, 37068,    15,   754,   310,  3387,  1107,  1711,\n",
      "            15,  7188, 43510,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 20704, 49651,    44,  1351,  8895,   434,  7583,  3295,   310,\n",
      "          6115,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         34780,  8895,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1845703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0262], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.5430], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6189, 0.3811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6250, 0.3730]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1845703125\n",
      "KL loss\n",
      "-0.00019845366477966309\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6294], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5266], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4043], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 20 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Verema Gumbs. I am 20 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 20 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Kane or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Thomson or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 16), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the Python form to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Hello firstdown the tasks<|endoftext|> up<|endoftext|> Ver employee is added to the list.<|endoftext|><|memory|>Hello Vegas isachelay<|endoftext|> Bluey is Blue/ Vermelette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 20.<|endoftext|> $$$<|endoftext|> 20. Paris. G's. (859).9).<|endoftext|> 24. American. Blueerry's.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Ver or Verema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kson<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 34780,  8895,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 37068,    15,\n",
      "           754,   310,  3387,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13, 41963,   390, 34780,  8895,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 42299,  1665,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1865234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0400], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6255, 0.3745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0040]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1865234375\n",
      "KL loss\n",
      "0.22270037233829498\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6650], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4951], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3657], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 111, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloaneema is favorite color is Blue<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 20 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema's favorite color is Green<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 11), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Hello Verically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Verema's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 111])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   434,  7583,  3295,   310,\n",
      "          6115,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 34780,  8895,   443, 28134,    15,   309,   717,  2030,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,\n",
      "          3745,   281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,\n",
      "          2183,   253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,\n",
      "          3745,   281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310, 34780,  8895,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 18942,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.294921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.3594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6241, 0.3759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6133, 0.3848]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.294921875\n",
      "KL loss\n",
      "-0.0011875629425048828\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5999], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5589], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4094], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 20 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Thomsonema or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Kaneema or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 12), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first is the tasks is up<|endoftext|> Ver employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello the of 20's on the favorite mobile sources sources sites.<|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Verema or Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kson<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 34780,  8895,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 37068,    15,\n",
      "           754,   310,  3387,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13, 34780,  8895,   390, 41963,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 42299,  1665,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1435546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0225], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6369, 0.3631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7617, 0.2373]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1435546875\n",
      "KL loss\n",
      "0.01762162148952484\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7944], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4589], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3128], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 20 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in New York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 49 years old. He lives in New York. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kaneema Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 21), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Helloaneema's favorite color is Green<|endoftext|><|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the.2 paragraphs for the of. the list. and by the list to the relevant image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Kane live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berson lives in Cairo York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  7584,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 34780,  8895,   443, 28134,    15,   309,   717,\n",
      "          2030,  1107,  1711,    15,   309,  3153,   275, 12911,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 37068,    15,\n",
      "           754,   310,  3387,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057, 41963,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 42299,  1665,  4852,   275,  1457,  2816,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.08837890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2773], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5671, 0.4329]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0032]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.08837890625\n",
      "KL loss\n",
      "0.2727906107902527\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2090.78it/s]\n",
      " 70%|███████   | 21/30 [23:25<11:40, 77.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7970], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4565], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4155], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloh is Ver years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>On 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Minh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh lives in New York<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Minh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh lives in New York<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 11), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>On 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonh lives in Cairo York<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 41963,   443, 28134,    15,   309,   717,\n",
      "          1283,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "          3689,    73,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 10292,    73,  4852,   275,  1457,  2816,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.451171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0620], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.451171875\n",
      "KL loss\n",
      "0.28158342838287354\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6690], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5455], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4121], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloh is Ver years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>On 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Thomsonh or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Minh or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 11), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the Python form to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>Hello the of 20's on the favorite mobile sources sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Kaneh or Kane?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 41963,   443, 28134,    15,   309,   717,\n",
      "          1283,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,   310,\n",
      "          5662,    13,  3689,    73,   390, 41963,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187, 10292,    73,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.45703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0106], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1143], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6276, 0.3724]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5273, 0.4746]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.45703125\n",
      "KL loss\n",
      "0.011537782847881317\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6547], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5304], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3580], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Onh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>On 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 10), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Helloson is favorite color is Green<|endoftext|><|memory|>Hello Verically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>Hello 1989, Ver the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thom<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 41963,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "         41963,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 18868,     0,   187]], device='cuda:0')\n",
      "0.453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3398], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.453125\n",
      "KL loss\n",
      "0.23833253979682922\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6788], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4058], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3948], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Onh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>On 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Thomson's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 7), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Helloh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Min an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 41963,   443,\n",
      "         28134,    15,   309,   717,  1283,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,\n",
      "            15,   754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         41963,   434,  1390,  1416,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.38671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0219], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.0938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5318, 0.4682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0167]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.38671875\n",
      "KL loss\n",
      "0.2752428352832794\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7612], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4726], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4547], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello 1989, Ver was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 14), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello first Vegas- is 20 stretch of South Las Vegas Boulevard in Cairo County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 20 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Kaneh?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,   310,\n",
      "          3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         41963,   443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,\n",
      "           309,  3153,   275,  4693,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310,  3689,    73,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,   746,     0,   187]], device='cuda:0')\n",
      "0.34375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6643, 0.3357]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0038]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.34375\n",
      "KL loss\n",
      "0.19314005970954895\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6936], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.6020], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4303], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Donald was born in Cairo. He is 40 years old. Donald is an expert in Python<|endoftext|><|memory|>Helloh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "29<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "29<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 2), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>On are 45. Ver document may become large by large list.<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On the Python list to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by a list to the more image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 10053,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  3285,  1107,  1711,    15, 10053,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 10292,\n",
      "            73,   310,   655,  1107,  1711,    15,   754,  4852,   275,  1457,\n",
      "          2816,    15,  3689,    73,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,  1978,\n",
      "         14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253, 15501,\n",
      "           326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,  6635,\n",
      "         16256,    15,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 10053,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  1717,     0,   187]], device='cuda:0')\n",
      "0.2197265625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0391], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.4688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 5.9128e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2197265625\n",
      "KL loss\n",
      "0.24836796522140503\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6320], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5893], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3900], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomh is 45 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Thomson or Kaneh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Thomson or Minh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 12), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Thom the Python form to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the more page.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Hello the of 20's on the favorite mobile sources sources sites.<|memory|>Helloson is favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Kane or Kaneh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 41963,   443, 28134,    15,   309,   717,\n",
      "          1283,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 10053,   369,  5686,   275,  4693,    15,   754,\n",
      "           310,  3285,  1107,  1711,    15, 10053,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,   310,\n",
      "          5662,    13, 41963,   390,  3689,    73,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187, 10292,    73,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.255859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0063], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.3203], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5781, 0.4219]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.255859375\n",
      "KL loss\n",
      "0.004512310028076172\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7715], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4592], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3873], device='cuda:0', grad_fn=<SumBackward1>), 8)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 131, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Minh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Building the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Minh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 15), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>Thom Donaldically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Helloland of small. you you are on, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Helloh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Minh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Minh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 131])\n",
      "tensor([[   93, 20704, 49651, 10292,    73,   310,   655,  1107,  1711,    15,\n",
      "           754,  4852,   275,  1457,  2816,    15,  3689,    73,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310, 41963,   443, 28134,    15,   309,   717,\n",
      "          1283,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         38453,   253,  4302,   326,  4483,   368,   281, 26065, 26921,  8062,\n",
      "           387,   253, 15180,  1268,   310,  2234,   281,  3733,   253, 10164,\n",
      "           478,  1050, 14980,   285,   436,  8113,  4583,    15,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310,  3689,    73,   271,\n",
      "          6485,   275,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 10292,    73,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.16796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0571], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5594, 0.4406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.16796875\n",
      "KL loss\n",
      "0.0037863701581954956\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6581], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5329], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3506], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomson is favorite color is Green<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 25 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomellow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson's favorite color is Yellow<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Yellow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 13), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Thom am a database with 25. average document size is 2542 Bytes..<|endoftext|><|memory|>Hello Vegas isachelay<|endoftext|> Gy is London<|endoftext|><|endoftext|>melette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 25 (<|endoftext|> $$$<|endoftext|> 25. London. Kane's. (859,8).<|endoftext|> 24. American. Kaneerry's.. (<|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Ver an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenellow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   434,  7583,  3295,   310, 25056,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         41963,   443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,\n",
      "           309,  3153,   275,  4693,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 10292,    73,   310,   655,\n",
      "          1107,  1711,    15,   754,  4852,   275,  1457,  2816,    15,  3689,\n",
      "            73,   310,   271,  6485,   275, 12604,   366,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310, 41963,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,    58,\n",
      "          3827,     0,   187]], device='cuda:0')\n",
      "0.28515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.8438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5705, 0.4295]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2500, 0.7500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.28515625\n",
      "KL loss\n",
      "0.10634148120880127\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7380], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5983], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4189], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|memory|>Thomh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I amhouse years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Donald born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Min<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Donald was born in London. He is 29 years old. Donald is an expert in Python<|endoftext|><|memory|>Minh is 19 years old. He lives in New York. Minh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Donald born?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 9), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Thom isabler the in is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello first Vegas Review is 20 stretch of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 25 4.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of New and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ver born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 10053,   369,  5686,   275,\n",
      "          4693,    15,   754,   310,  3285,  1107,  1711,    15, 10053,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 10292,\n",
      "            73,   310,   655,  1107,  1711,    15,   754,  4852,   275,  1457,\n",
      "          2816,    15,  3689,    73,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         41963,   443, 28134,    15,   309,   717,  1283,  1107,  1711,    15,\n",
      "           309,  3153,   275,  4693,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "         10053,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 18868,     0,   187]], device='cuda:0')\n",
      "0.2099609375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6914, 0.3066]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2099609375\n",
      "KL loss\n",
      "0.002185329794883728\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1439.76it/s]\n",
      " 73%|███████▎  | 22/30 [24:43<10:24, 78.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6146], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5327], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3849], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom is favorite color is Green<|endoftext|><|memory|>Hello, my name is Kane Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenple<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Sam's favorite color is Purple<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 12), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Thom 1989, Donald was born in London. He is 29 years old. Django is an expert in Python<|endoftext|><|memory|>Thom the of's's on London favorite mobile sources sources sites.<|memory|>Min Vegas isachelay<|endoftext|> Gy is London/<|endoftext|>melette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 25.<|endoftext|> $$$<|endoftext|> 25. Paris. Kane's. (859).9).<|endoftext|> 24. American. Pariserry's.. (<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Django an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenple<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 17232,   434,  7583,  3295,   310, 49685,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,\n",
      "           443, 28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,\n",
      "          3153,   275, 16496,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,  2374, 11161,    13, 42125,   369,\n",
      "          5686,   275, 37068,    15,   754,   310,  7904,  1107,  1711,    15,\n",
      "         42125,   310,   271,  6485,   275, 13814,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310,  5769,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 30431,   713,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.55859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.1562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6445, 0.3555]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.55859375\n",
      "KL loss\n",
      "0.0048526376485824585\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6190], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5676], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4258], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom is 25 years old. He lives in New. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomsonanthaumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in London. He is 29 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 8), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Thom first is the tasks is up<|endoftext|> Donald employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello is favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Kane or Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  5769,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275, 16496,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         42125,   369,  5686,   275, 37068,    15,   754,   310,  7904,  1107,\n",
      "          1711,    15, 42125,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7883,   310,  5662,    13, 10053,\n",
      "           390,  5769,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 16008,     0,   187]], device='cuda:0')\n",
      "0.484375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0037], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0130], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5909, 0.4091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.484375\n",
      "KL loss\n",
      "0.008444100618362427\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6540], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4964], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3545], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min, my name is Thomson Gumbs. I am 18 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Min 1989, Donald was born in Cairo. He is 29 years old. Django is an expert in Python<|endoftext|><|memory|>Min is 25 years old. He lives in London. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 20), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Min isabler the<|endoftext|> is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello are 19. Query document may become large by large list.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ver an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 16496,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,\n",
      "           275, 37068,    15,   754,   310,  7904,  1107,  1711,    15, 42125,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  4567,  1107,  1711,    15,   754,  4852,   275, 16496,\n",
      "            15, 10053,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  1276,   310,  5769,   434,  1390,\n",
      "          1416,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            40, 28134,     0,   187]], device='cuda:0')\n",
      "0.357421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0159], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2832], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6403, 0.3597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5664, 0.4336]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.357421875\n",
      "KL loss\n",
      "0.005151212215423584\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7648], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4981], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4691], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 111, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min 1989, Donald was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|memory|>Min, my name is Thomson Gumbs. I am 25 years old. I live in in. I am an expert in Javascript<|endoftext|><|memory|>Min is 19 years old. He lives in Abu. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "46<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Django?<|endoftext|>\n",
      "<|assistant|>\n",
      "46<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 20), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Min first is the tasks is up<|endoftext|> Donald employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello are 19. Query document may become large by large list.<|endoftext|><|memory|>Hello first are in in the document. \".<|endoftext|><|endoftext|> are list are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 111])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7904,  1107,  1711,    15, 42125,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5769,   443, 28134,    15,   309,   717,\n",
      "          4562,  1107,  1711,    15,   309,  3153,   275, 16496,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  4567,  1107,  1711,    15,   754,  4852,   275, 16496,\n",
      "            15, 10053,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  2347,  1711,   310, 42125,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,  2950,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.30859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0150], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6926, 0.3074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0122]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.30859375\n",
      "KL loss\n",
      "0.15603652596473694\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7482], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4475], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4334], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min is 32 years old. He lives in London. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 25 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "32<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 11), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>Min hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  5769,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275, 16496,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  2347,  1711,   310, 10053,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1237,     0,   187]], device='cuda:0')\n",
      "0.259765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0297], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6265, 0.3735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9766, 0.0237]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.259765625\n",
      "KL loss\n",
      "0.1839660406112671\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6060], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4840], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4664], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min, my name is Thomson Gumbs. I am 18 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Min is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 3), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Min is favorite color is Green<|endoftext|><|memory|>Hello isandomr the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello Donaldically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samoscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 16496,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         42125,   369,  5686,   275, 37068,    15,   754,   310,  7904,  1107,\n",
      "          1711,    15, 42125,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,  1057,  5769,  3153,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    46, 15635,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.173828125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1260], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6387, 0.3613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 5.8746e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.173828125\n",
      "KL loss\n",
      "0.22231023013591766\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6406], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5751], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4183], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in11. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Sam or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 18), (None, 11)]\n",
      "decoded_logits2\n",
      "|memory|>Min Donaldically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello 1989, Donald the changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Min or Min?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  5769,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275, 16496,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,    13,\n",
      "         42125,   369,  5686,   275, 37068,    15,   754,   310,  7904,  1107,\n",
      "          1711,    15, 42125,   310,   271,  6485,   275, 13814,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,  5769,\n",
      "           390, 10053,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 16008,     0,   187]], device='cuda:0')\n",
      "0.51171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0029], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0142], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6588, 0.3412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.51171875\n",
      "KL loss\n",
      "0.026247680187225342\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.8491], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4632], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3865], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in11. I am an expert in Javascript<|endoftext|><|memory|>Min is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Django was born in Cairo. He is 46 years old. Django is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Django born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 4), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Min, my name is Thomson Gumbs. I am 18 years old. I live in 11. I am an expert in Javascript<|endoftext|><|memory|>On the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>On first are in in the JSON. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Sam born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Mairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 42125,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  7904,  1107,  1711,    15, 42125,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5769,   443, 28134,    15,   309,   717,\n",
      "          4562,  1107,  1711,    15,   309,  3153,   275, 16496,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  4567,  1107,  1711,    15,   754,  4852,   275, 16496,\n",
      "            15, 10053,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,\n",
      "            29,    93,  4537, 49651,   187,  7161,   369, 42125,  5686,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187,    36, 22466,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.361328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0461], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6216, 0.3784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 1.7643e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.361328125\n",
      "KL loss\n",
      "0.23704801499843597\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7394], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4627], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4460], device='cuda:0', grad_fn=<SumBackward1>), 7)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 125, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 3), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Min is isachelay is Gy is London/<|endoftext|>atlette<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> 24. 24 (<|endoftext|> $$$<|endoftext|> 29. London. G's. (859,8).<|endoftext|> 24. American. Londonerry's.. (\n",
      "|memory|>Hello isandomr the<|endoftext|> is therition<|endoftext|> the people<|endoftext|>\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Las an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 125])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  5769,   443, 28134,    15,   309,   717,  4562,  1107,  1711,\n",
      "            15,   309,  3153,   275, 16496,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,\n",
      "           281,  1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,\n",
      "           253, 15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,\n",
      "           281,  6635, 16256,    15,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  1276,   310, 10053,   271,  6485,   275,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 16008,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.1083984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0137], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0262], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6218, 0.3782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1083984375\n",
      "KL loss\n",
      "0.014218337833881378\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7973], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4230], device='cuda:0', grad_fn=<SumBackward1>), 7), (tensor([0.4012], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Min is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 18 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 32 years old. He lives in Moscow. Donald is an expert in Karate<|endoftext|><|memory|>AI hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 12), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Min the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello the of's's on the favorite mobile sources sources sites.<|memory|>Hello 1989, Donald the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Ver live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in London<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  4567,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 10053,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 18128, 31835,  3745,   281,\n",
      "          1978, 14483,  9338,   428,   443,  1758,  3532,   567,  2183,   253,\n",
      "         15501,   326, 14980,   310, 24038,  3420, 19156,   434,  3745,   281,\n",
      "          6635, 16256,    15,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  5769,   443, 28134,    15,   309,   717,  4562,\n",
      "          1107,  1711,    15,   309,  3153,   275, 16496,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 10394, 49651,   187,\n",
      "         32869,   253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,\n",
      "           187,  7161,  1057, 10053,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 16008,  4852,   275, 16496,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1064453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 6, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 6, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.6602], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0104]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1064453125\n",
      "KL loss\n",
      "0.19444766640663147\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1594.85it/s]\n",
      " 77%|███████▋  | 23/30 [25:59<09:02, 77.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6023], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5752], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3335], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Minerry is 32 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 18 years old. I live in Moscowja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Django was born in Londonja. He is 46 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Sam or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jerry<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jorge or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 0), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the of's's on London favorite mobile sources sources sites.\n",
      "|memory|>Helloerry's 29 years old. He lives in Moscow. Joe is an expert in Karate<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Sam or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paulerry<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15, 47944,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  3127,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,   310,\n",
      "          5662,    13, 47944,   390,  5171,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    43,  4652,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.91015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-6.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5504, 0.4496]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0094]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.91015625\n",
      "KL loss\n",
      "0.2740713953971863\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7048], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5490], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4936], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald 1989, Django was born in Londonja. He is 29 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 18 years old. I live in Moscowja. I am an expert in Javascript<|endoftext|><|memory|>Helloerry's 32 years old. He lives in Moscow. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "53<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "53<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 7), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Donald first is the tasks is up<|endoftext|> Donald employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  8676,  1107,  1711,    15, 22739,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5171,   443, 28134,    15,   309,\n",
      "           717,  3127,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 47944,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310, 22739,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  3357,     0,   187]], device='cuda:0')\n",
      "0.79296875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6118, 0.3882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0068]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.79296875\n",
      "KL loss\n",
      "0.226085364818573\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7902], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5766], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4333], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald 1989, Django was born in Londonja. He is 49 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 18 years old. I live in Moscowja. I am an expert in Javascript<|endoftext|><|memory|>Donalderry is 32 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Rachel born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Rachel born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 17), (None, 15), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Donald am 19 database with 25. average document size is 2542 Bytes..<|endoftext|><|memory|>Hello's of small<|endoftext|> you you are an, is the place to<|endoftext|> fooduits are huge<|endoftext|> the blue blue<|endoftext|><|endoftext|> sure to try the. get. of you of are there.<|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Ver born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Beruja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  8676,  1107,  1711,    15, 22739,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5171,   443, 28134,    15,   309,\n",
      "           717,  3127,  1107,  1711,    15,   309,  3153,   275, 26957,  6362,\n",
      "            15,   309,   717,   271,  6485,   275, 34619,     0,    29,    93,\n",
      "         20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,   754,\n",
      "          4852,   275, 16496,    15, 47944,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,   369,\n",
      "         22739,  5686,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  5039,    86,  6362,     0,   187]], device='cuda:0')\n",
      "0.55859375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0243], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6806, 0.3194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0017]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.55859375\n",
      "KL loss\n",
      "0.18786285817623138\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6849], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5604], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5310], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald, my name is Sam Gumbs. I am 31 years old. I live in Moscowja. I am an expert in Javascript<|endoftext|><|memory|>Onumbs is 19 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Sam was born in Londonja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Paul live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 12), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Donald the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello the of's's on Sam favorite mobile sources sources sites.\n",
      "|memory|>Hello Vegas isachelay<|endoftext|> Gy is Sam.<|endoftext|>venlette<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24 (<|endoftext|> $$$<|endoftext|> 29. Sam. Sam's. (859,9).<|endoftext|> 24. American. Sam's's.. (\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Ver live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parisuja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5171,   443,\n",
      "         28134,    15,   309,   717,  3127,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    43,  4652,   310,  3127,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15, 47944,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "          5171,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  5039,    86,  6362,     0,   187]], device='cuda:0')\n",
      "0.443359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3906], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.9688], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6324, 0.3676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0038]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.443359375\n",
      "KL loss\n",
      "0.21768727898597717\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7491], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5391], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3792], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 123, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donalderry is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Moscowja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Sam was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Jorge an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 4), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Donald are 19. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello the of's's on Sam favorite mobile sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ver's expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 123])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15, 47944,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  3127,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "         47944,   271,  6485,   275,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    43,  4652,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,   187]], device='cuda:0')\n",
      "0.298828125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1641], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2158], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6325, 0.3675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5117, 0.4863]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.298828125\n",
      "KL loss\n",
      "0.01393882930278778\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6204], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4956], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4344], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On's is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Paul was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Paul's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 9), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Donalderry is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5171,   443,\n",
      "         28134,    15,   309,   717,  3127,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    43,  4652,   310,  3127,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15, 47944,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,   310,\n",
      "          5171,   434,  1390,  1416,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.25390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0068], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0649], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5379, 0.4621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.4863]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25390625\n",
      "KL loss\n",
      "0.0018765628337860107\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6774], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4339], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3933], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald is favorite color is Blue<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Onorge is 21 years old. He lives in Abu. Jorge is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Paul's favorite color is Black<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Paul's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 15), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Donald the Python name to write the first<|endoftext|> the document<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by the list to the more image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Helloal of small<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the blue blue<|endoftext|><|endoftext|> sure to try the. get. of you of are there.<|memory|>Hello theically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is the an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651, 17239,   434,  7583,  3295,   310,  5418,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  5171,\n",
      "           443, 28134,    15,   309,   717,  3127,  1107,  1711,    15,   309,\n",
      "          3153,   275, 26957,  6362,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651,    43,  4652,   310,  3127,\n",
      "          1107,  1711,    15,   754,  4852,   275, 16496,    15, 47944,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,  5171,   434,  7583,  3295,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 15383,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.287109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.4062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.4219], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.287109375\n",
      "KL loss\n",
      "0.022922396659851074\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.5966], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5932], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3896], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donald, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Onorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paulorge<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Paul or Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 10), (None, 2)]\n",
      "decoded_logits2\n",
      "|memory|>Donald, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On theically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>On, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Paul or Paul?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paulorge<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5171,   443,\n",
      "         28134,    15,   309,   717,  3127,  1107,  1711,    15,   309,  3153,\n",
      "           275, 26957,  6362,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    43,  4652,   310,  3127,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15, 47944,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,   310,\n",
      "          5662,    13,  5171,   390, 47944,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    43,  4652,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.259765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-5.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5391, 0.4609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7773, 0.2227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.259765625\n",
      "KL loss\n",
      "0.06173160672187805\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7568], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5585], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4006], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donaldorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Morge lives in Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge lives in Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 3), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Donald are 19. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jorge lives in Moscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15, 47944,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  3127,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,\n",
      "         47944,  3153,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    43,  4652,  4852,   275, 16496,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.1572265625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.6562], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6645, 0.3355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1875, 0.8125]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1572265625\n",
      "KL loss\n",
      "0.24032467603683472\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7455], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5601], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4438], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Donaldorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "21<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jorge is 21 years old. He lives in Moscow. Jorge is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Abuja. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abuja. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "21<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 21), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first Vegas is is 18 stretch of South Las Vegas Boulevard in Moscow County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 4 5.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Hello is favorite color is Blue<|endoftext|><|memory|>Hello first is the tasks<|endoftext|> up<|endoftext|> you employee is added to the list<|endoftext|><|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Las?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,    43,  4652,   310,  3127,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15, 47944,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310,  5171,   443, 28134,    15,   309,   717,  3127,  1107,\n",
      "          1711,    15,   309,  3153,   275, 26957,  6362,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 22739,   369,  5686,   275, 26957,  6362,    15,   754,\n",
      "           310,  8676,  1107,  1711,    15, 22739,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,\n",
      "          1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,\n",
      "           310, 47944,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,  1797,     0,   187]], device='cuda:0')\n",
      "0.10986328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0747], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.3438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6526, 0.3474]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9844, 0.0138]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.10986328125\n",
      "KL loss\n",
      "0.18003135919570923\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1670.17it/s]\n",
      " 80%|████████  | 24/30 [27:19<07:48, 78.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6235], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4732], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4162], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Abu. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abu. He is 53 years old. Rachel is an expert in Python<|endoftext|><|memory|>J is 21 years old. He lives in Moscow Town. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Jerry's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 7), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Helloorge is favorite color is Green<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello Vegas isachelay<|endoftext|> Gy is Blue.<|endoftext|>mitlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24 ·<|endoftext|> $$$<|endoftext|> 21.<|endoftext|>. G's. (859,9).<|endoftext|> 24. American. Sam's's.. (\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,\n",
      "           275, 12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         23852,   310,  5693,  1107,  1711,    15,   754,  4852,   275, 20904,\n",
      "         10079,    15,  7993,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310, 21122,   434,\n",
      "          1390,  1416,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.80078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0070], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0430], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5896, 0.4104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5078, 0.4902]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.80078125\n",
      "KL loss\n",
      "0.005767226219177246\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7552], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5042], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3796], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 120, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 21 years old. He lives in Moscow Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Abu. He is 53 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 19), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Hello are 19. Query document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the document are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first are stored in a collection called fs.files and the chunks that make up each document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jorge an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 120])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  1276,   310,  7993,   271,\n",
      "          6485,   275,    32,     0,   187,    29,    93,   515,  5567, 49651,\n",
      "           187, 23852,   310,   271,  6485,   275, 12604,   366,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.39453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0781], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0864], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6533, 0.3467]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4980]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.39453125\n",
      "KL loss\n",
      "0.024380937218666077\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6907], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4634], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3436], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloorge is favorite color is Black<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On is 48 years old. He lives in Berlin Town. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Jerry's favorite color is Green<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 21), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Hello is isachelay is Gy is Blue/<|endoftext|>Jlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> 24. 21 (<|endoftext|> $$$<|endoftext|> 21. Paris. Paul's. (859,9).<|endoftext|> 24. American. Paul's's.. (\n",
      "|memory|>Helloorge is favorite color is Black<|endoftext|><|memory|>Hello theically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Jerry's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651,    43,  9587,   434,  7583,  3295,   310,  6115,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         21122,   443, 28134,    15,   309,   717,  4562,  1107,  1711,    15,\n",
      "           309,  3153,   275, 12911,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 23852,   310,  5693,  1107,\n",
      "          1711,    15,   754,  4852,   275, 20904, 10079,    15,  7993,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310, 21122,   434,  7583,  3295,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 18942,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.44921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.1094], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.0156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5711, 0.4289]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4766, 0.5234]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.44921875\n",
      "KL loss\n",
      "0.00932738184928894\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8158], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5397], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3827], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 48 years old. He lives in Berlin Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ber lives in Cape Town<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter lives in Cape Town<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 2), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|>\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ber lives in Moscow Town<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057,  7993,  3153,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 23852,\n",
      "          4852,   275, 20904, 10079,     0,   187]], device='cuda:0')\n",
      "0.240234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.2188], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5749, 0.4251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0027]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.240234375\n",
      "KL loss\n",
      "0.2668968141078949\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6836], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5598], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5251], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989 Rachel Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello is 48 years old. He lives in Moscow Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 15), (None, 7)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello's of 20. you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the blue blue<|endoftext|><|endoftext|> sure to try the. get<|endoftext|> of you of go there.<|memory|>Hello hurts ability to keep democracy alive - Gina Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 23852,\n",
      "           310,  5693,  1107,  1711,    15,   754,  4852,   275, 20904, 10079,\n",
      "            15,  7993,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310, 22739,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2417,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.236328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0153], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.7656], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9414, 0.0601]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.236328125\n",
      "KL loss\n",
      "0.14961650967597961\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6639], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5850], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4138], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|> On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "j<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 12), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello the of's's on the favorite video sources sources sites.\n",
      "|memory|>Hello 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Rachel or Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "F<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "          7993,   390, 21122,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 23852,     0,   187]], device='cuda:0')\n",
      "0.2216796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-4.7500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5819, 0.4181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9688, 0.0293]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2216796875\n",
      "KL loss\n",
      "0.20788666605949402\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.5754], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4869], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4464], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Paul Gumbs. I am 21 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Jorge live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jerry live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 5), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Hello is isachelay is Gy is Blue/<|endoftext|>Jlet<|endoftext|><|endoftext|><|endoftext|>1)<|endoftext|> 24. 21 (<|endoftext|> $$$<|endoftext|> 21. Paul. Paul's. (859,9).<|endoftext|> Now. American. Paulorge's.. (\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello first Vegas B is a 21 of South Las Vegas Boulevard in Abu County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 5 21.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated G of Paradise and Winchester. is in considered to as as the Vegas.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Las live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Jlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,\n",
      "           754,  4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,  1057, 21122,  3153,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 23666,\n",
      "          3642,     0,   187]], device='cuda:0')\n",
      "0.15625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.9023], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.5312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6340, 0.3660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.15625\n",
      "KL loss\n",
      "0.21675705909729004\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6787], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5693], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4170], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Jerry or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Jerry or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 12), (None, 11), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the of's's on the favorite mobile sources sources sites.\n",
      "|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Jorge or Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "J<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,    13,\n",
      "         21122,   390,  7993,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 23852,     0,   187]], device='cuda:0')\n",
      "0.11328125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0554], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8320], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6604, 0.3396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6836, 0.3145]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.11328125\n",
      "KL loss\n",
      "9.402632713317871e-05\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7298], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5299], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4105], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 112, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Paul Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "48<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "48<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 6), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the Python list to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by a list to the more image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Hello the Python outline to draft the content of the newsletter.<|endoftext|> draft should contain 1-2 sentences about each topic in the draft, followed by a link to a relevant article.<|endoftext|> not attempt to use Google Docs or tables to perform this task.<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Jorge?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 112])\n",
      "tensor([[   93, 20704, 49651, 23852,   310,  5693,  1107,  1711,    15,   754,\n",
      "          4852,   275, 20904, 10079,    15,  7993,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 21122,   443, 28134,    15,   309,   717,  4562,  1107,\n",
      "          1711,    15,   309,  3153,   275, 12911,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 22739,   369,  5686,   275, 12911,    15,   754,   310,  7288,\n",
      "          1107,  1711,    15, 22739,   310,   271,  6485,   275, 13814,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,  7993,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187,  2385,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.07763671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1328], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.0312], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6702, 0.3298]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9805, 0.0199]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.07763671875\n",
      "KL loss\n",
      "0.15850508213043213\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7488], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5151], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5051], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>J is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Jerry born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peter is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Rachel born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 15), (None, 0)]\n",
      "decoded_logits2\n",
      "|memory|>On is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|memory|>Hello's of 20. you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the blue blue<|endoftext|><|endoftext|> sure to try the. get<|endoftext|> of you of go there.<|memory|>Hello is 48 years old. He lives in Cape Town. Peter is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Peter born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peterlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 23852,\n",
      "           310,  5693,  1107,  1711,    15,   754,  4852,   275, 20904, 10079,\n",
      "            15,  7993,   310,   271,  6485,   275, 12604,   366,     0,    29,\n",
      "            93, 20704, 49651, 12092,    13,   619,  1416,   310, 21122,   443,\n",
      "         28134,    15,   309,   717,  4562,  1107,  1711,    15,   309,  3153,\n",
      "           275, 12911,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,     0,\n",
      "           187,    29,    93,  4537, 49651,   187,  7161,   369, 22739,  5686,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 23666,\n",
      "          3642,     0,   187]], device='cuda:0')\n",
      "0.08203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0618], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 4.3106e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.08203125\n",
      "KL loss\n",
      "0.2938111126422882\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1866.46it/s]\n",
      " 83%|████████▎ | 25/30 [28:41<06:35, 79.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6669], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5012], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4702], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Jerry Gumbs. I am 31 years old. I live in Cape. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peterorgeesh's 18 years old. He lives in Cape. Gumbsesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Rachel live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ber<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 9), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello the of's's on the favorite mobile sources sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jerry live?<|endoftext|>\n",
      "<|assistant|>\n",
      "J<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,   443,\n",
      "         28134,    15,   309,   717,  3349,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,\n",
      "           275, 12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            40,  1351, 15897,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,   443,  1351, 15897,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057,  5769,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 18868,     0,   187]], device='cuda:0')\n",
      "0.671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.2109], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6340, 0.3660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8555, 0.1436]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.671875\n",
      "KL loss\n",
      "0.06050962954759598\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7498], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5043], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3727], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter 1989, Rachel was born in Berlin. He is 55 years old. Rachel is 55 expert in Python<|endoftext|><|memory|>Peter, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Peterorgeesh is 36 years old. He lives in Berlin. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Rachel born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Rachel born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Berlin<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 15), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Peter the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello's of 20<|endoftext|> you you are on, is the place to<|endoftext|> fooduits are huge<|endoftext|> the blue blue<|endoftext|><|endoftext|> sure to try the. get<|endoftext|> of you of go there.<|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by a list to the related image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Jerry born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Rlin<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5769,   443, 28134,    15,   309,   717,\n",
      "          3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "            40,  1351, 15897,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,   443,  1351, 15897,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "           369, 22739,  5686,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 23666,  3642,     0,   187]], device='cuda:0')\n",
      "0.384765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1484], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6731, 0.3269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0085]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.384765625\n",
      "KL loss\n",
      "0.17699109017848969\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.5999], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4707], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.2931], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 102, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter is favorite color is Green<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Onorgeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Sam's favorite color is Green<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Green<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 0), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Peter, my name is Jerry Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|memory|>Onorgeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Peter the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Sam's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Black<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 102])\n",
      "tensor([[   93, 20704, 49651, 17232,   434,  7583,  3295,   310,  6115,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,\n",
      "           443, 28134,    15,   309,   717,  3349,  1107,  1711,    15,   309,\n",
      "          3153,   275,  4693,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    40,  1351, 15897,   310,  5345,\n",
      "          1107,  1711,    15,   754,  4852,   275, 16496,    15,   443,  1351,\n",
      "         15897,   310,   271,  6485,   275, 12604,   366,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310,  5769,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 18942,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.34375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.8867], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.1484], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5664, 0.4355]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.34375\n",
      "KL loss\n",
      "0.0030968040227890015\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6438], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4669], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.3971], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peter, my name is Jerry Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Peter 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Sam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 16), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Peter Donaldically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello first is the tasks<|endoftext|> up by you employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Jerry an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  5769,   443,\n",
      "         28134,    15,   309,   717,  3349,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,\n",
      "           275, 12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            40,  1351, 15897,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,   443,  1351, 15897,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310,  5769,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2216796875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0115], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.3320], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6468, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5781, 0.4199]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2216796875\n",
      "KL loss\n",
      "0.0036445707082748413\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8564], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4799], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3750], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Peter 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Janeesh lives in Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ganeesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh lives in Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 14), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Peter first are in in the document. documents.<|endoftext|><|endoftext|> the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first Vegas Raiders is a stretch of South Las Vegas Boulevard in the County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is known, is 5 5.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Hello theically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Jerryaneesh live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peterumbsesh lives in Abu<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769,   443, 28134,    15,   309,\n",
      "           717,  3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 22739,   369,  5686,   275, 12911,    15,\n",
      "           754,   310,  7288,  1107,  1711,    15, 22739,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057,   443,  1351, 15897,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40,  1351, 15897,  4852,   275, 16496,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.2109375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-3.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-11.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6497, 0.3503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 4.3106e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2109375\n",
      "KL loss\n",
      "0.21418432891368866\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.8149], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4500], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3803], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Samaneesh or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Ganeesh or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 6), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Peter is of an. you you are on, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to try the. start. of you of go there.<|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the related image.<|endoftext|> not use to write the'ss to G to create this task.<|endoftext|>\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Jerryaneesh or Jerry?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samumbsesh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769,   443, 28134,    15,   309,\n",
      "           717,  3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 22739,   369,  5686,   275, 12911,    15,\n",
      "           754,   310,  7288,  1107,  1711,    15, 22739,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,\n",
      "           310,  5662,    13,   443,  1351, 15897,   390,  5769,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    40,  1351, 15897,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2217], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-7.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6325, 0.3675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0010]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.171875\n",
      "KL loss\n",
      "0.2260294407606125\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.8024], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4924], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3941], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Jerry Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, G or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Sam or Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 12), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Peter is of an. you you are on, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to get the. get. of you of go there.<|memory|>Hello the of's's on the favorite mobile sources sources sites.\n",
      "|memory|>On am 32 database with 31. average document size is 3142 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Jerry or Jerryaneesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769,   443, 28134,    15,   309,\n",
      "           717,  3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 22739,   369,  5686,   275, 12911,    15,\n",
      "           754,   310,  7288,  1107,  1711,    15, 22739,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,\n",
      "           310,  5662,    13,  5769,   390,   443,  1351, 15897,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    40,  1351, 15897,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.1416015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0527], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8164], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6836, 0.3184]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1416015625\n",
      "KL loss\n",
      "0.0034416615962982178\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.8068], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4933], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4178], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is G Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Ganeesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "37<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 14), (None, 0), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>Peter first Vegas is is a stretch of South Las Vegas Boulevard in Cairo County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 21 21.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated G of Paradise and Winchester. is in considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Helloaneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello the of's's on the favorite mobile online sources sites.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Lasaneesh?<|endoftext|>\n",
      "<|assistant|>\n",
      "45<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769,   443, 28134,    15,   309,\n",
      "           717,  3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 22739,   369,  5686,   275, 12911,    15,\n",
      "           754,   310,  7288,  1107,  1711,    15, 22739,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310,   443,  1351, 15897,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1787,     0,   187]], device='cuda:0')\n",
      "0.11669921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0176], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.5625], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5929, 0.4071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0105]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.11669921875\n",
      "KL loss\n",
      "0.23324862122535706\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.8227], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4328], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3734], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 127, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Ganeesh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Ganeesh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 0), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>Peter the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Helloaneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|memory|>Hello is favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Veraneesh an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Ganeesh is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 127])\n",
      "tensor([[   93, 20704, 49651,    40,  1351, 15897,   310,  5345,  1107,  1711,\n",
      "            15,   754,  4852,   275, 16496,    15,   443,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  5769,   443, 28134,    15,   309,\n",
      "           717,  3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 22739,   369,  5686,   275, 12911,    15,\n",
      "           754,   310,  7288,  1107,  1711,    15, 22739,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310,   443,  1351, 15897,   271,  6485,   275,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    40,  1351, 15897,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.08642578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 11, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 11, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0143], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0317], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.08642578125\n",
      "KL loss\n",
      "0.002446696162223816\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6834], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5408], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4391], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peter, my name is Sam Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Peteraneesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Ganeesh is 37 years old. He lives in Moscow. Ganeesh is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 1), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>On the Python list to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the outline. and by the list to the more image.<|endoftext|> not use to write the'ss to G to create this task.<|endoftext|>\n",
      "|memory|>Hello 1989, Rachel was born in Berlin. He is 55 years old. Rachel is an expert in Python<|endoftext|><|memory|>Peter first in in in the document. Rachel.<|endoftext|>. are documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Rachel?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 22739,   369,  5686,   275,\n",
      "         12911,    15,   754,   310,  7288,  1107,  1711,    15, 22739,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  5769,   443, 28134,    15,   309,   717,\n",
      "          3349,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "            40,  1351, 15897,   310,  5345,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,   443,  1351, 15897,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 22739,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  2417,     0,   187]], device='cuda:0')\n",
      "0.08740234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0084], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1514], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6325, 0.3675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5352, 0.4648]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.08740234375\n",
      "KL loss\n",
      "0.010509893298149109\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1440.20it/s]\n",
      " 87%|████████▋ | 26/30 [30:02<05:19, 79.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7816], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5556], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5294], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onaneema is 37 years old. He lives in Capeos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello 1989, Rachel was born in Berlin. He is 55 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in Berlin. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "58<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "58<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 10), (None, 4), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>On Donaldically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello the flip side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Samema?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,   754,\n",
      "           310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  7993,   443, 28134,    15,   309,   717,  1884,  1107,  1711,\n",
      "            15,   309,  3153,   275,  7785,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 34780,  8895,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,  3680,     0,   187]], device='cuda:0')\n",
      "0.7421875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1836], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.9062], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6830, 0.3170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0033]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.7421875\n",
      "KL loss\n",
      "0.18048344552516937\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6089], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.4969], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3835], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 103, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is favorite color is Green<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 31 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onaneema is 37 years old. He lives in Londonos. Kaneema is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenple<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter's favorite color is Purple<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Purple<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 7), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>On can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the Python Python to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the-2 paragraphs for the of. the list. and by a list to the source image.<|endoftext|> not use to write the'ss to G to create this task.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Sam an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenple<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 103])\n",
      "tensor([[   93, 20704, 49651, 23852,   434,  7583,  3295,   310, 49685,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,\n",
      "           443, 28134,    15,   309,   717,  1884,  1107,  1711,    15,   309,\n",
      "          3153,   275,  7785,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651,    44,  1351,  8895,   310,  9135,\n",
      "          1107,  1711,    15,   754,  4852,   275, 15184,   375,    15, 34780,\n",
      "          8895,   310,   271,  6485,   275, 12604,   366,     0,    29,    93,\n",
      "         10394, 49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,\n",
      "            93,  4537, 49651,   187,  1276,   310,  7993,   434,  7583,  3295,\n",
      "            32,     0,   187,    29,    93,   515,  5567, 49651,   187, 30431,\n",
      "           713,     0,   187]], device='cuda:0')\n",
      "0.462890625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.8438], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.5469], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6233, 0.3767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6680, 0.3320]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.462890625\n",
      "KL loss\n",
      "0.002584010362625122\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6389], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5362], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4843], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On, my name is Sam Gumbs. I am 31 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Onaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|system|>On 1989, Rachel was born in Berlin. He is 55 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 3), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>On, my name is Sam Gumbs. I am 31 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On isaner the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|system|>On first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  1884,  1107,  1711,    15,   309,  3153,\n",
      "           275,  7785,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,\n",
      "          1711,    15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,\n",
      "           754,   310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057,  7993,  3153,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 36062,     0,   187]], device='cuda:0')\n",
      "0.34765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.5742], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2754], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4258, 0.5742]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.34765625\n",
      "KL loss\n",
      "0.0348404198884964\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7803], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5660], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5391], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ganeema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Rachel was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Kane or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Kaneema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 19), (None, 19), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>G first are in in the document. documents.<|endoftext|>. the documents are are up the document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first are stored in a collection called fs.files and the chunks that make up each document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|memory|>Hello first are stored in a collection called fs.files and the chunks that make up each document are stored in a collection called fs.chunks.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Sam or Samema?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  7993,   443, 28134,    15,   309,\n",
      "           717,  1884,  1107,  1711,    15,   309,  3153,   275,  7785,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,\n",
      "           754,   310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,\n",
      "           310,  5662,    13,  7993,   390, 34780,  8895,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    44,  1351,  8895,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.259765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0527], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.2275], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6927, 0.3073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5430, 0.4570]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.259765625\n",
      "KL loss\n",
      "0.024572238326072693\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7960], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5276], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5028], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ganeema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Sam was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Kaneema or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Kaneema or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 5), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>G the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Samema or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peteraneema<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  7993,   443, 28134,    15,   309,\n",
      "           717,  1884,  1107,  1711,    15,   309,  3153,   275,  7785,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,\n",
      "           754,   310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7883,\n",
      "           310,  5662,    13, 34780,  8895,   390,  7993,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187,    44,  1351,  8895,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0344], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.3594], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6343, 0.3657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9102, 0.0889]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.171875\n",
      "KL loss\n",
      "0.10173404216766357\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6531], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5211], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5014], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G, my name is Sam Gumbs. I am 28 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Sam was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Onaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 16), (None, 18), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>G first is the tasks is up<|endoftext|> Sam employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello 1989, the the changes to are allowed in<|endoftext|>\n",
      "|memory|>Hello first Vegas- is a stretch of South Las Vegas Boulevard in the County, Nevada. is 4 for its concentration of resort hotels and casinos.<|endoftext|> Strip is as it is known, is 21 5.2 miles (6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of Paradise and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Sam an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  1884,  1107,  1711,    15,   309,  3153,\n",
      "           275,  7785,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 16922,   369,  5686,\n",
      "           275,  7785,    15,   754,   310,  2456,  1107,  1711,    15, 16922,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "            44,  1351,  8895,   310,  9135,  1107,  1711,    15,   754,  4852,\n",
      "           275, 15184,   375,    15, 34780,  8895,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310,  7993,   434,  1390,  1416,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2138671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0481], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1660], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6754, 0.3246]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4707]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2138671875\n",
      "KL loss\n",
      "0.023335561156272888\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7748], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5817], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5809], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G 1989, Jerry was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Helloaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 28 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Al<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Paris<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 9), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>G 1989, Jerry was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Alice born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Al<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 16922,   369,  5686,   275,\n",
      "          7785,    15,   754,   310,  2456,  1107,  1711,    15, 16922,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,    44,\n",
      "          1351,  8895,   310,  9135,  1107,  1711,    15,   754,  4852,   275,\n",
      "         15184,   375,    15, 34780,  8895,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  7993,   443, 28134,    15,   309,   717,  1884,  1107,  1711,\n",
      "            15,   309,  3153,   275,  7785,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "           369, 16922,  5686,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 36062,     0,   187]], device='cuda:0')\n",
      "0.18359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.7422], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8359], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5649, 0.4351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2871, 0.7109]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.18359375\n",
      "KL loss\n",
      "0.07798285782337189\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8294], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5248], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.4405], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ganeema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Lagos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Kaneema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 5), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>G Paris, Nic the changes to are allowed in<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello is favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Samema live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema lives in Abuos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,   754,\n",
      "           310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,   275,\n",
      "         13814,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  7993,   443, 28134,    15,   309,   717,  1884,  1107,  1711,\n",
      "            15,   309,  3153,   275,  7785,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  7161,\n",
      "          1057, 34780,  8895,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187,    44,  1351,  8895,  4852,   275, 15184,   375,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.7266], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6395, 0.3605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9258, 0.0742]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.125\n",
      "KL loss\n",
      "0.1124633401632309\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7276], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5956], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5649], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Helloaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "50<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 0), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>G is favorite color is Green<|endoftext|><|memory|>Helloaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello first Vegas is is a 21 of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is known, is 21 5.2 miles (6.7 km) in. and is in to of the Las Vegas city limits in the unincorporated G of New and Winchester. is in considered to as as the Vegas.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "58<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 16922,   369,  5686,   275,\n",
      "          7785,    15,   754,   310,  2456,  1107,  1711,    15, 16922,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,    44,\n",
      "          1351,  8895,   310,  9135,  1107,  1711,    15,   754,  4852,   275,\n",
      "         15184,   375,    15, 34780,  8895,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310,  7993,   443, 28134,    15,   309,   717,  1884,  1107,  1711,\n",
      "            15,   309,  3153,   275,  7785,    15,   309,   717,   271,  6485,\n",
      "           275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  2347,\n",
      "          1711,   310, 16922,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,  1235,     0,   187]], device='cuda:0')\n",
      "0.0869140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1709], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5853, 0.4147]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9922, 0.0079]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.0869140625\n",
      "KL loss\n",
      "0.2461826503276825\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7751], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4701], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4672], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 126, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Ganeema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is Kaneema an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Kaneema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Paris. He is 50 years old. Alice is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Kaneema an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 9), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Ganeema is 58 years old. He lives in Lagos. Kaneema is an expert in Karate<|endoftext|><|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Helloal of 58 in you you are an, is the place to<|endoftext|> fooduits are huge<|endoftext|> the best blue.<|endoftext|> sure to try the. get. of you of are there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Kaneema an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Kaneema is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 126])\n",
      "tensor([[   93, 20704, 49651,    44,  1351,  8895,   310,  9135,  1107,  1711,\n",
      "            15,   754,  4852,   275, 15184,   375,    15, 34780,  8895,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "         12092,    13,   619,  1416,   310,  7993,   443, 28134,    15,   309,\n",
      "           717,  1884,  1107,  1711,    15,   309,  3153,   275,  7785,    15,\n",
      "           309,   717,   271,  6485,   275, 34619,     0,    29,    93, 20704,\n",
      "         49651,  2374, 11161,    13, 16922,   369,  5686,   275,  7785,    15,\n",
      "           754,   310,  2456,  1107,  1711,    15, 16922,   310,   271,  6485,\n",
      "           275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,   253,\n",
      "          1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,  1276,\n",
      "           310, 34780,  8895,   271,  6485,   275,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,    44,  1351,  8895,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.04833984375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 11, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 11, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0586], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0212], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([False], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4902, 0.5078]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.04833984375\n",
      "KL loss\n",
      "0.009688898921012878\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1908.50it/s]\n",
      " 90%|█████████ | 27/30 [31:25<04:02, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6673], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5488], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5071], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G 1989, Alice was born in Paris. He is 55 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Sam Gumbs. I am 30 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Onson is 49 years old. He lives in Lag Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "20<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 9), (None, 8), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>G of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello first Vegas- is a stretch of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is often, is 5 5.2 miles (6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of Paradise and Winchester. is in considered to as as the Vegas.<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "39<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  1384,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7993,   443, 28134,    15,   309,   717,\n",
      "          3307,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         42299,  1665,   310,  2030,  1107,  1711,    15,   754,  4852,   275,\n",
      "          8742,  9757,    15, 41963,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "         12951,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "           938,     0,   187]], device='cuda:0')\n",
      "0.65234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3633], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.6875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6490, 0.3510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0049]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.65234375\n",
      "KL loss\n",
      "0.2029803991317749\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7155], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6906], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4325], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Gson is 25 years old. He lives in Moscow Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Cairo. He is 50 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Peter or Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 5), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>G, my name is Peter Gumbs. I am 30 years old. I live in Moscow. I am an expert in Javascript<|endoftext|><|memory|>On first step is to identify the right people to lead the change<|endoftext|><|memory|>On first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peterson<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13,  7993,   390, 41963,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 42299,  1665,     0,   187]], device='cuda:0')\n",
      "0.443359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1113], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.5391], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5818, 0.4182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8047, 0.1934]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.443359375\n",
      "KL loss\n",
      "0.055602192878723145\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.7006], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5120], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4974], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>G, my name is Peter Gumbs. I am 30 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Alice was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 8), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>G hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Sam an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  3307,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,\n",
      "            15,   754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  1276,   310,  7993,\n",
      "           434,  1390,  1416,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.314453125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0243], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0386], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6464, 0.3536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.314453125\n",
      "KL loss\n",
      "0.02113562822341919\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8091], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6055], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4206], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Kson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 30 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in Los Angeles<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Thomson live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in Los Angeles<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 5), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>K are 19. Peter document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello is favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Sam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson lives in Paris Angeles<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057, 41963,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         42299,  1665,  4852,   275,  8742,  9757,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.220703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 8, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 8, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3379], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6386, 0.3614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0035]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.220703125\n",
      "KL loss\n",
      "0.2133285254240036\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7652], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5130], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4913], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>K 1989, Alice was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Nic born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 14), (None, 21)]\n",
      "decoded_logits2\n",
      "|memory|>K, my name is Peter Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On first Vegas is is a 20 of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is known, is 20 5.2 miles (6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of New and Winchester. is in considered to as as the Vegas.<|endoftext|><|memory|>On's favorite color is Green<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does London born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 12951,   369,  5686,   275,\n",
      "         37068,    15,   754,   310,  1384,  1107,  1711,    15, 12951,   310,\n",
      "           271,  6485,   275, 13814,     0,    29,    93, 20704, 49651, 12092,\n",
      "            13,   619,  1416,   310,  7993,   443, 28134,    15,   309,   717,\n",
      "          3307,  1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "         42299,  1665,   310,  2030,  1107,  1711,    15,   754,  4852,   275,\n",
      "          8742,  9757,    15, 41963,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,   369, 12951,\n",
      "          5686,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            36, 22466,     0,   187]], device='cuda:0')\n",
      "0.1845703125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.2109], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5868, 0.4132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 9.8228e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1845703125\n",
      "KL loss\n",
      "0.26616302132606506\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7196], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5697], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3518], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 122, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Kson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Peter was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Thomson an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 14), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>K are 19. Peter document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello first Vegas is is a 20 of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos.<|endoftext|> Strip is as it is known, is 20 5.2 miles (6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of New and Winchester. is in considered to as as the Vegas.<|endoftext|><|memory|>Hello isaner the<|endoftext|> is therition<|endoftext|> the team.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Sam an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 122])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  1276,   310, 41963,\n",
      "           271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 42299,  1665,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,   187]], device='cuda:0')\n",
      "0.126953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0221], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0413], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6588, 0.3412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5039, 0.4961]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.126953125\n",
      "KL loss\n",
      "0.025196298956871033\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6943], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6564], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4069], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Kson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 28 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Peter was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Thomson or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomson<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 15), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>K the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Helloia of 20 in you you are on, is the place to<|endoftext|> fooduit are huge. the best blue.<|endoftext|> sure to try the. get. of you of go there.<|memory|>Hello 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is older, Peter or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peterson<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13, 41963,   390,  7993,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 42299,  1665,     0,   187]], device='cuda:0')\n",
      "0.11376953125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0129], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-6.2500], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6064, 0.3936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000, 0.0020]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.11376953125\n",
      "KL loss\n",
      "0.2449081838130951\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.5987], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5489], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4106], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>K is favorite color is Green<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenellow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Peter's favorite color is Yellow<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Peter's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Yellow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 13), (None, 9), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>K is isachelane is Gy is G<|endoftext|><|endoftext|>Glet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 24.<|endoftext|> $$$<|endoftext|> 28.<|endoftext|>. Gane. (8,9).<|endoftext|> 24. American. ParisG's.. (\n",
      "|memory|>Hello of Thrones is a fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Las an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Greenellow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651, 23852,   434,  7583,  3295,   310, 25056,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,\n",
      "           443, 28134,    15,   309,   717,  3307,  1107,  1711,    15,   309,\n",
      "          3153,   275,  4693,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 42299,  1665,   310,  2030,  1107,\n",
      "          1711,    15,   754,  4852,   275,  8742,  9757,    15, 41963,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310,  7993,   434,  7583,  3295,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187,    58,  3827,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.1826171875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.0156], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.1094], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6145, 0.3855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5234, 0.4766]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1826171875\n",
      "KL loss\n",
      "0.008864402770996094\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6862], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5657], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.3716], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>K, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Onson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "London<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 4), (None, 14), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>K Peter first side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello first Vegas of is 20 20 of South Las Vegas Boulevard in Paris County, Nevada. is 4 for its concentration of resort hotels and casinos. The Strip is as it is known, is 20 5.2 miles in6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of Paradise and Winchester. is in considered to as as the Vegas.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Peter live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Peter<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310,  7993,   443,\n",
      "         28134,    15,   309,   717,  3307,  1107,  1711,    15,   309,  3153,\n",
      "           275,  4693,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,\n",
      "            15,   754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057,  7993,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         18868,     0,   187]], device='cuda:0')\n",
      "0.0673828125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1992], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6827, 0.3173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 2.4796e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.0673828125\n",
      "KL loss\n",
      "0.1899797022342682\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7447], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6088], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4416], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "25<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Thomson is 25 years old. He lives in Los Angeles. Thomson is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Nic was born in Cairo. He is 20 years old. Nic is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "25<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 9), (None, 8)]\n",
      "decoded_logits2\n",
      "|memory|>Thom are 19. Peter document may become large by large list.<|endoftext|>\n",
      "|memory|>Hello of Thrones is 55 fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What old is Query?<|endoftext|>\n",
      "<|assistant|>\n",
      "47<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 42299,  1665,   310,  2030,  1107,  1711,    15,\n",
      "           754,  4852,   275,  8742,  9757,    15, 41963,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310,  7993,   443, 28134,    15,   309,   717,  3307,\n",
      "          1107,  1711,    15,   309,  3153,   275,  4693,    15,   309,   717,\n",
      "           271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374,\n",
      "         11161,    13, 12951,   369,  5686,   275, 37068,    15,   754,   310,\n",
      "          1384,  1107,  1711,    15, 12951,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "         41963,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          1099,     0,   187]], device='cuda:0')\n",
      "0.044677734375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0262], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-4.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6664, 0.3336]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9883, 0.0099]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.044677734375\n",
      "KL loss\n",
      "0.1772322803735733\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1579.06it/s]\n",
      " 93%|█████████▎| 28/30 [32:44<02:40, 80.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.6935], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.6890], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4850], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Peter Gumbs. I am 22 years old. I live in Londonos. I am an expert in Javascript<|endoftext|><|memory|>Thom is is 55 years old. He lives in Paris. Samantha is an expert in Karate<|endoftext|><|memory|>On 1989, Niconica was born in Cairo. He is 40 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adamantha or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Sam<|endoftext|><|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Samantha or Adam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 9), (None, 5)]\n",
      "decoded_logits2\n",
      "|memory|>Thom is of 20. you you are on, is the place to<|endoftext|> fooduits are huge. the best blue.<|endoftext|> sure to try the. start. of you of go there.<|memory|>Hello of Thrones is 55 fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Peter or or Peter?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adam<|endoftext|><|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,   655,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17232, 36412,   310,  1884,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15,  5769, 36412,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13,  5769, 36412,   390, 13187,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 17232, 36412,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.83203125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.2031], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.5000], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7852, 0.2148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.83203125\n",
      "KL loss\n",
      "0.018484920263290405\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.6953], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.6698], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5862], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 118, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom 1989, Niconica was born in Cairo. He is 50 years old. Veronica is an expert in Python<|endoftext|><|memory|>Thom is is 30 years old. He lives in Paris. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 22 years old. I live in Londonos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Veronica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 21), (None, 18), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>Thom is favorite color is Green<|endoftext|><|memory|>Hello 1989, Nic Adam changes to can allowed in<|endoftext|>\n",
      "|memory|>Hello the first side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What does Adamonica born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Londonoscow<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 118])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 16496,    15,   754,   310,  8978,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 17232, 36412,   310,  1884,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,  5769, 36412,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 13187,   443, 28134,    15,   309,   717,   655,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,   369,  7188, 43510,  5686,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,    46, 15635,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.5546875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.1143], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.1250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.7001, 0.2999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 3.3188e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.5546875\n",
      "KL loss\n",
      "0.17713990807533264\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.7100], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5827], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5076], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 119, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Peter Gumbs. I am 22 years old. I live in Londonos. I am an expert in Javascript<|endoftext|><|memory|>Thom is is 30 years old. He lives in London. Samantha is an expert in Karate<|endoftext|><|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Lag's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 8), (None, 10), (None, 9)]\n",
      "decoded_logits2\n",
      "|memory|>Thom the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Thom Nicically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and output correctly.<|endoftext|><|memory|>Hello of Thrones is 55 fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, George R. R. Martin's series of fantasy novels, the first of which is A Game of Thrones. The show was both produced and filmed in Belfast and elsewhere in the United Kingdom.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Organ an last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 119])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,   655,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17232, 36412,   310,  1884,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15,  5769, 36412,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          1276,   310, 13187,   434,  1390,  1416,    32,     0,   187,    29,\n",
      "            93,   515,  5567, 49651,   187,    40, 28134,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.494140625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0075], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1953], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6644, 0.3356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5469, 0.4531]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.494140625\n",
      "KL loss\n",
      "0.014439806342124939\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6756], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.6435], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4072], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Peter Gumbs. I am 22 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Thom is is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Adam live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 3), (None, 13)]\n",
      "decoded_logits2\n",
      "|memory|>Thom first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team.\n",
      "|memory|>Hello Vegas isacheluit is Gy is<|endoftext|><|endoftext|>25mitlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 21.<|endoftext|> $$$<|endoftext|> 28.<|endoftext|>. Gane. (859,8). Open 24. American. Peterane's.. (\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Nic live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Adamos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,   655,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17232, 36412,   310,  1884,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15,  5769, 36412,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057, 13187,  3153,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 47529,   375,     0,   187]], device='cuda:0')\n",
      "0.384765625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0762], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6510, 0.3490]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 3.6240e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.384765625\n",
      "KL loss\n",
      "0.21340177953243256\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7228], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6540], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5361], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 126, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom is is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name isThom Gumbs. I am 22 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Samantha an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Samantha an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 1), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>Thom hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|memory|>Thom the flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter an an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 126])\n",
      "tensor([[   93, 20704, 49651, 17232, 36412,   310,  1884,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15,  5769, 36412,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 13187,   443, 28134,    15,   309,   717,   655,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          1276,   310,  5769, 36412,   271,  6485,   275,    32,     0,   187,\n",
      "            29,    93,   515,  5567, 49651,   187, 17232, 36412,   310,   271,\n",
      "          6485,   275, 12604,   366,     0,   187]], device='cuda:0')\n",
      "0.294921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 10, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 10, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0228], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0894], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.5746, 0.4254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.4824]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.294921875\n",
      "KL loss\n",
      "0.0023349225521087646\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.7067], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.6668], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4721], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Thomantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Adam or Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Adam or Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 1), (None, 4), (None, 3)]\n",
      "decoded_logits2\n",
      "|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|memory|>Thom the first side of this challenge is enormous opportunity<|endoftext|><|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is older, Nic or Ver??<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,   443,\n",
      "         28134,    15,   309,   717,   655,  1107,  1711,    15,   309,  3153,\n",
      "           275, 15184,   375,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 20704, 49651, 17232, 36412,   310,  1884,  1107,\n",
      "          1711,    15,   754,  4852,   275, 16496,    15,  5769, 36412,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7883,   310,  5662,    13, 13187,   390,  5769, 36412,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 17232, 36412,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.2578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0124], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.1387], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6295, 0.3705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5312, 0.4688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2578125\n",
      "KL loss\n",
      "0.009952567517757416\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.7225], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.6534], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6058], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom 1989, Niconica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|memory|>Thomantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "59<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Veronica?<|endoftext|>\n",
      "<|assistant|>\n",
      "59<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 2), (None, 20), (None, 20)]\n",
      "decoded_logits2\n",
      "|memory|>Thom, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On are right. Query document may become large by large list.<|endoftext|><|memory|>On are right. Query document may become large by large list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Adamonica?<|endoftext|>\n",
      "<|assistant|>\n",
      "19<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13,  7188, 43510,   369,  5686,\n",
      "           275, 16496,    15,   754,   310,  8978,  1107,  1711,    15,  7188,\n",
      "         43510,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 17232, 36412,   310,  1884,  1107,  1711,    15,   754,  4852,\n",
      "           275, 16496,    15,  5769, 36412,   310,   271,  6485,   275, 12604,\n",
      "           366,     0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,\n",
      "           310, 13187,   443, 28134,    15,   309,   717,   655,  1107,  1711,\n",
      "            15,   309,  3153,   275, 15184,   375,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310,  7188, 43510,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  3046,     0,   187]], device='cuda:0')\n",
      "0.2353515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0276], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.5938], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6632, 0.3368]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0038]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2353515625\n",
      "KL loss\n",
      "0.194051131606102\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.6207], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5504], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4391], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 101, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thom is favorite color is Green<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Onantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Pur<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Adam's favorite color is Blue<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Adam's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Blue<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 7), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>Thom first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello first Vegas Raiders is 20 22 of 22 Las Vegas Boulevard in the County, Nevada. is 22 for its concentration of resort hotels and casinos.<|endoftext|> Strip is as it is known, is 20 22.2 miles in6.8 km) in. and is in to of the Las Vegas city limits in the unincorporated G of New and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where is Peter an last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Pur<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 101])\n",
      "tensor([[   93, 20704, 49651, 33467,   434,  7583,  3295,   310, 10063,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 13187,\n",
      "           443, 28134,    15,   309,   717,   655,  1107,  1711,    15,   309,\n",
      "          3153,   275, 15184,   375,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 17232, 36412,   310,  1884,\n",
      "          1107,  1711,    15,   754,  4852,   275, 16496,    15,  5769, 36412,\n",
      "           310,   271,  6485,   275, 12604,   366,     0,    29,    93, 10394,\n",
      "         49651,   187, 32869,   253,  1677,  1953,     0,   187,    29,    93,\n",
      "          4537, 49651,   187,  1276,   310, 13187,   434,  7583,  3295,    32,\n",
      "             0,   187,    29,    93,   515,  5567, 49651,   187, 22036,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.25\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-2.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.2656], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6144, 0.3856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7461, 0.2539]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.25\n",
      "KL loss\n",
      "0.019488878548145294\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.7772], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6911], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5678], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Thomantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Samantha live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha lives in Moscow<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Samantha live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha lives in Moscow<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 7), (None, 10), (None, 19)]\n",
      "decoded_logits2\n",
      "|memory|>Thom hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello youically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|memory|>Hello first in in in the document. documents.<|endoftext|>. are documents are are up the document are stored in a collection called fs.chunks.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ver live live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Samantha lives in Cairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 17232, 36412,   310,  1884,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15,  5769, 36412,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 13187,   443, 28134,    15,   309,   717,   655,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          7161,  1057,  5769, 36412,  3153,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187, 17232, 36412,  4852,   275, 16496,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.10791015625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0145], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.6172], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6902, 0.3098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8320, 0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.10791015625\n",
      "KL loss\n",
      "0.026597589254379272\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.7367], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6895], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.6021], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Helloantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Peter Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "30<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Samantha is 30 years old. He lives in Moscow. Samantha is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lagos. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Veronica was born in Moscow. He is 59 years old. Veronica is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Samantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "30<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 13), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Hello the Python form to write the first<|endoftext|> the first<|endoftext|><|endoftext|> first should be the,2 paragraphs for the of. the outline. and by the list to the related image.<|endoftext|> not use to write the'ss to other to create this task.<|endoftext|>\n",
      "|memory|>Hello Vegas isacheluit is Gy is<|endoftext|>/25mitlet<|endoftext|><|endoftext|><|endoftext|>G)<|endoftext|> 24. 21.<|endoftext|> $$$<|endoftext|> 28.<|endoftext|>. Gane. (859,9). Open 24. American. Peterane's.. (\n",
      "|memory|>Hello 1989, Nic the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Nicantha?<|endoftext|>\n",
      "<|assistant|>\n",
      "1<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 17232, 36412,   310,  1884,  1107,  1711,    15,\n",
      "           754,  4852,   275, 16496,    15,  5769, 36412,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,\n",
      "           619,  1416,   310, 13187,   443, 28134,    15,   309,   717,   655,\n",
      "          1107,  1711,    15,   309,  3153,   275, 15184,   375,    15,   309,\n",
      "           717,   271,  6485,   275, 34619,     0,    29,    93, 20704, 49651,\n",
      "          2374, 11161,    13,  7188, 43510,   369,  5686,   275, 16496,    15,\n",
      "           754,   310,  8978,  1107,  1711,    15,  7188, 43510,   310,   271,\n",
      "          6485,   275, 13814,     0,    29,    93, 10394, 49651,   187, 32869,\n",
      "           253,  1677,  1953,     0,   187,    29,    93,  4537, 49651,   187,\n",
      "          2347,  1711,   310,  5769, 36412,    32,     0,   187,    29,    93,\n",
      "           515,  5567, 49651,   187,  1229,     0,   187]], device='cuda:0')\n",
      "0.09375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0432], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-2.2812], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.7183, 0.2817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9023, 0.0962]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.09375\n",
      "KL loss\n",
      "0.0510336197912693\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2095.79it/s]\n",
      " 97%|█████████▋| 29/30 [34:00<01:19, 79.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "-----------------------------------\n",
      "index_slice\n",
      "[1]\n",
      "top_k\n",
      "[(tensor([0.7139], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5782], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5606], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 115, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Ver was born in Moscowja. He is 20 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello is 32 years old. He lives in Capeos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Thomson born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where was Thomson born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Abuja<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 16), (None, 18)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello firstdown the tasks is up by Ver employee is added to the list.<|endoftext|>\n",
      "|memory|>Hello 1989, Ver the changes to can allowed in<|endoftext|>\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ver born?<|endoftext|>\n",
      "<|assistant|>\n",
      "Thomuja<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 115])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 41963,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  3349,  1107,  1711,    15, 41963,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  2164,  1107,  1711,    15,   754,  4852,   275, 15184,\n",
      "           375,    15, 10053,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,\n",
      "           443, 28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,\n",
      "          3153,   275, 37068,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,   369, 41963,\n",
      "          5686,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          5039,    86,  6362,     0,   187]], device='cuda:0')\n",
      "0.578125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 5, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 5, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0393], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-9.8125], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6929, 0.3071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 5.6982e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.578125\n",
      "KL loss\n",
      "0.18321287631988525\n",
      "index_slice\n",
      "[5]\n",
      "top_k\n",
      "[(tensor([0.6851], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5170], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4502], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 114, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello, my name is Adam Gumbs. I am 19 years old. I live in London. I am an expert in Javascript<|endoftext|><|memory|>On is 30 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>On 1989, Ver was born in Moscowja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Alice live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Cairo<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 3), (None, 14), (None, 10)]\n",
      "decoded_logits2\n",
      "|memory|>Hello isabler the<|endoftext|> is therition<|endoftext|> the team<|endoftext|>\n",
      "|memory|>Hello first Vegas Raiders is 20 20 of 22 Las Vegas Boulevard in Moscow County, Nevada. is 22 for its concentration of resort hotels and casinos. The Strip is as it is known, is 20 22.2 miles in6.8 km) in. and is in to of Moscow Las Vegas city limits in the unincorporated G of New and Winchester. is often considered to as as the Vegas.<|endoftext|>\n",
      "|memory|>Hello Verically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function uses an alternative formulation to compute the output and the correctly.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Ver live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Parisairo<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 114])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,\n",
      "           754,  4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,\n",
      "           275, 12604,   366,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057, 16922,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "            36, 22466,     0,   187]], device='cuda:0')\n",
      "0.330078125\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.3164], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-8.1875], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6935, 0.3065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 3.8147e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.330078125\n",
      "KL loss\n",
      "0.18174134194850922\n",
      "index_slice\n",
      "[9]\n",
      "top_k\n",
      "[(tensor([0.6359], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5759], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.5304], device='cuda:0', grad_fn=<SumBackward1>), 2)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello 1989, Ver was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|memory|>Hello is 28 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 22 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "28<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Thomson?<|endoftext|>\n",
      "<|assistant|>\n",
      "28<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 18), (None, 18), (None, 1)]\n",
      "decoded_logits2\n",
      "|memory|>Hello London, Ver the changes to are allowed in<|endoftext|>\n",
      "|memory|>Hello 1989, Ver small enough documents are stored<|endoftext|><|endoftext|>\n",
      "|memory|>Hello 1989, Donald was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Ver?<|endoftext|>\n",
      "<|assistant|>\n",
      "25<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651,  2374, 11161,    13, 41963,   369,  5686,   275,\n",
      "         26957,  6362,    15,   754,   310,  3349,  1107,  1711,    15, 41963,\n",
      "           310,   271,  6485,   275, 13814,     0,    29,    93, 20704, 49651,\n",
      "         16008,   310,  2164,  1107,  1711,    15,   754,  4852,   275, 15184,\n",
      "           375,    15, 10053,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "            29,    93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,\n",
      "           443, 28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,\n",
      "          3153,   275, 37068,    15,   309,   717,   271,  6485,   275, 34619,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "         41963,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          1619,     0,   187]], device='cuda:0')\n",
      "0.275390625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0076], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.3750], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "1\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6361, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0046]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.275390625\n",
      "KL loss\n",
      "0.21325062215328217\n",
      "index_slice\n",
      "[8]\n",
      "top_k\n",
      "[(tensor([0.8380], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4839], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4054], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 117, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Hello is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 22 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Donald was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Lagos<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Where does Donald live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Lagos<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 5), (None, 0), (None, 15)]\n",
      "decoded_logits2\n",
      "|memory|>Hello first step is to identify the right people to lead the change<|endoftext|><|memory|>Hello is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Helloable of 20 in you you are on, is the place to<|endoftext|> fooduits are huge. the best blue.<|endoftext|> sure to try the. get. of you of go there.<|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How does Ver live?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald lives in Lagos<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 117])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 16922,   443, 28134,    15,   309,   717,  3495,  1107,\n",
      "          1711,    15,   309,  3153,   275, 37068,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7161,  1057, 10053,\n",
      "          3153,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "         16008,  4852,   275, 15184,   375,     0,   187]], device='cuda:0')\n",
      "0.21875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 7, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 7, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0262], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.8008], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6008, 0.3992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6836, 0.3164]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.21875\n",
      "KL loss\n",
      "0.007896825671195984\n",
      "index_slice\n",
      "[4]\n",
      "top_k\n",
      "[(tensor([0.5901], device='cuda:0', grad_fn=<SumBackward1>), 21), (tensor([0.5433], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4114], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 100, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Onice is favorite color is Blue<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Red<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Alice's favorite color is Red<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's favorite color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Red<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 20), (None, 16), (None, 14)]\n",
      "decoded_logits2\n",
      "|memory|>On are 19. Ver document may become large by large list.<|endoftext|><|memory|>Hello firstdown the tasks is up by Ver employee is added to the list.<|endoftext|><|memory|>Hello first Vegas Raiders is 22 22 of 22 Las Vegas Boulevard in Moscow County, Nevada. is 22 for its concentration of resort hotels and casinos.<|endoftext|> 22 is as it is known, is 20 22.2 miles in6.8 km) in. and is in to of Moscow Las Vegas city limits in the unincorporated G of Cairo and Winchester. is often considered to as as the Vegas.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Adam's last color?<|endoftext|>\n",
      "<|assistant|>\n",
      "Y<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 100])\n",
      "tensor([[   93, 20704, 49651,  2422,   547,   434,  7583,  3295,   310,  4410,\n",
      "             0,    29,    93, 20704, 49651, 12092,    13,   619,  1416,   310,\n",
      "         16922,   443, 28134,    15,   309,   717,  3495,  1107,  1711,    15,\n",
      "           309,  3153,   275, 37068,    15,   309,   717,   271,  6485,   275,\n",
      "         34619,     0,    29,    93, 20704, 49651, 16008,   310,  2164,  1107,\n",
      "          1711,    15,   754,  4852,   275, 15184,   375,    15, 10053,   310,\n",
      "           271,  6485,   275, 12604,   366,     0,    29,    93, 10394, 49651,\n",
      "           187, 32869,   253,  1677,  1953,     0,   187,    29,    93,  4537,\n",
      "         49651,   187,  1276,   310, 16922,   434,  7583,  3295,    32,     0,\n",
      "           187,    29,    93,   515,  5567, 49651,   187, 10252,     0,   187]],\n",
      "       device='cuda:0')\n",
      "0.2353515625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-1.2891], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-3.4375], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "21\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6668, 0.3332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8945, 0.1045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.2353515625\n",
      "KL loss\n",
      "0.07072798162698746\n",
      "index_slice\n",
      "[0]\n",
      "top_k\n",
      "[(tensor([0.8204], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4813], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4680], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 113, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>On is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Ver was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "24<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "24<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 6), (None, 6), (None, 12)]\n",
      "decoded_logits2\n",
      "|memory|>On the Python form to write the first<|endoftext|> the report<|endoftext|><|endoftext|> first should be the,2 paragraphs for the of. the outline. and by the list to the more image.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|>\n",
      "|memory|>Hello the Python outline to draft the content of the newsletter.<|endoftext|> draft should contain 1-2 sentences about each topic in the draft, followed by a link to a relevant article.<|endoftext|> not attempt to use Google Docs or tables to perform this task.<|endoftext|><|memory|>Hello Ver of 20's on the favorite online online sources sites.\n",
      "|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How old is Nic?<|endoftext|>\n",
      "<|assistant|>\n",
      "55<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 113])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 16922,   443, 28134,    15,   309,   717,  3495,  1107,\n",
      "          1711,    15,   309,  3153,   275, 37068,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
      "         10053,    32,     0,   187,    29,    93,   515,  5567, 49651,   187,\n",
      "          1348,     0,   187]], device='cuda:0')\n",
      "0.1513671875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0071], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-5.6250], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.7101, 0.2899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9961, 0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1513671875\n",
      "KL loss\n",
      "0.1606249213218689\n",
      "index_slice\n",
      "[6]\n",
      "top_k\n",
      "[(tensor([0.7013], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6084], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4666], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Sam is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Ver was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Donald or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Donald or Alice?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 0), (None, 12), (None, 6)]\n",
      "decoded_logits2\n",
      "|memory|>Sam is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello Ver of 20's on Sam favorite media online sources sites.<|memory|>On the Python Python to write the first for your first<|endoftext|><|endoftext|> first should be the,2 paragraphs for the of. the list. and by a list to the related image.<|endoftext|> not use to write the Docs to other to create this task.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Donald or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 16922,   443, 28134,    15,   309,   717,  3495,  1107,\n",
      "          1711,    15,   309,  3153,   275, 37068,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13, 10053,   390, 16922,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 16008,     0,   187]], device='cuda:0')\n",
      "0.1318359375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0042], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0043], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6071, 0.3929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1318359375\n",
      "KL loss\n",
      "0.012607082724571228\n",
      "index_slice\n",
      "[2]\n",
      "top_k\n",
      "[(tensor([0.6937], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.5428], device='cuda:0', grad_fn=<SumBackward1>), 1), (tensor([0.5386], device='cuda:0', grad_fn=<SumBackward1>), 0)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Sam, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Adam was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|memory|>Sam is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Alice's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Alice's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 11), (None, 7), (None, 16)]\n",
      "decoded_logits2\n",
      "|memory|>Sam can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello hurts ability to keep democracy alive - Gane Neff told the BBC that AI is damaging media organisation's ability to generate profits.<|endoftext|><|memory|>Hello firstdown the tasks is up by Ver employee is added to the list.<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Adam's last name?<|endoftext|>\n",
      "<|assistant|>\n",
      "Gumbs<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 12092,    13,   619,  1416,   310, 16922,   443,\n",
      "         28134,    15,   309,   717,  3495,  1107,  1711,    15,   309,  3153,\n",
      "           275, 37068,    15,   309,   717,   271,  6485,   275, 34619,     0,\n",
      "            29,    93, 20704, 49651,  2374, 11161,    13, 41963,   369,  5686,\n",
      "           275, 26957,  6362,    15,   754,   310,  3349,  1107,  1711,    15,\n",
      "         41963,   310,   271,  6485,   275, 13814,     0,    29,    93, 20704,\n",
      "         49651, 16008,   310,  2164,  1107,  1711,    15,   754,  4852,   275,\n",
      "         15184,   375,    15, 10053,   310,   271,  6485,   275, 12604,   366,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  1276,   310, 16922,\n",
      "           434,  1390,  1416,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187,    40, 28134,     0,   187]], device='cuda:0')\n",
      "0.1044921875\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 4, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 4, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0029], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.4043], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "2\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6447, 0.3553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5977, 0.4004]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1044921875\n",
      "KL loss\n",
      "0.00044780969619750977\n",
      "index_slice\n",
      "[3]\n",
      "top_k\n",
      "[(tensor([0.6953], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.6122], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.4182], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 116, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Sam is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Adam was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Donald or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "Who is older, Alice or Donald?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 2), (None, 4)]\n",
      "decoded_logits2\n",
      "|memory|>Samia of 20. you you are on, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to get the. start. of you of go there.<|memory|>On, my name is Adam Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On Sam flip side of this challenge is enormous opportunity<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is older, Alice or Sam?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 116])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 16922,   443, 28134,    15,   309,   717,  3495,  1107,\n",
      "          1711,    15,   309,  3153,   275, 37068,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  7883,   310,  5662,\n",
      "            13, 16922,   390, 10053,    32,     0,   187,    29,    93,   515,\n",
      "          5567, 49651,   187, 16008,     0,   187]], device='cuda:0')\n",
      "0.1181640625\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 3, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 3, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0043], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-0.0060], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.6458, 0.3542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5000, 0.5000]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.1181640625\n",
      "KL loss\n",
      "0.02308966964483261\n",
      "index_slice\n",
      "[7]\n",
      "top_k\n",
      "[(tensor([0.7423], device='cuda:0', grad_fn=<SumBackward1>), 0), (tensor([0.4390], device='cuda:0', grad_fn=<SumBackward1>), 2), (tensor([0.3668], device='cuda:0', grad_fn=<SumBackward1>), 1)]\n",
      "shift_logits_shape\n",
      "torch.Size([1, 121, 50280])\n",
      "-----------\n",
      "decoded_logits\n",
      "|memory|>Sam is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Alice was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "decoded_labels\n",
      "|memory|>Donald is 24 years old. He lives in Lagos. Donald is an expert in Karate<|endoftext|><|memory|>Hello, my name is Alice Gumbs. I am 23 years old. I live in Cairo. I am an expert in Javascript<|endoftext|><|memory|>On 1989, Thomson was born in Abuja. He is 28 years old. Thomson is an expert in Python<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "What is Donald an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "\n",
      "---------------\n",
      "[(None, 15), (None, 11), (None, 17)]\n",
      "decoded_logits2\n",
      "|memory|>Samia of 20. you you are on, is the place to<|endoftext|> fooduits are huge. the blue blue.<|endoftext|> sure to get the. start. of you of go there.<|memory|>Hello can use the Python json module to pretty-print the JSON data. <|endoftext|><|memory|>Hello am 20 database of 20. average document size is 2828 Bytes..<|endoftext|><|system|>\n",
      "Answer the given question<|endoftext|>\n",
      "<|user|>\n",
      "How is Adam an expert in?<|endoftext|>\n",
      "<|assistant|>\n",
      "Donald is an expert in Karate<|endoftext|>\n",
      "<\n",
      "-------------\n",
      "labels shape\n",
      "torch.Size([1, 121])\n",
      "tensor([[   93, 20704, 49651, 16008,   310,  2164,  1107,  1711,    15,   754,\n",
      "          4852,   275, 15184,   375,    15, 10053,   310,   271,  6485,   275,\n",
      "         12604,   366,     0,    29,    93, 20704, 49651, 12092,    13,   619,\n",
      "          1416,   310, 16922,   443, 28134,    15,   309,   717,  3495,  1107,\n",
      "          1711,    15,   309,  3153,   275, 37068,    15,   309,   717,   271,\n",
      "          6485,   275, 34619,     0,    29,    93, 20704, 49651,  2374, 11161,\n",
      "            13, 41963,   369,  5686,   275, 26957,  6362,    15,   754,   310,\n",
      "          3349,  1107,  1711,    15, 41963,   310,   271,  6485,   275, 13814,\n",
      "             0,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
      "             0,   187,    29,    93,  4537, 49651,   187,  1276,   310, 10053,\n",
      "           271,  6485,   275,    32,     0,   187,    29,    93,   515,  5567,\n",
      "         49651,   187, 16008,   310,   271,  6485,   275, 12604,   366,     0,\n",
      "           187]], device='cuda:0')\n",
      "0.0615234375\n",
      "shift_logits_r shape\n",
      "torch.Size([1, 9, 50280])\n",
      "shift_logits2 shape\n",
      "torch.Size([1, 9, 50280])\n",
      "---------- Retriever ------------\n",
      "s_retrieval shape\n",
      "tensor([-0.0065], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_random shape\n",
      "tensor([-1.1406], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SumBackward1>)\n",
      "s_retrieval > s_random\n",
      "tensor([True], device='cuda:0')\n",
      "s_r1 shape\n",
      "s_r2 shape\n",
      "0\n",
      "a_r shape\n",
      "torch.Size([1, 2])\n",
      "s_r shape\n",
      "torch.Size([1, 2])\n",
      "a_r s_r\n",
      "tensor([[0.7027, 0.2973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7578, 0.2432]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Losses\n",
      "-----------------------------\n",
      "Generator Loss\n",
      "0.0615234375\n",
      "KL loss\n",
      "0.0043123215436935425\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1488.03it/s]\n",
      "100%|██████████| 30/30 [35:18<00:00, 70.61s/it]\n"
     ]
    }
   ],
   "source": [
    "# We finetune in an alternating pattern, first generator, then retriever\n",
    "indices = np.arange(len(toy_data_preprocessed[\"input_ids_r\"]))\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    np.random.shuffle(indices)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    for i in range(0, len(indices), BATCH_SIZE):\n",
    "        index_slice = indices[i : i + BATCH_SIZE]\n",
    "        batch_x_r = [toy_data_preprocessed[\"input_ids_r\"][i] for i in index_slice]\n",
    "        batch_x_g = [toy_data_preprocessed[\"input_ids_g\"][i] for i in index_slice]\n",
    "        batch_x_g_len = torch.tensor([len(i) for i in batch_x_g])\n",
    "\n",
    "        batch_y_g = [toy_data_preprocessed[\"label_ids\"][i] for i in index_slice]\n",
    "        batch_y_g_len = torch.tensor([len(i) for i in batch_y_g])\n",
    "\n",
    "        batch_x_r = torch.nn.utils.rnn.pad_sequence(\n",
    "            batch_x_r, batch_first=True, padding_value=0\n",
    "        ).cuda()\n",
    "        batch_x_g = torch.nn.utils.rnn.pad_sequence(\n",
    "            batch_x_g, batch_first=True, padding_value=0\n",
    "        ).cuda()\n",
    "        batch_y_g = torch.nn.utils.rnn.pad_sequence(\n",
    "            batch_y_g, batch_first=True, padding_value=0\n",
    "        ).cuda()\n",
    "        print(\"index_slice\")\n",
    "        print(index_slice)\n",
    "\n",
    "        # Optimize Generator\n",
    "        top_k = mama.retrieve(batch_x_r, embedded_corpus, k=3)\n",
    "        print(\"top_k\")\n",
    "        print(top_k)\n",
    "\n",
    "        out, augmented_input_ids = mama.generate(\n",
    "            query_g=batch_x_g,\n",
    "            embedded_corpus=embedded_corpus,\n",
    "            memory_indices=top_k,\n",
    "            return_augmented_input_ids=True,\n",
    "        )\n",
    "        logits = out.logits\n",
    "        labels = augmented_input_ids[:, 1:].cuda().contiguous()\n",
    "        labels_r = batch_y_g[:, 6:].cuda().contiguous()\n",
    "        # labels = batch_x_g[:, 1:].cuda().contiguous()\n",
    "        shift_offset = 5 + (logits.shape[1] - ((batch_x_g.shape[1] - batch_x_g_len) + batch_y_g_len)).cuda()\n",
    "        shift_logits_r = logits[:, shift_offset:-1, :].contiguous()\n",
    "        shift_logits = logits[:, :-1, :].contiguous()\n",
    "        # shift_offset = (logits.shape[1] - ((batch_x_g.shape[1] - batch_x_g_len))).cuda()\n",
    "        print(\"shift_logits_shape\")\n",
    "        print(shift_logits.shape)\n",
    "        print(\"-----------\")\n",
    "        # Decode logits\n",
    "        decoded_logits = g_tokenizer.decode(logits[0].argmax(dim=-1))\n",
    "        print(\"decoded_logits\")\n",
    "        print(decoded_logits)\n",
    "\n",
    "        # Decode labels\n",
    "        decoded_labels = g_tokenizer.decode(labels[0])\n",
    "        print(\"decoded_labels\")\n",
    "        print(decoded_labels)\n",
    "        print(\"---------------\")\n",
    "\n",
    "        # Sample 3 random memories\n",
    "        rand_memory_indices = np.random.choice(len(memory_corpus), 3)\n",
    "        rand_memory_indices = [(None, i) for i in rand_memory_indices]\n",
    "        print(rand_memory_indices)\n",
    "\n",
    "        out2 = mama.generate(batch_x_g, embedded_corpus, rand_memory_indices)\n",
    "        shift_offset2 = 5 + (out2.logits.shape[1] - ((batch_x_g.shape[1] - batch_x_g_len) + batch_y_g_len)).cuda()\n",
    "        shift_logits2 = out2.logits[:, shift_offset2:-1, :].contiguous()\n",
    "\n",
    "        # Decode logits\n",
    "        decoded_logits2 = g_tokenizer.decode(out2.logits[0].argmax(dim=-1))\n",
    "        print(\"decoded_logits2\")\n",
    "        print(decoded_logits2)\n",
    "        print(\"-------------\")\n",
    "\n",
    "        print(\"labels shape\")\n",
    "        print(labels.shape)\n",
    "        print(labels)\n",
    "\n",
    "\n",
    "\n",
    "        generator_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        loss = generator_loss_fn(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)), labels.view(-1)\n",
    "        )\n",
    "        optimizer1.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        # Clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(mama.generator.parameters(), 1.0)\n",
    "        optimizer1.step()\n",
    "        # Print loss\n",
    "        generator_loss = loss.item()\n",
    "        print(loss.item())\n",
    "        # Optimize Retriever\n",
    "\n",
    "        # Get embedding for the query\n",
    "        query_r_emb = mama.retriever.model.forward(batch_x_r)\n",
    "\n",
    "        print(\"shift_logits_r shape\")\n",
    "        print(shift_logits_r.shape)\n",
    "\n",
    "        print(\"shift_logits2 shape\")\n",
    "        print(shift_logits2.shape)\n",
    "\n",
    "        # Calculate s_retrieval, the probability of the generated response given the memory\n",
    "        s_retrieval = F.log_softmax(shift_logits_r, dim=2).gather(dim=2, index=labels_r.unsqueeze(2)).squeeze(2).sum(dim=1)\n",
    "        # Calculate s_random, the probability of the generated response given a random memory\n",
    "        s_random = F.log_softmax(shift_logits2, dim=2).gather(dim=2, index=labels_r.unsqueeze(2)).squeeze(2).sum(dim=1)\n",
    "\n",
    "        print(\"---------- Retriever ------------\")\n",
    "\n",
    "        print(\"s_retrieval shape\")\n",
    "        print(s_retrieval)\n",
    "\n",
    "        print(\"s_random shape\")\n",
    "        print(s_random)\n",
    "\n",
    "        print(\"s_retrieval > s_random\")\n",
    "        print(s_retrieval > s_random)\n",
    "\n",
    "        # s_r1 = exp(s_retrieval  ) / (exp(s_retrieval ) + exp(s_random ))\n",
    "        # s_r2 = exp(s_random  ) / (exp(s_retrieval ) + exp(s_random ))\n",
    "\n",
    "        print(\"s_r1 shape\")\n",
    "        # print(s_r1.shape)\n",
    "\n",
    "        print(\"s_r2 shape\")\n",
    "        # print(s_r2.shape)\n",
    "\n",
    "        # s_r = torch.stack([s_r1, s_r2], dim=1)\n",
    "        s_r = F.softmax(torch.stack([s_retrieval, s_random], dim=1), dim=1)\n",
    "\n",
    "        print(top_k[0][1])\n",
    "\n",
    "        # Calculate the average embedding of the items in the memory\n",
    "        avg_memory_emb_r = torch.stack(\n",
    "            [\n",
    "                mama.retriever.model.forward(corpos_r_tokens[i[1]][\"input_ids\"].cuda())\n",
    "                for i in top_k\n",
    "            ]\n",
    "        ).mean(dim=0)\n",
    "        # mama.retriever.cpu()\n",
    "        # avg_memory_emb_r = torch.stack(\n",
    "        #     [\n",
    "        #         mama.retriever.model.forward(corpos_r_tokens[i[1]][\"input_ids\"])\n",
    "        #         for i in top_k\n",
    "        #     ]\n",
    "        # ).mean(dim=0)\n",
    "\n",
    "        # Calculate the average embedding of t\n",
    "        # he items in the random memory\n",
    "        avg_random_emb_r = torch.stack(\n",
    "            [\n",
    "                mama.retriever.model.forward(corpos_r_tokens[i[1]][\"input_ids\"].cuda())\n",
    "                for i in rand_memory_indices\n",
    "            ]\n",
    "        ).mean(dim=0)\n",
    "\n",
    "        # Calculate the cosine similarity between the query and the average memory embedding\n",
    "        a_memory = cos(query_r_emb, avg_memory_emb_r)\n",
    "\n",
    "        # Calculate the cosine similarity between the query and the average random memory embedding\n",
    "        a_random = cos(query_r_emb, avg_random_emb_r)\n",
    "\n",
    "        # a_r1 = exp(a_memory ) / (exp(a_memory ) + exp(a_random ))\n",
    "        # a_r2 = exp(a_random ) / (exp(a_memory ) + exp(a_random ))\n",
    "\n",
    "        # a_r = torch.stack([a_r1, a_r2], dim=1)\n",
    "        a_r = torch.softmax(torch.stack([a_memory, a_random], dim=1), dim=1)\n",
    "\n",
    "        print(\"a_r shape\")\n",
    "        print(a_r.shape)\n",
    "\n",
    "        print(\"s_r shape\")\n",
    "        print(s_r.shape)\n",
    "\n",
    "        print(\"a_r s_r\")\n",
    "        print(a_r)\n",
    "        print(s_r)\n",
    "\n",
    "        # Minimize the KL divergence between a_r and s_r\n",
    "        if epoch > 10:\n",
    "            kl_loss = torch.nn.KLDivLoss()\n",
    "            loss = kl_loss(a_r.log(), s_r.detach())\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(mama.retriever.parameters(), 1.0)\n",
    "            optimizer2.step()\n",
    "        # Print loss\n",
    "        print(\"Losses\")\n",
    "        print(\"-----------------------------\")\n",
    "        print(\"Generator Loss\")\n",
    "        print(generator_loss)\n",
    "        print(\"KL loss\")\n",
    "        print(loss.item())\n",
    "    # Randomize the dataset\n",
    "    toy_data_preprocessed, embedded_corpus = randomize_dataset(device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([(1/100) * (max(n-1, 0) / 99) for n in range(1, 101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for n=0\n",
      "0.0\n",
      "probability for n=1\n",
      "0.0\n",
      "probability for n=2\n",
      "0.010101010101010102\n",
      "probability for n=3\n",
      "0.020202020202020204\n",
      "probability for n=4\n",
      "0.030303030303030304\n",
      "probability for n=5\n",
      "0.04040404040404041\n",
      "probability for n=6\n",
      "0.050505050505050504\n",
      "probability for n=7\n",
      "0.06060606060606061\n",
      "probability for n=8\n",
      "0.0707070707070707\n",
      "probability for n=9\n",
      "0.08080808080808081\n",
      "probability for n=10\n",
      "0.09090909090909091\n",
      "probability for n=11\n",
      "0.10101010101010101\n",
      "probability for n=12\n",
      "0.1111111111111111\n",
      "probability for n=13\n",
      "0.12121212121212122\n",
      "probability for n=14\n",
      "0.13131313131313133\n",
      "probability for n=15\n",
      "0.1414141414141414\n",
      "probability for n=16\n",
      "0.15151515151515152\n",
      "probability for n=17\n",
      "0.16161616161616163\n",
      "probability for n=18\n",
      "0.1717171717171717\n",
      "probability for n=19\n",
      "0.18181818181818182\n",
      "probability for n=20\n",
      "0.1919191919191919\n",
      "probability for n=21\n",
      "0.20202020202020202\n",
      "probability for n=22\n",
      "0.21212121212121213\n",
      "probability for n=23\n",
      "0.2222222222222222\n",
      "probability for n=24\n",
      "0.23232323232323232\n",
      "probability for n=25\n",
      "0.24242424242424243\n",
      "probability for n=26\n",
      "0.25252525252525254\n",
      "probability for n=27\n",
      "0.26262626262626265\n",
      "probability for n=28\n",
      "0.2727272727272727\n",
      "probability for n=29\n",
      "0.2828282828282828\n",
      "probability for n=30\n",
      "0.29292929292929293\n",
      "probability for n=31\n",
      "0.30303030303030304\n",
      "probability for n=32\n",
      "0.31313131313131315\n",
      "probability for n=33\n",
      "0.32323232323232326\n",
      "probability for n=34\n",
      "0.3333333333333333\n",
      "probability for n=35\n",
      "0.3434343434343434\n",
      "probability for n=36\n",
      "0.35353535353535354\n",
      "probability for n=37\n",
      "0.36363636363636365\n",
      "probability for n=38\n",
      "0.37373737373737376\n",
      "probability for n=39\n",
      "0.3838383838383838\n",
      "probability for n=40\n",
      "0.3939393939393939\n",
      "probability for n=41\n",
      "0.40404040404040403\n",
      "probability for n=42\n",
      "0.41414141414141414\n",
      "probability for n=43\n",
      "0.42424242424242425\n",
      "probability for n=44\n",
      "0.43434343434343436\n",
      "probability for n=45\n",
      "0.4444444444444444\n",
      "probability for n=46\n",
      "0.45454545454545453\n",
      "probability for n=47\n",
      "0.46464646464646464\n",
      "probability for n=48\n",
      "0.47474747474747475\n",
      "probability for n=49\n",
      "0.48484848484848486\n",
      "probability for n=50\n",
      "0.494949494949495\n",
      "probability for n=51\n",
      "0.5050505050505051\n",
      "probability for n=52\n",
      "0.5151515151515151\n",
      "probability for n=53\n",
      "0.5252525252525253\n",
      "probability for n=54\n",
      "0.5353535353535354\n",
      "probability for n=55\n",
      "0.5454545454545454\n",
      "probability for n=56\n",
      "0.5555555555555556\n",
      "probability for n=57\n",
      "0.5656565656565656\n",
      "probability for n=58\n",
      "0.5757575757575758\n",
      "probability for n=59\n",
      "0.5858585858585859\n",
      "probability for n=60\n",
      "0.5959595959595959\n",
      "probability for n=61\n",
      "0.6060606060606061\n",
      "probability for n=62\n",
      "0.6161616161616161\n",
      "probability for n=63\n",
      "0.6262626262626263\n",
      "probability for n=64\n",
      "0.6363636363636364\n",
      "probability for n=65\n",
      "0.6464646464646465\n",
      "probability for n=66\n",
      "0.6565656565656566\n",
      "probability for n=67\n",
      "0.6666666666666666\n",
      "probability for n=68\n",
      "0.6767676767676768\n",
      "probability for n=69\n",
      "0.6868686868686869\n",
      "probability for n=70\n",
      "0.696969696969697\n",
      "probability for n=71\n",
      "0.7070707070707071\n",
      "probability for n=72\n",
      "0.7171717171717171\n",
      "probability for n=73\n",
      "0.7272727272727273\n",
      "probability for n=74\n",
      "0.7373737373737373\n",
      "probability for n=75\n",
      "0.7474747474747475\n",
      "probability for n=76\n",
      "0.7575757575757576\n",
      "probability for n=77\n",
      "0.7676767676767676\n",
      "probability for n=78\n",
      "0.7777777777777778\n",
      "probability for n=79\n",
      "0.7878787878787878\n",
      "probability for n=80\n",
      "0.797979797979798\n",
      "probability for n=81\n",
      "0.8080808080808081\n",
      "probability for n=82\n",
      "0.8181818181818182\n",
      "probability for n=83\n",
      "0.8282828282828283\n",
      "probability for n=84\n",
      "0.8383838383838383\n",
      "probability for n=85\n",
      "0.8484848484848485\n",
      "probability for n=86\n",
      "0.8585858585858586\n",
      "probability for n=87\n",
      "0.8686868686868687\n",
      "probability for n=88\n",
      "0.8787878787878788\n",
      "probability for n=89\n",
      "0.8888888888888888\n",
      "probability for n=90\n",
      "0.898989898989899\n",
      "probability for n=91\n",
      "0.9090909090909091\n",
      "probability for n=92\n",
      "0.9191919191919192\n",
      "probability for n=93\n",
      "0.9292929292929293\n",
      "probability for n=94\n",
      "0.9393939393939394\n",
      "probability for n=95\n",
      "0.9494949494949495\n",
      "probability for n=96\n",
      "0.9595959595959596\n",
      "probability for n=97\n",
      "0.9696969696969697\n",
      "probability for n=98\n",
      "0.9797979797979798\n",
      "probability for n=99\n",
      "0.98989898989899\n",
      "probability for n=100\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4950495049504948"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = 0\n",
    "for n in range(1, 101):\n",
    "  print(f\"probability for n={n}\")\n",
    "  prob = (max(n-1, 0) / 99)\n",
    "  print(prob)\n",
    "  weighted_sum += (1/101) * prob\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.7401], device='cuda:0', grad_fn=<SumBackward1>), 1),\n",
       " (tensor([0.6285], device='cuda:0', grad_fn=<SumBackward1>), 0),\n",
       " (tensor([0.4782], device='cuda:0', grad_fn=<SumBackward1>), 2)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  2171,  2003,  8472, 14545, 16031,  5910,\n",
       "          1012,  1045,  2572,  2676,  2086,  2214,  1012,  1045,  2444,  1999,\n",
       "          2047,  2259,  1012,  1045,  2572,  2019,  6739,  1999,  9262, 22483,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpos_r_tokens[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = mama.forward(\n",
    "  query_r=toy_data_preprocessed[\"input_ids_r\"][0].unsqueeze(0).cuda(),\n",
    "  query_g=toy_data_preprocessed[\"input_ids_g\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mama.state_dict(), \"./mama_toy.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutput(logits=tensor([[[  6.0000,  -9.5625,   7.0625,  ...,  -9.6875,  -9.5000,  -9.6875],\n",
       "         [ 11.5000,  -5.4062,  11.8750,  ...,  -5.3438,  -4.9375,  -4.6562],\n",
       "         [  8.2500, -11.5000,   7.5938,  ..., -11.1875, -11.5625, -11.4375],\n",
       "         ...,\n",
       "         [ 31.7500,  -9.8750,  11.9375,  ..., -10.0625, -10.5625, -10.5000],\n",
       "         [ 25.2500,  -5.3125,  15.1875,  ...,  -4.6250,  -4.8750,  -4.7812],\n",
       "         [ 21.2500,  -2.9688,  15.9375,  ...,  -2.4531,  -2.8125,  -2.7188]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"'<|system|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nHow old is Minh?<|endoftext|>\\n\"\n",
    "s_tokens = g_tokenizer.encode(s, add_special_tokens=False, return_tensors=\"pt\")\n",
    "s_tokens_r = r_tokenizer.encode(s, add_special_tokens=False, return_tensors=\"pt\")\n",
    "s_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    8,    29,    93, 10394, 49651,   187, 32869,   253,  1677,  1953,\n",
       "             0,   187,    29,    93,  4537, 49651,   187,  2347,  1711,   310,\n",
       "          3689,    73,    32,     0,   187]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tokens.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3s = mama.forward(\n",
    "  query_r=s_tokens_r.cuda(),\n",
    "  query_g=s_tokens.cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.4305], device='cuda:0', grad_fn=<SumBackward1>), 1),\n",
       " (tensor([0.4060], device='cuda:0', grad_fn=<SumBackward1>), 2),\n",
       " (tensor([0.3624], device='cuda:0', grad_fn=<SumBackward1>), 0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topks = mama.retrieve(\n",
    "  query_r=s_tokens_r.cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")\n",
    "topks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3s = mama.generate(\n",
    "  query_g=s_tokens.cuda(),\n",
    "  embedded_corpus=embedded_corpus,\n",
    "  memory_indices=topks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|memory|>Adam 1989, Adamantha was born in Abu. He is 26 years old. Samantha is an expert in Python<|endoftext|><|memory|>Hello, my name is Thomsonanthaumbs. I am 19 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|memory|>Adam is 41 years old. He lives in Parisja. Donald is an expert in Karate<|endoftext|><<|user|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nHow old is Samh?<|endoftext|>\\n<'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(out3s.logits[0].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|memory|>Adam 1989, Ver was born in Lagos. He is 26 years old. Adam is an expert in Python<|endoftext|><|memory|>Helloachel is 23 years old. He lives in Paris. Rachel is an expert in Karate<|endoftext|><|memory|>Hello, my name is Thomson Gumbs. I am 21 years old. I live in Paris. I am an expert in Javascript<|endoftext|><|system|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nHow was Adam born?<|endoftext|>\\n<|assistant|>\\nLagos<|endoftext|>\\n<'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_memory_indices = np.random.choice(len(memory_corpus), 3)\n",
    "rand_memory_indices = [(None, i) for i in rand_memory_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out4 = mama.generate(\n",
    "  query_g=toy_data_preprocessed[\"input_ids_g\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus,\n",
    "  memory_indices=rand_memory_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"|memory|>Adam more of's is<|endoftext|> the favorite game sources source sites.<|memory|>Hello the technology that allows you to simulate organizational dynamics at the computational level is key to training the Organizational AI and this vision overall.<|endoftext|><|memory|>Hello are right. Query document may become large by large list.<|endoftext|><|system|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nWhat old is Ver?<|endoftext|>\\n<|assistant|>\\n35<|endoftext|>\\n<\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(out4.logits[0].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = mama.retrieve(\n",
    "  query_r=toy_data_preprocessed[\"input_ids_r\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus\n",
    ")\n",
    "\n",
    "out5 = mama.generate(\n",
    "  query_g=toy_data_preprocessed[\"input_ids_g\"][0].unsqueeze(0).cuda(),\n",
    "  embedded_corpus=embedded_corpus,\n",
    "  memory_indices=topk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|memory|>Adam is 41 years old. He lives in Parisja. Donald is an expert in Karate<|endoftext|><|memory|>Hello 1989, Adamantha was born in Abu. He is 26 years old. Samantha is an expert in Python<|endoftext|><|memory|>Hello, my name is Thomsonanthaumbs. I am 19 years old. I live in Lag. I am an expert in Javascript<|endoftext|><|system|>\\nAnswer the given question<|endoftext|>\\n<|user|>\\nWho old is Sam?<|endoftext|>\\n<|assistant|>\\n58<|endoftext|>\\n<'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.decode(out5.logits[0].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   29,    93,   515,  5567, 49651,  1812]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tokenizer.encode(\"<|assistant|>36\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2848533056"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(mama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
