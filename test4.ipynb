{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mocuto/anaconda3/envs/m2/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from based.models.gpt import GPTLMHeadModel\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'causal_attention_cuda'\n",
      "Successfully imported the causal dot product kernel! \n",
      "Successfully imported the FLA triton kernels! \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPTLMHeadModel.from_pretrained_hf(\"hazyresearch/based-360m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTLMHeadModel(\n",
       "  (transformer): GPTModel(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(50264, 1024)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (3-5): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (8-10): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (13-15): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (18-20): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (23-26): 4 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0, inplace=False)\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTLMHeadModel(\n",
       "  (transformer): GPTModel(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(50264, 1024)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (3-5): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (8-10): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (13-15): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (18-20): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (23-26): 4 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0, inplace=False)\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the the\n"
     ]
    }
   ],
   "source": [
    "text = \"Paris is the capital of \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "output = model(input_ids.cuda(), num_last_tokens=2)[0]\n",
    "prediction = torch.argmax(output, dim=-1)\n",
    "prediction_text = tokenizer.decode(prediction[0], skip_special_tokens=True)\n",
    "print(prediction_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I take one more step, it will be a very long time before I will be able to\n"
     ]
    }
   ],
   "source": [
    "input = tokenizer.encode(\"If I take one more step, it will be\", return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(input, max_length=20)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3466, -1.0931, -0.3796,  ...,  1.4669,  1.1784, -0.6306],\n",
       "         [ 0.9851, -0.9446,  0.2412,  ...,  1.4911,  1.0009, -1.1894],\n",
       "         [-0.3481,  0.6451, -0.4064,  ...,  1.4124,  0.5562, -1.0948],\n",
       "         [ 1.2101, -2.3107,  0.3959,  ...,  1.3128, -0.5501, -1.4398],\n",
       "         [ 0.4671, -0.2395,  0.8004,  ...,  2.0549,  0.0364,  0.5992],\n",
       "         [ 0.6768, -0.1461,  0.9306,  ...,  1.3063,  0.4129,  0.0129]]],\n",
       "       device='cuda:0', grad_fn=<DropoutAddLayerNormFnBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "output = model.transformer.forward(input_ids.cuda())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 1024])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = model.transformer.forward_with_hidden_states(output)\n",
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutput(logits=tensor([[[ 1.4798,  5.1853, -0.6468,  ..., -8.5160, -8.8513, -8.6187]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3 = model.forward(input_ids, hidden_states=output2, num_last_tokens=1)\n",
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.argmax(output3[0], dim=-1)\n",
    "prediction_text = tokenizer.decode(prediction[0], skip_special_tokens=True)\n",
    "print(prediction_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0140,  0.1109, -0.0666,  ..., -0.0406,  0.0346, -0.0036],\n",
       "        [-0.0723,  0.0188, -0.0229,  ...,  0.0148, -0.1590,  0.0202],\n",
       "        [-0.0382, -0.2077,  0.0858,  ..., -0.0919,  0.0741,  0.0711],\n",
       "        ...,\n",
       "        [ 0.0222, -0.0407, -0.0543,  ...,  0.0659,  0.0081,  0.0398],\n",
       "        [ 0.0137, -0.0373, -0.0338,  ...,  0.0561, -0.0003,  0.0436],\n",
       "        [ 0.0155, -0.0379, -0.0462,  ...,  0.0733,  0.0429,  0.0510]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=50264, bias=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
